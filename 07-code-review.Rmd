# Code Review
## Review protocol
This section describes the review protocol used for the systematic review presented in this
chapter. The protocol has been set up using Kitchenham's method as described by @kitchenham2007.

### Research questions
The goal of the review is to summarize the state of the art and identify future challenges in the
code review area. The research questions are as follows:

* **RQ1**: *What is the state of the art in the research area of code review?* This question
focusses on topics that are researched often, the results of that research, and research methods,
tools and datasets that are used.
* **RQ2**: *What is the current state of practice in the area of code review?* This concerns tools
and techniques that are developed and used in practice, by open source projects but also by
commercial companies.
* **RQ3**: *What are future challenges in the area of code review?* This concerns both research
challenges and challenges for use in practice.

### Search process
The search process consists of the following:

* A Google Scholar search using the search query *"modern code review" OR "modern code reviews"*.
The results list will be sorted by decreasing relevance by Google Scholar and will be considered by
us in order.
* A general Google search for non-scientific reports (e.g., blog posts) and implemented code review
tools. For this search queries *code review* and *code review tools* are used, respectively. The
result list will be considered in order.
* All papers in the initial seed provided by the course instructor will be considered.
* All papers referenced by already collected papers will be considered. We exlude papers found
using this rule of the search process. In other words, we do not apply this rule recursively.

From now on, elements of all four categories listed above in general will be called *resource*.

### Inclusion criteria
From the scientific literature, the following types of papers will be considered:

Papers researching recent code review

* concepts,
* methodologies,
* tools and platforms,
* and experiments concerning the preceding.

From non-scientific resources, all resources discussing recent tools and techniques used in
practice will be considered.

### Exclusion criteria
Resources published before 2008 will be excluded from the study, in order for the survey to show
only the state of the art of the field.

### Primary study selection process
We will select a number of candidate resources based on the criteria stated above. For each
resource, each person participating in the review can select it as a candidate.

From all candidates, resource will be selected that will actually be reviewed. This can also be
done by each person participating in the review. All resources that are candidates but are not
selected for actual review must be explicitly rejected, with accompanying reasoning, by at least
two persons participating in the review.

### Data collection
The following data will be collected from each considered resource:

* Source (for example, the blog website or specific journal)
* Year published
* Type of resource
* Author(s) and organization(s)
* Summary of the resource of a maximum of 100 words
* Data for answering **RQ1**:
    - Sub-topic of research
    - Research method
    - Tools that are subject of research
    - Datasets that are subject of research
    - Research questions and their answers
* Data for answering **RQ2**:
    - Tools used
    - Company/organization using the tool
    - Evaluation of the tool
* Data for answering **RQ3**:
    - Future research challenges posed

All data will be collected by one person participating in the review and checked by another.

## Candidate resources
In this section, all candidates that are collected using the described search process are
presented. The `In survey` column in the tables below indicates whether the paper has been
included in the survey in the end or if it has been excluded for some reason. If it has been
excluded, the reason will be stated in the section *Excluded papers*.

### Initial seed
These following table lists all initial seed papers provided by the course intructor. They are
listed in alphabetical order of the first author's name, and then by publish year.

| Title                                                                                                                               | Year | Reference                  | In survey? (Y/N) |
|-------------------------------------------------------------------------------------------------------------------------------------|------|----------------------------|------------------|
| Expectations, outcomes, and challenges of modern code review                                                                        | 2013 | @bacchelli2013expectations | Y                |
| Modern code reviews in open-source projects: Which problems do they fix?                                                            | 2014 | @beller2014modern          | Y                |
| Lessons learned from building and deploying a code review analytics platform                                                        | 2015 | @bird2015lessons           | Y                |
| Design and code inspections to reduce errors in program development                                                                 | 2002 | @fagan2002design           |                  |
| An exploratory study of the pull-based software development model                                                                   | 2014 | @gousios2014exploratory    |                  |
| The impact of code review coverage and code review participation on software quality: A case study of the qt, vtk, and itk projects | 2014 | @mcintosh2014impact        |                  |

### Google Scholar
The following table lists all candidates that have been collected through the Google Scholar search
described in the search process. They are listed in alphabetical order of the first author's name,
and then by publish year. Note that as described in the search process section, papers in the
search are considered in order of search result number. The *Search date* and *Result number*
columns indicate the date on which the search was executed and the position in the search result
list, respectively.

| Title                                                                                                         | Year | Reference                   | Search date | Result number | In survey? (Y/N) |
|---------------------------------------------------------------------------------------------------------------|------|-----------------------------|-------------|---------------|------------------|
| Investigating technical and non-technical factors influencing modern code review                              | 2016 | @baysal2016investigating    | 29-09-2018  | 9             |                  |
| Modern code review                                                                                            | 2010 | @cohen2010modern            | 25-09-2018  | 1             | N                |
| An empirical study of the impact of modern code review practices on software quality                          | 2016 | @mcintosh2016empirical      | 25-09-2018  | 4             |                  |
| A Study of the Quality-Impacting Practices of Modern Code Review at Sony Mobile                               | 2016 | @shimagaki2016study         | 29-09-2018  | 11            |                  |
| Reda: A web-based visualization tool for analyzing modern code review dataset                                 | 2014 | @thongtanunam2014reda       | 29-09-2018  | 8             |                  |
| Who should review my code? A file location-based code-reviewer recommendation approach for modern code review | 2015 | @thongtanunam2015should     | 29-09-2018  | 5             |                  |
| Revisiting code ownership and its relationship with software quality in the scope of modern code review       | 2016 | @thongtanunam2016revisiting | 29-09-2018  | 6             |                  |
| Review participation in modern code review                                                                    | 2017 | @thongtanunam2017review     | 29-09-2018  | 10            |                  |
| Mining the Modern Code Review Repositories: A Dataset of People, Process and Product                          | 2016 | @yang2016mining             | 29-09-2018  | 12            |                  |
| Automatically recommending peer reviewers in modern code review                                               | 2016 | @zanjani2016automatically   | 29-09-2018  | 7             |                  |
 

### By reference
The following table lists all candidates that have been found by being referenced by another paper
we found. They are listed in alphabetical order of the first author's name, and then by publish
year.

| Title                                                                                  | Year | Reference               | Referenced by | In survey? (Y/N) |
|----------------------------------------------------------------------------------------|------|-------------------------|---------------|------------------|
| A Faceted Classification Scheme for Change-Based Industrial Code Review Processes      | 2016 | @baum2016faceted        |               |                  |
| The Choice of Code Review Process: A Survey on the State of the Practice               | 2017 | @baum2017choice         |               |                  |
| The influence of non-technical factors on code review                                  | 2013 | @baysal2013influence    |               |                  |
| Impact of peer code review on peer impression formation: A survey                      | 2013 | @bosu2013impact         |               |                  |
| Software Reviews: The State of the Practice                                            | 2003 | @ciolkowski2003software |               |                  |
| Code reviews do not find bugs: how the current code review best practice slows us down | 2015 | @czerwonka2015code      |  Zequn        | Y                |

## Collected data
This section contains data collected from all resources included in the survey, according to the
*Data collection* section of the review protocol. Note that if some data could not be collected, it
is explicitly stated.

The resources are listed in alphabetical order of first author name, and then by year published.

### Expectations, outcomes, and challenges of modern code review
Reference: @bacchelli2013expectations

#### Summary
This paper describes research about the goals and actual effects of code reviews. Interviews and
experiments have been done with people in the programming field.

One of the main conclusions is that the main effect of doing code reviews is that everyone involved
understands the code better. This is opposed to what the goal of code reviews generally is:
discovering errors.

#### For answering **RQ1**
* *Sub-topic*: in practice; tools
* *Research method*: empirical; qualitative
* *Tools*: CodeFlow
* *Datasets*: Data collected from interviews, surveys and code reviews

#### Research questions and answers
* *What are the motivations and expectations for modern code review? Do they change from managers
  to developers and testers?* The top motivation for code reviews is finding defects, closely
  followed by code improvement. There does not seem to be a large difference between managers,
  developers and testers.
* *What are the actual outcomes of modern code review? Do they match the expectations?* Code
  improvements are the most seen outcomes of code review, followed by code understanding and social
  communication. The outcomes do not match the expectations well. For example, only 14% of
  researched review comments was about code defects, while about 44% chose finding defects as the
  main motivation for doing code review.
* *What are the main challenges experienced when performing modern code reviews relative to the
  expectations and outcomes?* The main challenges is by far understanding the code under review.
  This occurs for example when code has to be reviewed that is not in the same system as a
  developers works on daily.

#### For answering **RQ2**
Not applicable

#### For answering **RQ3**
#### Future research challenges
* Research on automating code review tasks. This mainly concerns low-level tasks, like checking
  boundary conditions or catching common mistakes.
* Research on code comprehension during code review. According to the authors research has been
  done on this with new developers in mind, but it would also be applicable to code reviews. The
  authors note that IDEs often include tools for code comprehension, but code review tools do not.
* Research on awareness and learning during code review. Those two aspects were cited as
  motivations for code review by developers. Future research could research these aspects more
  explicitly.

### A Faceted Classification Scheme for Change-Based Industrial Code Review Processes
Reference: @baum2016faceted

#### Summary
The broad research questions answered in this article are: How is code review performed in industry
today? Which commonalities and variations exist between code review processes of different teams
and companies? The article describes a classification scheme for change-based code review processes
in industry. This scheme is based on descriptions of the code review processes of eleven companies,
obtained from interviews with software engineering professionals that were performed during a
Grounded Theory study.

### The Choice of Code Review Process: A Survey on the State of the Practice
Reference: @baum2017choice

#### Summary
This paper, published in 2017, is trying to answer 3 RQs. Firstly, how prevalent is change-based
review in the industry? Secondly, does the chance that code review remains in use increase if code
review is embedded into the process (and its supporting tools) so that it does not require a
conscious decision to do a review? Thirdly, are the intended and acceptable levels of review
effects a mediator in determining the code review process?

### The influence of non-technical factors on code review
Reference: @baysal2013influence

### Investigating technical and non-technical factors influencing modern code review
Reference: @baysal2016investigating

### Modern code reviews in open-source projects: Which problems do they fix?
Reference: @beller2014modern

#### Summary
It has been researched what kinds of problems are solved by doing code reviews. The conclusion is
that 75% are improvements in evolvability of the code, and 25% in functional aspects.

It has also been researched which part of the review comments is actually followed up by an action,
and which part of the edits after a review are actually caused by review comments.

#### For answering **RQ1**
* *Sub-topic*: impact,changes
* *Research method*: empirically explore; change classification
* *Tools*: R
* *Datasets*: documented history of ConQAT and GROMACS

#### Research questions and answers
* *Which types of changes occur in code under review?* 75% of changes are related to the
evolvability of the system, and only 25% to its functionality.
* *What triggered the changes occurring in code under review?* 
78-90% of the trigger are review comments and the remaining 10-22% are 'undocumented'.
* *What influences the number of changes in code under review?* Code churn, number of changed files
and task type are the most important factors influencing the number of changes.

#### For answering **RQ2**
Not applicable

#### For answering **RQ3**
#### Future research challenges



### Lessons learned from building and deploying a code review analytics platform
Reference: @bird2015lessons

#### Summary
A code review data analyzation platform developed and used by Microsoft is discussed. It is mainly
presented what users of the system think of it and how its use influences development teams. One of
the conclusions is that in general, the platform has a positive influence on development teams and
their products.

#### For answering **RQ1**
Not applicable

#### For answering **RQ2**
* *Tools used:* CodeFlow
* *Company/organization using the tool:* Microsoft
* *Evaluation of the tool:* CodeFlow has already had a positive implace on development teams because of its simplicity, low barrier for feedback and flexible support of Microsoft's disparate engineering systems. But some challenges such as dealing with branches and linking reviews to commits need to improve.

#### For answering **RQ3**
#### Future research challenges
* Research on an automatic way to classify and assess the usefulness of comments. This is the interviewees's request and a challenge of CodeFlow.  
* Research on many aspects of code view based on CodeFlow or other similar tools. 

### Impact of peer code review on peer impression formation: A survey
Reference: @bosu2013impact

### Software Reviews: The State of the Practice
Reference: @ciolkowski2003software

#### Summary
To investigate how industry carries out software reviews and in what forms, this paper conducted
a two-part survey in 2002, the first part based on a national initiative in Germany and the second
involving companies worldwide. Additionally, this paper also include some fundamental concepts
of code review, such as functionalities of code review.

### Code reviews do not find bugs: how the current code review best practice slows us down
Reference: @czerwonka2015code

#### Summary
As code review has many uses and benefits, the authors hope to find out whether the current code
review methods are sufficiently efficient. They also research whether other methods may be more
efficient. With experience gained at Microsoft and with support of data, the authors posit (1) that
code reviews often do not find functionality issues that should block a code submission; (2) that
effective code reviews should be performed by people with a specific set of skills; and (3) that
the social aspect of code reviews cannot be ignored.

#### For answering **RQ1**
* *Sub-topic*: impact
* *Research method*: empirical
* *Tools*: not mentioned
* *Datasets*: data collected from engineering systems

#### Research questions and answers

* *In what situations, do code reviews provide more value than others?* 
Unlike inspections, code reviews do not require participants to be in the same place nor do they
happen at a fixed, prearranged time. 
Aligning with a distributed nature of many projects, code reviews are asynchronous and frequently
supporting geographically distributed reviewers.
* *What is the value of consistency of applying code reviews equally to all code changes?* 
Code review usefulness is negatively correlated with the size of a code review.
With 20 or more changed files, the more files there are in a single
review, the lower the overall rate of useful feedback.

#### For answering **RQ2**
Not applicable

#### For answering **RQ3**
#### Future research challenges
* Research on undocumented changes of code review because prior research has neglected.

* Due to its costs, code reviewing practice is a topic deserving to be better
understood, systematized and applied to software engineering workflow with more precision than the
best practice currently prescribes. 


### Design and code inspections to reduce errors in program development
Reference: @fagan2002design

#### Summary
This paper describes a method to thoroughly check code quality after each step of the development
process, in a heavyweight manner. It does not really concern agile development.

The authors state that these methods do not affect the developing process negatively, and that they
work well for improving software quality.

### An exploratory study of the pull-based software development model
Reference: @gousios2014exploratory

#### Summary
This article focuses on how much pull requests are being used and how they are used, focusing on
GitHub. For example, it is concluded that pull-requests are not being used that much, that
pull-requests are being merged fast after they have been submitted, and that a pull request not
being merged is most of the time not caused by technical errors in the pull-request.

### The impact of code review coverage and code review participation on software quality: A case study of the qt, vtk, and itk projects
Reference: @mcintosh2014impact

#### Summary
This paper focuses on the influence of doing light-weight code reviews on software quality. In
particular, the effect of review coverage (the part of the code that has been reviewed) and review
participation (a measure for how much reviewers are involved in the review process) are being
assessed.

It turns out that both aspects improve software quality when they are higher. Review participation
is the most influential. According to the authors there are other aspects, which they have not
looked into, that are of significant importance for the review process.

### Who should review my code? A file location-based code-reviewer recommendation approach for modern code review
Reference: @thongtanunam2015should

### Revisiting code ownership and its relationship with software quality in the scope of modern code review 
Reference: @thongtanunam2016revisiting

### Who should review this change?: Putting text and file location analyses together for more accurate recommendations
Reference: @xia2015should

### Automatically recommending peer reviewers in modern code review
Reference: @zanjani2016automatically

## Excluded papers
The following papers have been excluded from the survey. These papers are candidates, but have not
been added to the final survey for the stated reason.

* @cohen2010modern: This book is not accessible via the TU Delft subscription of Safari Books
  Online, and hence we could not read it to include it in the survey.
