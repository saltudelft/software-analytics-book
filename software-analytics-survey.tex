\documentclass[]{book}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={A Literature Survey of Software Analytics},
            pdfauthor={IN4334 2018 TU Delft},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{longtable,booktabs}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\newcommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}

  \title{A Literature Survey of Software Analytics}
    \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
    \author{IN4334 2018 TU Delft}
    \preauthor{\centering\large\emph}
  \postauthor{\par}
      \predate{\centering\large\emph}
  \postdate{\par}
    \date{2018-10-16}

\usepackage{booktabs}
\usepackage{amsthm}
\makeatletter
\def\thm@space@setup{%
  \thm@preskip=8pt plus 2pt minus 4pt
  \thm@postskip=\thm@preskip
}
\makeatother

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\chapter{Preamble}\label{intro}

The book you see in front of you is the outcome of an eight week seminar
run by the Software Engineering Research Group (SERG) at TU Delft. We
have split up the novel area of Software Analytics into several sub
topics. Every chapter addresses one such sub-topic of Software Analytics
and is the outcome of a systematic literature review a laborious team of
3-4 students performed.

With this book, we hope to structure the new field of Software Analytics
and show how it is related to many long existing research fields.

\emph{The IN4334 -- Software Analytics class of 2018}

\section{License}\label{license}

\includegraphics{figures/cc-nc-sa.png} This book is copyrighted 2018 by
TU Delft and its respective authors and distributed under the
\href{https://creativecommons.org/licenses/by-nc-sa/4.0/}{CC BY-NC-SA
4.0 license}

\chapter{A contemporary view on Software
Analytics}\label{a-contemporary-view-on-software-analytics}

\section{What is Software Analytics?}\label{what-is-software-analytics}

\section{A list of Software Analytics
Sub-Topics}\label{a-list-of-software-analytics-sub-topics}

\chapter{Testing Analytics}\label{testing-analytics}

\section{Motivation}\label{motivation}

Testing is an important aspect in software engineering, as it forms the
first line of defence against the introduction of software faults Pinto
et al. \cite{pinto2012understanding}. However, in practice it seems that
not all developers test actively. In this chapter we will survey on the
use of testing and the tools that make this possible. We will also look
into the future development of tools that is done or required in order
to improve testing practices in real-world applications. Testing is not
the holy grail for completely removing all bugs from a program but it
can decrease the chances for a user to encounter a bug. We believe that
extra research is needed to ease the life of developers by making
testing more efficient, easier to maintain and more effective.
Therefore, we wanted to write a survey on the testing behavior, current
practices and future developments of testing. In order to perform our
survey, we formulated three Research Questions (RQs):

\begin{itemize}
\tightlist
\item
  \textbf{RQ1} How do developers currently test?
\item
  \textbf{RQ2} What state of the art technologies are being used?
\item
  \textbf{RQ3} What future developments can be expected?
\end{itemize}

In this chapter we will first elaborate on the research protocol that
was used in order to find papers and extract information for the survey.
Second, the actual findings for each of the research questions will be
explained.

\section{Research Protocol}\label{research-protocol}

For this chapter, Kitchenham's survey method \cite{Kitchenham2004} was
applied. For this method, a protocol has to be specified. This protocol
is defined for the research questions given above. Below the inclusion
and exclusion criteria are given, which helped finding the rightful
papers. After these criteria, the actual search for papers is described.
The papers that were found are listed and after they are tested against
the criteria that are given. The data that is extracted from these
papers are list afterward. Some papers that were left out will be listed
and the reasons for leaving them out will be given to make clear why
some papers do not meet the required desire.

Each of the papers found was tested using our inclusion and exclusion
criteria. These criteria were introduced to make sure the papers have
the information required to answer the RQs while also being relevant
with respect to their quality and age. Below a list of inclusion and
exclusion criteria is given. In general, for all criteria, the exclusion
criteria take precedence over inclusion criteria. The following
inclusion and exclusion criteria were used:

\begin{itemize}
\tightlist
\item
  Papers published before 2008 are excluded from the research, unless a
  reference/citation is used for an unchanged concept.
\item
  Papers referring to less than 15 other papers, excluding
  self-references, are excluded from the research.
\item
  Selected papers should have an abstract, introduction and conclusion
  section.
\item
  Papers stating the developers' testing behavior are included.
\item
  Papers stating the developers' problems related to testing are
  included.
\item
  Papers stating the technologies, related to testing analytics, which
  developers use are included.
\item
  Papers writing about the expected advantage of current findings in
  testing analytics are included.
\item
  Papers with recommendations for future development in the software
  testing field are included.
\end{itemize}

The papers used in this chapter were found by using a given initial seed
of papers (query defined below as `Initial Paper Seed'). From this
initial seed of papers we used the keywords used by those papers to
construct queries. Additionally, the references (`referenced by') and
the citations (`cited in') of the papers were used to find papers. The
query row of the tables describing the references, as found below,
indicates how a paper was found. For queries the default search sites
were Scopus,\footnote{\url{https://www.scopus.com/}} Google
Scholar\footnote{\url{https://scholar.google.com/}} and
Springer.\footnote{\url{https://www.springer.com}}

The keywords used to construct queries in order to find papers were:
software, test*, analytics, test-suite, evolution, software development,
computer science, software engineering, risk-driven, survey software
testing

The table below describes for each paper, which Query resulted in which
paper being found. Each of the papers is categorized with a
corresponding research question. In the table below, the categories per
paper were added based on their general topic. These broad topics will
be assigned to a corresponding research question. Categorizations are
based on the bullet points extracted from each paper. These bullet
points can be found in the appendix of this chapter in section
\emph{`Extracted paper information'}.

\begin{longtable}[]{@{}llll@{}}
\toprule
\begin{minipage}[b]{0.18\columnwidth}\raggedright\strut
Category\strut
\end{minipage} & \begin{minipage}[b]{0.16\columnwidth}\raggedright\strut
Reference\strut
\end{minipage} & \begin{minipage}[b]{0.50\columnwidth}\raggedright\strut
Query\strut
\end{minipage} & \begin{minipage}[b]{0.04\columnwidth}\raggedright\strut
Relevant to\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.18\columnwidth}\raggedright\strut
Co-evolution\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright\strut
Greiler et al. {[}\protect\hyperlink{ref-greiler2013}{57}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.50\columnwidth}\raggedright\strut
In `cited by' of ``Understanding myths and realities of test-suite
evolution'' on Scopus\strut
\end{minipage} & \begin{minipage}[t]{0.04\columnwidth}\raggedright\strut
RQ2, RQ3\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.18\columnwidth}\raggedright\strut
Co-evolution\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright\strut
Hurdugaci and Zaidman
{[}\protect\hyperlink{ref-hurdugaci2012}{65}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.50\columnwidth}\raggedright\strut
Keywords: Maintain developer tests, `cited by' in ``Studying the
co-evolution of production and test code in open source and industrial
developer test processes through repository mining'' on IEEE\strut
\end{minipage} & \begin{minipage}[t]{0.04\columnwidth}\raggedright\strut
RQ2\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.18\columnwidth}\raggedright\strut
Co-evolution\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright\strut
Marsavina et al. {[}\protect\hyperlink{ref-marsavina2014}{86}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.50\columnwidth}\raggedright\strut
Google Scholar keywords: Maintain developer tests, in `cited by' of
``Aiding Software Developers to Maintain Developer Tests'' on IEEE\strut
\end{minipage} & \begin{minipage}[t]{0.04\columnwidth}\raggedright\strut
RQ1\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.18\columnwidth}\raggedright\strut
Co-evolution\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright\strut
Zaidman et al.
{[}\protect\hyperlink{ref-zaidman2011studying}{124}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.50\columnwidth}\raggedright\strut
Initial Paper Seed\strut
\end{minipage} & \begin{minipage}[t]{0.04\columnwidth}\raggedright\strut
RQ1\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.18\columnwidth}\raggedright\strut
Production evolution\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright\strut
Eick et al. {[}\protect\hyperlink{ref-eick2001}{51}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.50\columnwidth}\raggedright\strut
Referenced by: {[}\protect\hyperlink{ref-leung2015testing}{80}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.04\columnwidth}\raggedright\strut
Discarded\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.18\columnwidth}\raggedright\strut
Production evolution\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright\strut
Leung and Lui {[}\protect\hyperlink{ref-leung2015testing}{80}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.50\columnwidth}\raggedright\strut
Initial Paper Seed\strut
\end{minipage} & \begin{minipage}[t]{0.04\columnwidth}\raggedright\strut
RQ3\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.18\columnwidth}\raggedright\strut
Risk-driven testing\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright\strut
Atifi et al. {[}\protect\hyperlink{ref-atifi2017}{6}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.50\columnwidth}\raggedright\strut
In `cited by' of ``Risk-driven software testing and reliability''\strut
\end{minipage} & \begin{minipage}[t]{0.04\columnwidth}\raggedright\strut
RQ2, RQ3\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.18\columnwidth}\raggedright\strut
Risk-driven testing\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright\strut
Hemmati and Sharifi {[}\protect\hyperlink{ref-hemmati2018}{62}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.50\columnwidth}\raggedright\strut
In `cited by' of ``Test case analytics: Mining test case traces to
improve risk-driven testing''\strut
\end{minipage} & \begin{minipage}[t]{0.04\columnwidth}\raggedright\strut
RQ3\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.18\columnwidth}\raggedright\strut
Risk-driven testing\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright\strut
Noor and Hemmati {[}\protect\hyperlink{ref-noor2015test}{95}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.50\columnwidth}\raggedright\strut
Initial Paper Seed\strut
\end{minipage} & \begin{minipage}[t]{0.04\columnwidth}\raggedright\strut
RQ2, RQ3\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.18\columnwidth}\raggedright\strut
Risk-driven testing\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright\strut
Schneidewind {[}\protect\hyperlink{ref-schneidewind2007}{109}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.50\columnwidth}\raggedright\strut
Scopus query: risk-driven testing\strut
\end{minipage} & \begin{minipage}[t]{0.04\columnwidth}\raggedright\strut
RQ3\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.18\columnwidth}\raggedright\strut
Risk-driven testing\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright\strut
Vernotte et al. {[}\protect\hyperlink{ref-vernotte2015}{121}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.50\columnwidth}\raggedright\strut
Scopus query: ``risk-driven'' AND testing\strut
\end{minipage} & \begin{minipage}[t]{0.04\columnwidth}\raggedright\strut
RQ2, RQ3\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.18\columnwidth}\raggedright\strut
Test evolution\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright\strut
Bevan et al. {[}\protect\hyperlink{ref-bevan2005}{21}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.50\columnwidth}\raggedright\strut
Referenced by:
{[}\protect\hyperlink{ref-pinto2012understanding}{98}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.04\columnwidth}\raggedright\strut
Discarded\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.18\columnwidth}\raggedright\strut
Test evolution\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright\strut
Mirzaaghaei et al.
{[}\protect\hyperlink{ref-supportingtestsuite}{92}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.50\columnwidth}\raggedright\strut
Google Scholar query: test-suite evolution\strut
\end{minipage} & \begin{minipage}[t]{0.04\columnwidth}\raggedright\strut
RQ2, RQ3\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.18\columnwidth}\raggedright\strut
Test evolution\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright\strut
Pinto et al.
{[}\protect\hyperlink{ref-pinto2012understanding}{98}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.50\columnwidth}\raggedright\strut
Initial Paper Seed\strut
\end{minipage} & \begin{minipage}[t]{0.04\columnwidth}\raggedright\strut
RQ1\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.18\columnwidth}\raggedright\strut
Test evolution\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright\strut
Pinto et al. {[}\protect\hyperlink{ref-pinto2013}{97}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.50\columnwidth}\raggedright\strut
Referenced by:
{[}\protect\hyperlink{ref-pinto2012understanding}{98}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.04\columnwidth}\raggedright\strut
RQ1\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.18\columnwidth}\raggedright\strut
Test generation\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright\strut
Bowring and Hegler
{[}\protect\hyperlink{ref-bowring2014obsidian}{29}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.50\columnwidth}\raggedright\strut
Springer: Reverse search on ``Automatically generating maintainable
regression unit tests for programs''\strut
\end{minipage} & \begin{minipage}[t]{0.04\columnwidth}\raggedright\strut
RQ2, RQ3\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.18\columnwidth}\raggedright\strut
Test generation\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright\strut
Dulz {[}\protect\hyperlink{ref-dulz2013model}{47}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.50\columnwidth}\raggedright\strut
Scopus query: ``software development'' AND Computer Science AND Software
Engineering\strut
\end{minipage} & \begin{minipage}[t]{0.04\columnwidth}\raggedright\strut
RQ2\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.18\columnwidth}\raggedright\strut
Test generation\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright\strut
Robinson et al. {[}\protect\hyperlink{ref-robinson2011}{105}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.50\columnwidth}\raggedright\strut
Referenced by
{[}\protect\hyperlink{ref-supportingtestsuite}{92}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.04\columnwidth}\raggedright\strut
RQ2\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.18\columnwidth}\raggedright\strut
Test generation\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright\strut
Shamshiri et al.
{[}\protect\hyperlink{ref-shamshiri2018automatically}{110}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.50\columnwidth}\raggedright\strut
Google Scholar query: Automatically generating unit tests\strut
\end{minipage} & \begin{minipage}[t]{0.04\columnwidth}\raggedright\strut
RQ3\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.18\columnwidth}\raggedright\strut
Testing practices\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright\strut
Beller et al. {[}\protect\hyperlink{ref-beller2015}{20}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.50\columnwidth}\raggedright\strut
In `cited by' of ``Understanding myths and realities of test-suite
evolution''.\strut
\end{minipage} & \begin{minipage}[t]{0.04\columnwidth}\raggedright\strut
RQ1\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.18\columnwidth}\raggedright\strut
Testing practices\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright\strut
Beller et al.
{[}\protect\hyperlink{ref-beller2017developer}{16}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.50\columnwidth}\raggedright\strut
Initial Paper Seed\strut
\end{minipage} & \begin{minipage}[t]{0.04\columnwidth}\raggedright\strut
RQ1\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.18\columnwidth}\raggedright\strut
Testing practices\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright\strut
Garousi and Zhi {[}\protect\hyperlink{ref-GAROUSI20131354}{55}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.50\columnwidth}\raggedright\strut
Google Scholar query: Survey software testing\strut
\end{minipage} & \begin{minipage}[t]{0.04\columnwidth}\raggedright\strut
RQ1\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.18\columnwidth}\raggedright\strut
Testing practices\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright\strut
Moiz {[}\protect\hyperlink{ref-moiz2017uncertainty}{93}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.50\columnwidth}\raggedright\strut
Springer query: software testing\strut
\end{minipage} & \begin{minipage}[t]{0.04\columnwidth}\raggedright\strut
RQ3\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\section{Results}\label{results}

In this section the research questions will be answered. To answer these
questions, information from the relevant papers are aggregated. The
answers to each research questions are summarized in the conclusion.

\subsection{(RQ1) How do developers currently
test?}\label{rq1-how-do-developers-currently-test}

To answer RQ1, ``How do developers currently test?'', we first outline
general test practices, then discuss the co-evolution of test and
production code and finally, look into the use of Test Driven
Development among developers.

\subsubsection{How do we test?}\label{how-do-we-test}

For the quality of code, test coverage is a popular metric. Alternatives
are, for example, acceptance tests, the number of defects in the last
week, or defects per Line of Code (LOC)
{[}\protect\hyperlink{ref-GAROUSI20131354}{55}{]}. However, code
coverage might not be the best indicator for the extensiveness of
testing. For example, according to Beller et al.
{[}\protect\hyperlink{ref-Beller:2015:DT:2819009.2819101}{17}{]} a code
coverage of 75\% can possibly be reached with only spending less than a
tenth of the total development time on testing. Another concern of using
test coverage as a metric is the concept of treating the metric
{[}\protect\hyperlink{ref-bouwers2012a}{28}{]} , where developers try to
uplift the value of code coverage by hitting many lines with only a few
test cases. Marsavina et al.
{[}\protect\hyperlink{ref-marsavina2014}{86}{]} observed that test cases
were rarely updated when changes related to attributes or methods in the
production code were made. Possible explanations for this are that these
changes were not significant or the tests were too simple and were
likely to pass. This also fits with the findings of Romano et al.
{[}\protect\hyperlink{ref-ROMANO201764}{107}{]}, where they claim that
``{[}d{]}evelopers write quick-and-dirty production code to pass the
tests, do not update their tests often, and ignore refactoring.''

Besides older tests rarely being updated for changed code, even new
tests do not necessarily have the purpose of validating new production
code lines. Pinto et al.
{[}\protect\hyperlink{ref-pinto2012understanding}{98}{]} observed that a
significant number of new tests that are added, were not necessarily
added to cover new code but rather to exercise the changed parts of the
code after the program is modified. This finding fits with the
observation of Marsavina et al.
{[}\protect\hyperlink{ref-marsavina2014}{86}{]}, who found that test
cases are created or deleted in order to address the modified branches
whenever numerous condition related changes are conducted in the
production code base. Older production code lines, therefore, may stay
untouched by any test cases. Lines uncovered by any traditional code
coverage tool should be indicated and signaled to the developer.
Therefore, developers should be aware of the fact that they did not
cover some lines of their production code with any tests. It seems to be
a deliberate action by most developers to not cover older production
code lines. These lines might be `too hard' to test, other lines may be
easier to test, or developers do not seem to see the relevance of
testing these uncovered lines of code. However, the most commonly used
coverage metrics are branch coverage and conditional coverage
{[}\protect\hyperlink{ref-GAROUSI20131354}{55}{]}. As both branch
coverage and conditional coverage require multiple different conditions
for if-statements, it may possibly be that the absolute number of missed
lines of production code by tests is very low but rather the number of
missed conditions is higher.

\subsubsection{Co-evolution}\label{co-evolution}

In a case study conducted by Zaidman et al.
{[}\protect\hyperlink{ref-zaidman2011studying}{124}{]}, there was no
evidence found for an increased activity of testing before a release.

However, the study detected periods of increased test writing activity.
These increased activities of writing test cases were found to be after
longer periods of writing production code
{[}\protect\hyperlink{ref-zaidman2011studying}{124}{]}. With a longer
timespan of not writing tests, it can be concluded for these cases that
the production code and test code do not gracefully co-evolve
{[}\protect\hyperlink{ref-zaidman2011studying}{124}{]}
{[}\protect\hyperlink{ref-marsavina2014}{86}{]}.

\subsubsection{Test-Driven Development
(TDD)}\label{test-driven-development-tdd}

We found different definitions for TDD across multiple studies.
According to Zaidman et al.
{[}\protect\hyperlink{ref-zaidman2011studying}{124}{]}, evidence of TDD
was found where test code was committed alongside production code,
meaning that the methodology of TDD is used when production code was
written before the respective test code. This is in contrast with the
originally proposed constraint by Beck
{[}\protect\hyperlink{ref-beck2003test}{14}{]}, where a line of
production code should only be written after a failing automated test
was written in advance. The confusion for the definition of TDD can also
be traced back by the finding of Beller et al.
{[}\protect\hyperlink{ref-beller2015}{20}{]}, where programmers who
claim they practice TDD neither follow it strictly nor practice it for
all of their modification. A survey conveyed by Garousi and Zhi
{[}\protect\hyperlink{ref-GAROUSI20131354}{55}{]} on 196 respondents
(amongst them managers and developers) indicated that with a ratio of
3:1 use Test-last development and Test-driven development respectively.
This found ratio is in contrast with the numbers found by Beller et al.
{[}\protect\hyperlink{ref-beller2015}{20}{]}; only 1.7\% of the observed
developers seemed to follow the strict TDD definition, where most of
these developers only practice this strict definition in less than 20\%
of their time. However, it is important to mention that the survey done
by Garousi and Zhi {[}\protect\hyperlink{ref-GAROUSI20131354}{55}{]}
only surveyed the subjects, which allows the confusion for the
definition of TDD to play a major role in the results found.

\subsection{(RQ2) What state of the art technologies are being
used?}\label{rq2-what-state-of-the-art-technologies-are-being-used}

We will cover two research fields regarding testing analytics: test
evolution and generation, and risk-driven testing.

\subsubsection{Test Evolution and
Generation}\label{test-evolution-and-generation}

Pinto et al. {[}\protect\hyperlink{ref-pinto2012understanding}{98}{]}
found the investigation of automated test repairing is not a promising
research avenue, as these techniques would require manual guidance which
could end up being similar to traditional refactoring tools.
Nonetheless, more research is performed in this field since then. An
approach for automatically repairing and generating test cases during
software evolution is proposed by Mirzaaghaei et al.
{[}\protect\hyperlink{ref-supportingtestsuite}{92}{]}. This approach
uses information available in existing test cases, defines a set of
heuristics to repair test cases invalidated by changes in the software,
and generate new test cases for evolved software. This properly repairs
90\% of the compilation errors addressed and covers the same amount of
instructions. The results show that the approach can effectively
maintain evolving test suites and perform well compared to competing
approaches.

While full automated test suite generation can not replace human testing
entirely yet, Bowring and Hegler
{[}\protect\hyperlink{ref-bowring2014obsidian}{29}{]} introduced a tool
that generates the templates for tests, which guarantees compilation,
supports exception handling and finds a suitable location for the test.
Developers still need to fix the test oracles themselves, but the
template is there. The technique looks at the context in order to decide
what template to use. Robinson et al.
{[}\protect\hyperlink{ref-robinson2011}{105}{]} created a regression
unit tests generation tool. It is a suite of techniques for enhancing an
existing unit test generation system. The authors performed experiments
using an industrial system. The generated tests from these experiments
achieved good coverage and mutation kill score, were readable by the
product developers and required few edits as the system under test
evolved. Dulz {[}\protect\hyperlink{ref-dulz2013model}{47}{]} found that
by directly adjusting specific probability values in the usage profile
of a Markov chain usage model, it is relatively easy to generate
abstract test suites for different user classes and test purposes in an
automated approach. By using proper tools, such as the TestUS
Testplayer, even less experienced test engineers will be able to
efficiently generate abstract test cases and to graphically assess
quality characteristics of different test suites. Hurdugaci and Zaidman
{[}\protect\hyperlink{ref-hurdugaci2012}{65}{]} introduces TestNForce
(Visual Studio only), a tool to help developers identify unit tests that
need to be altered and executed after code change.

\subsubsection{Risk-driven Testing}\label{risk-driven-testing}

The paper by Vernotte et al.
{[}\protect\hyperlink{ref-vernotte2015}{121}{]} introduces and reports
on an original tool-supported, risk-driven security testing process
called Pattern-driven and Model-based Vulnerability Testing. This fully
automated testing process, relying on risk-driven strategies and
Model-Based Testing (MBT) techniques, aims to improve the capability of
detection of various Web application vulnerabilities, in particular SQL
injections, Cross-Site Scripting, and Cross-Site Request Forgery. An
empirical evaluation shows that this novel process is appropriate for
automatically generating and executing risk-driven vulnerability test
cases and is promising to be deployed for large-scale Web applications.

A new risk measure is defined by Noor and Hemmati
{[}\protect\hyperlink{ref-noor2015test}{95}{]}, which assigns a risk
factor to a test case if it is similar to a failing test case from
history. The new risk measure is by far more effective in identifying
failing test cases compared to the traditional risk measure. Using this
method for identifying test cases with a high risk factor, these test
cases can for example be ran in the background while developing code, to
find faults earlier. Furthermore, prioritizing these tests while running
the entire test-suite could make the suite detect failing tests earlier
and the developer can start fixing the faulty code right away.

\subsection{(RQ3) What Future Developments Can Be
Expected?}\label{rq3-what-future-developments-can-be-expected}

This section will elaborate on which future developments can be expected
in the field of software analytics.

\subsubsection{Co-Evolution and Test
Generation}\label{co-evolution-and-test-generation}

For understanding how test- and production code co-evolve and how tests
can be generated to support developers, studies have been conducted
{[}\protect\hyperlink{ref-marsavina2014}{86},
\protect\hyperlink{ref-pinto2012understanding}{98},
\protect\hyperlink{ref-zaidman2011studying}{124}{]}. Additionally a tool
has been made in order to analyze and, consequently, better understand
test-suite evolution {[}\protect\hyperlink{ref-pinto2013}{97}{]}. For
the time being the practical implications of this subtopic have mainly
been sought in the repairing and generation of tests.

According to Pinto et al.
{[}\protect\hyperlink{ref-pinto2012understanding}{98}{]} test repairs
occur often enough to justify the development and research for automated
repair techniques. M. Mirzaaghaei et al.
{[}\protect\hyperlink{ref-supportingtestsuite}{92}{]} argue that
evolving test cases is an expensive and time-consuming activity, for
which automated approaches reduce the pressure on developers. Shamshiri
et al. {[}\protect\hyperlink{ref-shamshiri2018automatically}{110}{]}
argue that automated generation of unit tests does not end up generating
realistic tests and that the effectivity of developers writing manual
tests is equal to developers using automatically generated tests.
Therefore, they call for the use of more realistic tests. This suggests
that automated test generation is still a topic of future interest,
which will likely be researched in order to find a way to generate
realistic tests.

\subsubsection{Risk-driven Testing}\label{risk-driven-testing-1}

Risk-driven testing is an area of recent attention. Researchers have
been looking for methods that can either detect potential risks within
the same project {[}\protect\hyperlink{ref-noor2015test}{95}{]}
{[}\protect\hyperlink{ref-hemmati2018}{62}{]}
{[}\protect\hyperlink{ref-vernotte2015}{121}{]} or that can detect risks
based on models carried over from one project to another
{[}\protect\hyperlink{ref-leung2015testing}{80}{]}
{[}\protect\hyperlink{ref-atifi2017}{6}{]}. These techniques have been
implementing history based prediction approaches.

In the future, we can expect more interest and research into risk-driven
testing as allocating testing activities effectively will remain
important due to testing efforts and developer time being expensive.
This area will likely stay in its research phase for the next couple of
years as effective measures for risk prediction are still being
researched. This goes for measures within the same project and
cross-project prediction. Given that the currently researched techniques
regard history based implementations, it is likely that these techniques
will be subject to further research later on.

\subsubsection{Testing Practices}\label{testing-practices}

Research of several papers
{[}\protect\hyperlink{ref-GAROUSI20131354}{55}{]}
{[}\protect\hyperlink{ref-beller2017developer}{16}{]}
{[}\protect\hyperlink{ref-beller2015}{20}{]} has indicated that testing
of any form is not as widely practiced as the status quo suggests. How
the current state of the practice will change depends on various
developments within the field. Tools will be created to assist the
developer in writing quality code and tests, such as TestEvoHound as
suggested by M. Greiler. {[}\protect\hyperlink{ref-greiler2013}{57}{]}.
As automated test generation becomes more effective this may reduce the
need for developers to spend a lot of time on writing and maintaining
tests. With the development of risk-driven testing, developers may also
be able to focus on the parts that are likely to be the most important
to address, which could lead to better time allocation. The status quo
for how much time is to be expected to be spent on testing may also
change, given automated test repair and generation techniques become
effective and accessible.

\section{Conclusion}\label{conclusion}

In this chapter, three different research questions about software
testing analytics were answered. (RQ1) How do developers currently test?
(RQ2) What state of the art technologies are being used? (RQ3) What
future developments can be expected?

Regarding the current testing practices of developers (RQ1), we found
that developers do not seem to update their tests very often and when
they do, it is because of a changed condition in production code lines.
Furthermore, older uncovered production code lines are not likely to be
covered in the end. Developers, thus, seem to ignore indications of
their code coverage tools or do not seem to use any code coverage tool
at all. Furthermore, developers do not seem to put a lot of effort into
making sure the co-evolution of their production- and test code is done
gracefully. They do, on the other hand, make sure their test code
compiles when production code classes have been removed. However,
testing is mostly done in longer periods of increased testing. The
methodology of TDD also seems to be a confusing term for developers, as
there is not enough clear guidance in the implementation of it. The
actual ratio of TLD and TDD is, therefore, unknown but can be guessed
with great certainty to be much lower for TDD than for TDD.

The current state of the art in testing analytics (RQ2) consists of
research in co-evolution and generation of tests, and risk-driven
testing. Approaches are proposed for automatically repairing and
generating test cases during software evolution. While fully automated
test suite generation is not there yet, a tool is introduced that
generates the templates for tests, which guarantees compilation,
supports exception handling and finds a suitable location for the test.
In the field of risk-driven testing, new risk measures are defined which
make prioritizing certain high-risk tests able while running the entire
test-suite, which could make the suite detect failing tests earlier.

For future developments (RQ3), further research can be expected on the
front of automated test generation. Even with some discussion regarding
the effectiveness of test generation, the field currently agrees that
conducting research in order to find, especially, realistic ways of
generating tests is worthwhile. We also found that risk-driven testing
has been given more attention in the form of research recently. This
subtopic is still in its research phase. It can be expected that
research on the front of history based risk prediction methods will
continue.

\chapter{Build analytics}\label{build-analytics}

\section{Motivation}\label{motivation-1}

Ideally, when building a project from source code to executable, the
process should be fast and without any errors. Unfortunately, this is
not always the case and automated builds results notify developers of
compile errors, missing dependencies, broken functionality and many
other problems. This chapter is aimed to give an overview of the effort
made in build analytics field and Continuous Integration (CI) as an
increasingly common development practice in many projects.

\section{Research Questions}\label{research-questions}

\begin{itemize}
\tightlist
\item
  \textbf{RQ1} What is the current state of the art in the field of
  build analytics? 
\item
  \textbf{RQ2} What is the current state of practice in the field of
  build analytics? 
\item
  \textbf{RQ3} What future research can we expect in the field of build
  analytics? 
\end{itemize}

\section{Research protocol}\label{research-protocol-1}

Using the initial seed consisting of
{[}\protect\hyperlink{ref-bird2017predicting}{22}{]},
{[}\protect\hyperlink{ref-beller2017oops}{18}{]},
{[}\protect\hyperlink{ref-rausch2017empirical}{103}{]},
{[}\protect\hyperlink{ref-beller2017travistorrent}{19}{]},
{[}\protect\hyperlink{ref-pinto2018work}{96}{]},
{[}\protect\hyperlink{ref-zhao2017impact}{127}{]},
{[}\protect\hyperlink{ref-widder2018m}{122}{]} and
{[}\protect\hyperlink{ref-hilton2016usage}{63}{]} we used references to
find new papers to analyze. Moreover, we used academical search engines
like \emph{GoogleScholar} to perform a keyword based search for other
relevant build analytics domain papers. The keywords used were: build
analytics, machine learning, build time, prediction, continuous
integration, build failures, active learning, build errors, mining,
software repositories, open-source software.

\section{Answers}\label{answers}

Through this we found the following papers

\section{Summary of papers}\label{summary-of-papers}

\subsection{\texorpdfstring{{[}\protect\hyperlink{ref-bird2017predicting}{22}{]}}{{[}22{]}}}\label{bird2017predicting}

\emph{Initial Seed}

This is a US patent grant for a method of predicting software build
errors. This patent is owned by Microsoft. Using logistic regression a
prediction can be made on the probability of a build failing. Using this
method build errors can be better anticipated, which decreases the time
until the build works again.

\subsection{\texorpdfstring{{[}\protect\hyperlink{ref-beller2017oops}{18}{]}}{{[}18{]}}}\label{beller2017oops}

\emph{Initial Seed}

This paper explores data from Travis CI\footnote{See
  \url{https://travis-ci.org}} on a large scale by analyzing 2,640,825
build logs of Java and Ruby builds. It uses \textsc{TravisTorrent} as a
data source. It is found that the number one reason for failing builds
it test failure. It also explores differences in testing between Java
and Ruby.

\subsection{\texorpdfstring{{[}\protect\hyperlink{ref-rausch2017empirical}{103}{]}}{{[}103{]}}}\label{rausch2017empirical}

\emph{Initial Seed}

A stuy on the build results of 14 open source software Java projects. It
is similar to {[}\protect\hyperlink{ref-beller2017oops}{18}{]}, albeit
on a smaller scale. It does go more in depth on the result and changes
over time.

\subsection{\texorpdfstring{{[}\protect\hyperlink{ref-beller2017travistorrent}{19}{]}}{{[}19{]}}}\label{beller2017travistorrent}

\emph{Initial Seed}

This paper introduces \textsc{TravisTorrent}, a dataset containing
analyzed builds from more than 1,000 projects. This data is freely
downloadable from the internet. It uses \textsc{GHTorrent} to link the
information from travis to commits on GitHub.

\subsection{\texorpdfstring{{[}\protect\hyperlink{ref-pinto2018work}{96}{]}}{{[}96{]}}}\label{pinto2018work}

\emph{Initial Seed}

This paper is a survey amongst Travis CI users. It found that users are
not sure whether a job failure represents a failure or not, that
inadequate testing is the most common (technical) reason for build
breakage and that people feel that there is a false sense of confidence
when blindly trusing tests.

\subsection{\texorpdfstring{{[}\protect\hyperlink{ref-zhao2017impact}{127}{]}}{{[}127{]}}}\label{zhao2017impact}

\emph{Initial Seed}

This paper analyzed approximately 160,000 projects written in seven
different programming languages. It notes that adoption of CI is often
part of a reorganization. It collected information on the differences
before and after adoption of CI. There is also a survey amongst
developers to learn about their experiences in adopting Travis CI.

\subsection{\texorpdfstring{{[}\protect\hyperlink{ref-widder2018m}{122}{]}}{{[}122{]}}}\label{widder2018m}

\emph{Initial Seed}

This paper analyzes what factors have impact on abandonment of Travis.
They find that increased build complexity reduces the chance of
abandonment, but larger projects abandon at a higher rate and that a
project's language has significant but varying effect. A surprising
result is that metrics of configuration attempts and knowledge
dispersion in the project do not affect the rate of abandonment.

\subsection{\texorpdfstring{{[}\protect\hyperlink{ref-hilton2016usage}{63}{]}}{{[}63{]}}}\label{hilton2016usage}

\emph{Initial Seed}

This paper explores which CI system developers use, how developers use
CI and why developers use CI. For this it analyzes data from Github,
Travis CI and it conducts a developer survey. It finds that projects
using CI release twice as often, accept pull requests faster and have
developers who are less worried about breaking the build.

\subsection{\texorpdfstring{{[}\protect\hyperlink{ref-vassallo2017tale}{120}{]}}{{[}120{]}}}\label{vassallo2017tale}

\emph{References {[}\protect\hyperlink{ref-beller2017oops}{18}{]} }

This paper discusses the difference in failures on continuous
integration between open source software (OSS) and industrial software
projects. For this 349 Java OSS projects and 418 project from ING
Nederland, a financial organization.

Using cluser analysis it was observed that both kinds of projects share
similar build failures, but in other cases very different patterns
emerge.

\subsection{\texorpdfstring{{[}\protect\hyperlink{ref-hassan2018hirebuild}{60}{]}}{{[}60{]}}}\label{hassan2018hirebuild}

\emph{References
{[}\protect\hyperlink{ref-beller2017travistorrent}{19}{]} }

This paper uses TravisTorrent
({[}\protect\hyperlink{ref-beller2017travistorrent}{19}{]}) to show that
22\% of code commits include changes in build script files to keep the
build working or to fix the build.

In the paper a tool is proposed to automatically fix build failures
based on previous changes.

\subsection{\texorpdfstring{{[}\protect\hyperlink{ref-vassallo2018break}{119}{]}}{{[}119{]}}}\label{vassallo2018break}

\emph{References {[}\protect\hyperlink{ref-beller2017oops}{18}{]},
{[}\protect\hyperlink{ref-rausch2017empirical}{103}{]} }

This paper proposes a tool called \textsc{BART} to help developers fix
build errors. This tool eliminates the need to browse error logs which
can be very long by generating a summary of the failure with useful
information.

\subsection{\texorpdfstring{{[}\protect\hyperlink{ref-zampetti2017open}{125}{]}}{{[}125{]}}}\label{zampetti2017open}

\emph{Referenced by {[}\protect\hyperlink{ref-vassallo2018break}{119}{]}
}

This paper studies the usage of static analysis tools in 20 Java open
source software projects hosted on GitHub and using Travic CI as
continuous integration infrastructure. There is investigated which tools
are being used, what types of issues make the build fail or raise
warnings and how is responded to broken builds.

\subsection{\texorpdfstring{{[}\protect\hyperlink{ref-baltes2018no}{8}{]}}{{[}8{]}}}\label{baltes2018no}

\emph{Google Scholar search term
\texttt{Github\ "Continuous\ Integration"}, papers from 2018}

This paper analyses 93 GitHub projects before and after adoption of
Travis CI. It finds only one non-negligible effect, an increasing merge
ratio, meaning that more merging commits in relation to all commits
after a project started using Travis CI. But the paper also shows that
this effect can be seen on projects not adopting CI. It shows the
importance of having a proper dataset with as little bias as possible.

\section{What is the current state of the art in the field of build
analytics?}\label{what-is-the-current-state-of-the-art-in-the-field-of-build-analytics}

The current state-of-the-art in build analytics domain refers to the use
of machine learning techniques to increase the productivity when using
Continuos Integration (CI), to generate contraints on the configuration
of the CI that could improve build success rate and to predict build
failures even for newer projects with less training data available.
Beside the papers from the initial seed, we will discuss the following
state-of-the-art aproaches papers:

\subsection{\texorpdfstring{{[}\protect\hyperlink{ref-bisong2017built}{24}{]}}{{[}24{]}}}\label{bisong2017built}

This paper aims to find a balance between the frequency of integration
and developers productivity. They proposed models able to predict the
build time of a job taking advantage of data from TravisTorrent. Their
research is also slighty addressing the problem of optimal build time.
Their method consists of selecting using different strategies to select
the relevant features from the 56 features presented in TravisTorrent
build records and applying a set of both linear and non-linear algorithm
for predicting the time of a build. They evaluate the models performance
using Root Mean Square Error (RMSE) and R-Squared and obtained for some
models like Extreme-Gradient-Boosting(XGBOOST) a very high R-Squared
around 80\%, which shows that their model was able to capture the
variation of build time over multiple projects. The main downfall of
this paper is the testing size of only 10000 records of the 1,846,396
available data due to computational limits resulted probably from the
usage of R machine learning packages, instead of python with TensorFlow.
Their research could be useful on one hand for software developers and
project managers for a better time management scheme and one the other
hand for other researchers that may improve their proposed models.

\subsection{\texorpdfstring{{[}\protect\hyperlink{ref-santolucito2018statically}{108}{]}}{{[}108{]}}}\label{santolucito2018statically}

The paper presents a tool VeriCI capable of checking the errors in CI
configurations files before the developer push a commit and without
needing to wait for the build result. Even if there are some other
papers that achieve even higher accuracy in prediction of build
failures, this paper is unique by not using metadata in the learning
process like number of commits, code churn and so on. The authors rely
on the actual user programs and configuration scripts, fact that make
the identification of the error cause possible. Their approach consists
of the following steps: give a formal description to the CI build
process, extract the right code features and train self-explainable
decision trees. VeriCI achieve 83\% accuracy of predicting build failure
on real data from GitHub projects and 30-48\% of time the error
justification provided by the tool matched the actual error cause. Even
if VeriCI is capable of locate and give a reason for the expected
failure, the false positive rate is quite high, therefore the authors
proposed as a future work the analysis of the cost impact that a high
rate of false positive has and also deploying the tool in large scale of
CI enviroments.

\subsection{\texorpdfstring{{[}\protect\hyperlink{ref-ni2018acona}{94}{]}}{{[}94{]}}}\label{ni2018acona}

This paper is posted only as a cover so far. It is the most recent paper
of this survey, with the poster being published in June 2018. The paper
addresses the problem of build failure prediction in CI environment for
newer projects with less data available. It is using already trained
models from other project with more data available and combined them by
the means of active learning in order to find which of that models
generalized better from the problem in hand and to update the models
weights accordingly. It is also aimed to cut the expense that CI
introduce by reducing the label data necessarily for training. Even if
the method seems promising, the results presented in the poster shows an
F-Measure (harmonic average of recall and precision) of around 40\% that
could be better improved.

\section{What is the current state of practice in the field of build
analytics?}\label{what-is-the-current-state-of-practice-in-the-field-of-build-analytics}

In this section, I will examine scientific papers to analyse the current
trend of build analytics in the software development industry.

\subsection{\texorpdfstring{{[}\protect\hyperlink{ref-fowler2006continuous}{53}{]}}{{[}53{]}}}\label{fowler2006continuous}

In this paper, Martin talks about the current state of the software
industry in terms of Continuous Integration (CI) and comments on the
practises required to implement CI effectively. He talks about his
experience working for a large English electronics company where the
development of a project took two years and the integration process took
several months. Integration is a long and unpredictable process. Martin
suggested this approach and that the two most common reactions he got
were: ``it can't work (here)'' or ``doing it won't make much
difference''. He expresses that most engineers don't know how simple the
process can be of setting the CI framework up. In this way, we get a
glimpse into the practises popular within the industry regarding build
analytics.

\subsection{\texorpdfstring{{[}\protect\hyperlink{ref-hilton2016usage}{63}{]}}{{[}63{]}}}\label{hilton2016usage-1}

This paper examines the usage, costs and benefits of Continuous
Integration. A survey conducted in open-source projects indicated that
40\% of all projects used CI. Of the projects that used CI, 90\% used
Travis for their CI services. They also determine that the more popular
projects use CI but there is no correlation between the popularity of
language and usage of CI. It also observes that the median project
introduces CI a year into development. The paper claims that CI is
widely used in practise nowadays and CI adoption rates will increase
even further in the future.

\subsection{\texorpdfstring{{[}\protect\hyperlink{ref-rausch2017empirical}{103}{]}}{{[}103{]}}}\label{rausch2017empirical-1}

Version Control Systems (VCS) such as GitHub, and hosted build
automation platforms such as Travis, have made Continuous Integration is
widely available for projects of every size. This paper suggests that CI
is widely used and has improved the quality of processes and developed
software itself. However, the article suggests that there is little
known about the variety and frequency of errors that cause builds to
fail. It suggests that developers should eliminate flaky tests and
address common issues regularly such as broken interaction with
repositories to keep the build system healthy.

\subsection{\texorpdfstring{{[}\protect\hyperlink{ref-stolberg2009enabling}{113}{]}}{{[}113{]}}}\label{stolberg2009enabling}

This paper defines CI as a key element in agile software development and
testing environment. It also uses Marin Fowler's practises of CI (as
discussed previously) and expresses the importance of CI in the software
industry.

\section{What future research can we expect in the field of build
analytics?}\label{what-future-research-can-we-expect-in-the-field-of-build-analytics}

Future research in build analytics branches in a couple of different
topics. {[}\protect\hyperlink{ref-pinto2018work}{96}{]} proposes to
focus on getting a better understanding of the users and why they might
choose to abandon an automatic build platform.

According to {[}\protect\hyperlink{ref-baltes2018no}{8}{]} future work
could look into more perspectives when analyzing commit data, for
instance partitioning commits by developer. It also notes the importance
of more qualitative research.

\chapter{Bug Prediction}\label{bug-prediction}

\section{Motivation}\label{motivation-2}

Minimizing the number of bugs in software is an effort central to
software engineering - faulty code fails to fullfill the purpose it was
written for, its impact ranges from sligthly embarrassing to disastrous
and dangerous, and last but not least - fixing it costs time and money.
Resources in a software development lifecycle are almost always limited
and therefore should be allocated to where they are needed most - in
order to avoid bugs, they should be focused on the most fault-prone
areas of the project. Being able to predict where such areas might be
would allow more development and testing efforts to be allocated on the
right places.

However, as noted in {[}\protect\hyperlink{ref-DAmbros2012}{50}{]},
reliably predicting which parts of source code are the most fault-prone
is one of the holy-grails of software engineering. Thus it is not
surprising that bug-prediction continues to garner a widespread research
interest in software analytics, now equipped with the ever-expanding
toolbox of data-mining and machine learning techniques. In this survey
we investigate the current efforts in bug-prediction in the light of the
advances in software analytics methods and focus our attention on
answering the following research questions:

\begin{itemize}
\tightlist
\item
  \textbf{RQ1} What is the current state of the art in bug prediction?
  More specifically, we aim to answer the following:

  \begin{itemize}
  \tightlist
  \item
    What software or other metrics does bug prediction rely on and how
    good are they?
  \item
    What kind prediction models are predominantly used?
  \item
    How are bug prediction models and results validated and evaluated?
  \end{itemize}
\item
  \textbf{RQ2} What is the current state of practice in bug prediction?

  \begin{itemize}
  \tightlist
  \item
    Are bug prediction techniques applied in practice and if so, how?
  \item
    Are the current developments in the field able to provide actionable
    tools for developers?
  \end{itemize}
\item
  \textbf{RQ3} What are some of the open challenges and directions for
  future research?
\end{itemize}

\section{Research protocol}\label{research-protocol-2}

We started by studying the initial 6 seed papers which were selected
based on domain knowledge:

\begin{itemize}
\tightlist
\item
  {[}\protect\hyperlink{ref-Gyimothy2005}{58}{]}
\item
  {[}\protect\hyperlink{ref-Catal2009review}{32}{]}
\item
  {[}\protect\hyperlink{ref-Arisholm2010}{5}{]}
\item
  {[}\protect\hyperlink{ref-DAmbros2010}{49}{]}
\item
  {[}\protect\hyperlink{ref-Hall2012}{59}{]}
\item
  {[}\protect\hyperlink{ref-Lewis2013}{81}{]}
\end{itemize}

Our searches were based on the following elements:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Keyword search using search engines (Scopus, ACM Digital Library, IEEE
  Explorer). The search query was constructed so that the paper title
  had to contain the phrase bug prediction, but also the other more
  general variants used in literature: \emph{bug/defect/fault
  prediction}. The title also had to contain at least one of following
  keywords: \emph{metrics}, \emph{models}, \emph{validation},
  \emph{evaluation}, \emph{developers}. To remain within the bug
  prediction field we required \emph{software} to appear in the
  abstract.
\item
  Filtering search results by publication date. We excluded papers older
  than 10 years; that is, published before 2008.
\item
  Filtering by the number of citations. We selected papers with 10 or
  more citations in order to focus on the ones that already have some
  visibility within the field.
\item
  Exploring other impactful publications by the same authors.
\end{enumerate}

\emph{Table 1. Papers found by investigating the authors of other
papers.}

\begin{longtable}[]{@{}lll@{}}
\toprule
Starting point & Type & Result\tabularnewline
\midrule
\endhead
{[}\protect\hyperlink{ref-DAmbros2010}{49}{]} & is author of &
{[}\protect\hyperlink{ref-DAmbros2012}{50}{]}\tabularnewline
{[}\protect\hyperlink{ref-Catal2009review}{32}{]} & is author of &
{[}\protect\hyperlink{ref-Catal2011}{31}{]}
{[}\protect\hyperlink{ref-Catal2009investigating}{33}{]}\tabularnewline
\bottomrule
\end{longtable}

\section{Answers}\label{answers-1}

\chapter{Ecosystem Analytics}\label{ecosystem-analytics}

\section{Motivation}\label{motivation-3}

In the modern day and age, the majority of software products make use of
external software or libraries to use the functionality (for example
parsing JSON) of these products, without having to develop this
functionality itself. Moreover, multiple languages, such as Python and
Rust, provide package managers (pip\footnote{\url{https://pypi.org/project/pip/}}
and Cargo\footnote{\url{https://crates.io/}} respectively) which can be
used to easily manage this third-party functionality, as well as
distribute it.

In parallel to this, the popularity of creating open source projects is
on the rise as well. On platforms such as GitHub\footnote{\url{https://github.com:}},
it is easy and quick to create a new software project, which can be
developed, reviewed and used by the whole community. This development
leads to more libraries being developed and being available for public
use.

Because of these two developments, further inspection of the dependency
relations between projects leads to a graph-like structure of software
projects, where the nodes are the projects and the edges represent a
dependency between two software projects. This structure is known as a
\emph{software ecosystem}. As stated by
{[}\protect\hyperlink{ref-Messerschmitt2003}{91}{]}, a \emph{software
ecosystem} is ``a collection of software products that have some given
degree of symbiotic relationships.'' Another, similar definition is
given by {[}\protect\hyperlink{ref-Lungu2009}{82}{]}: ``A software
ecosystem is a collection of software projects which are developed and
co-evolve in the same environment.''
{[}\protect\hyperlink{ref-Mens2013}{90}{]} extends this definition, ``by
explicitly considering the communities involved (e.g.~user and developer
communities) as being part of the software ecosystem.''
{[}\protect\hyperlink{ref-Stallman2002}{112}{]} opposes the overall
notion of calling this structure a software ecosystem: ``It is
inadvisable to describe the free software community, or any human
community, as an ecosystem, because that word implies the absence of
ethical judgment.''

Although {[}\protect\hyperlink{ref-Stallman2002}{112}{]} thinks that the
term software ecosystem itself is incorrect, it does not necessarily
disagree with the definition of the term. The definition which will be
used in this chapter is the definition of
{[}\protect\hyperlink{ref-Mens2013}{90}{]}, since it captures the
essence of the other two definitions, while adding the notion of the
human communities alongside as well.

By performing analysis on these software ecosystems, the aim is to
generate meaningful insights. These insights can then be used to improve
the efficiency and effectivity of the software development process, as
well as to learn to identify and inform about potential problems. For
example, a warning could be displayed if a dependency has a security
vulnerability.

The field of research on software ecosystems, \emph{ecosystem
analytics}, focuses on performing such analysis. This chapter discovers
what the current progress is in this field of research through a
literature survey. This discovery is not limited to the theoretical
perspective, but will uncover practical implications as well as the open
challenges of the field. In order to describe each covered aspect, we
have formulated three research questions:

\begin{itemize}
\tightlist
\item
  \textbf{RQ1}: What is the current state of the art in software
  analytics for ecosystem analytics?
\item
  \textbf{RQ2}: What are the practical implications from the state of
  the art?
\item
  \textbf{RQ3}: What are the open challenges in ecosystem analytics, for
  which future research is required?
\end{itemize}

Each of these research questions will be answered using recent papers
written in this field of research.

This chapter is structured as follows. First, the research protocol is
described in detail. This includes decisions on which papers are
included in the review. After this, the research questions are answered
using the previously stated set of papers.

\section{Research Protocol}\label{research-protocol-3}

In order to select literature to answer the research questions given in
the previous section, the survey method suggested by
{[}\protect\hyperlink{ref-Kitchenham2004}{75}{]} is used. This method
creates a systematic way to select a set of papers, which is relevant to
the research question(s).

The search strategy, as described by
{[}\protect\hyperlink{ref-Kitchenham2004}{75}{]}, are usually iterative
and benefit from consultations with experts in the field, amongst other
things. Our search strategy can be split in three different types:

\begin{itemize}
\tightlist
\item
  the initial seed, given by an expert in the field, MSc. Joseph
  Hejderup
\item
  a search using a digital search engine, namely Google
  Scholar\footnote{\url{https://github.com:}}
\item
  a selection of referenced papers within papers selected before in the
  above two searches
\end{itemize}

In order to select literature to answer the research questions given in
the previous section, the survey method suggested by
{[}\protect\hyperlink{ref-Kitchenham2004}{75}{]} is used. This method
creates a systematic way to select a set of papers, which is relevant to
the research question(s).

The search strategy, as described by
{[}\protect\hyperlink{ref-Kitchenham2004}{75}{]}, are usually iterative
and benefit from consultations with experts in the field, amongst other
things. Our search strategy can be split in three different types:

\begin{itemize}
\tightlist
\item
  the initial seed, given by an expert in the field, MSc. Joseph
  Hejderup
\item
  a search using a digital search engine, namely Google
  Scholar\footnote{\url{https://github.com:}}
\item
  a selection of referenced papers within papers selected before in the
  above two searches
\end{itemize}

\subsection{Initial seed}\label{initial-seed}

MSc. Joseph Hejderup has provided us with a total of thirteen papers, as
shown in Table 1.

As each of these papers come from an expert in the field, each paper is
assumed to be relevant to atleast the field of software ecosystems.
Because of this, each of these papers were judged on their relevance to
either of the research questions. In Table 1, this relevance judgment is
shown in the left column, since a paper is only selected, if the paper
is indeed relevant. Table 2 describes the reason for which each
particular paper is not selected for the literature survey.

\begin{longtable}[]{@{}lllll@{}}
\toprule
\begin{minipage}[b]{0.01\columnwidth}\raggedright\strut
Selected\strut
\end{minipage} & \begin{minipage}[b]{0.09\columnwidth}\raggedright\strut
Author(s)\strut
\end{minipage} & \begin{minipage}[b]{0.34\columnwidth}\raggedright\strut
Title\strut
\end{minipage} & \begin{minipage}[b]{0.02\columnwidth}\raggedright\strut
Year\strut
\end{minipage} & \begin{minipage}[b]{0.39\columnwidth}\raggedright\strut
Keywords\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.01\columnwidth}\raggedright\strut
-\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Abate2009}{2}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright\strut
Strong dependencies between software components\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2009\strut
\end{minipage} & \begin{minipage}[t]{0.39\columnwidth}\raggedright\strut
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.01\columnwidth}\raggedright\strut
-\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Abate2011}{1}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright\strut
Predicting upgrade failures using dependency analysis\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2011\strut
\end{minipage} & \begin{minipage}[t]{0.39\columnwidth}\raggedright\strut
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.01\columnwidth}\raggedright\strut
+\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Abdalkareem2017}{3}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright\strut
Why do developers use trivial packages? An empirical case study on
NPM\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2017\strut
\end{minipage} & \begin{minipage}[t]{0.39\columnwidth}\raggedright\strut
JavaScript; Node.js; Code Reuse; Empirical Studies\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.01\columnwidth}\raggedright\strut
+\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Bogart2016}{26}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright\strut
How to break an api: Cost negotiation and community values in three
software ecosystem\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2016\strut
\end{minipage} & \begin{minipage}[t]{0.39\columnwidth}\raggedright\strut
Software ecosystems; Dependency management; semantic versioning;
Collaboration; Qualitative research\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.01\columnwidth}\raggedright\strut
+\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Claes2015}{37}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright\strut
A historical analysis of Debian package incompatibilities\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2015\strut
\end{minipage} & \begin{minipage}[t]{0.39\columnwidth}\raggedright\strut
debian, conflict, empirical, analysis, software, evolution,
distribution, package, dependency, maintenance\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.01\columnwidth}\raggedright\strut
+\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Constantinou2017}{38}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright\strut
An empirical comparison of developer retention in the RubyGems and NPM
software ecosystems\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2017\strut
\end{minipage} & \begin{minipage}[t]{0.39\columnwidth}\raggedright\strut
Software ecosystem, Socio-technical interaction, Software evolution,
Empirical analysis, Survival analysis\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.01\columnwidth}\raggedright\strut
+\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Hejderup2018}{61}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright\strut
Software Ecosystem Call Graph for Dependency Management\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2018\strut
\end{minipage} & \begin{minipage}[t]{0.39\columnwidth}\raggedright\strut
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.01\columnwidth}\raggedright\strut
+\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Kikas2017}{73}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright\strut
Structure and evolution of package dependency networks\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2017\strut
\end{minipage} & \begin{minipage}[t]{0.39\columnwidth}\raggedright\strut
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.01\columnwidth}\raggedright\strut
+\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Kula2017}{78}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright\strut
Do developers update their library dependencies?\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2017\strut
\end{minipage} & \begin{minipage}[t]{0.39\columnwidth}\raggedright\strut
Software reuse, Software maintenance, Security vulnerabilities\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.01\columnwidth}\raggedright\strut
-\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Mens2013}{90}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright\strut
Studying Evolving Software Ecosystems based on Ecological Models\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2013\strut
\end{minipage} & \begin{minipage}[t]{0.39\columnwidth}\raggedright\strut
Coral Reef, Natural Ecosystem, Open Source Software, Ecological Model,
Software Project\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.01\columnwidth}\raggedright\strut
+\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Raemaekers2017}{101}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright\strut
Semantic versioning and impact of breaking changes in the Maven
repository\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2017\strut
\end{minipage} & \begin{minipage}[t]{0.39\columnwidth}\raggedright\strut
Semantic versioning, Breaking changes, Software libraries\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.01\columnwidth}\raggedright\strut
+\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Robbes2012}{104}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright\strut
How do developers react to API deprecation? The case of a smalltalk
ecosystem\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2012\strut
\end{minipage} & \begin{minipage}[t]{0.39\columnwidth}\raggedright\strut
Ecosystems, Mining Software Repositories, Empirical Studies\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.01\columnwidth}\raggedright\strut
+\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Trockman2018}{118}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright\strut
Adding sparkle to social coding: An empirical study of repository badges
in the npm ecosystem\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2018\strut
\end{minipage} & \begin{minipage}[t]{0.39\columnwidth}\raggedright\strut
\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\emph{Table: 1. Papers provided by MSc. Joseph Hejderup. The first
column describes whether the paper of the row will be used. A `+' means
it will be used, a `-' means it will not.}

\begin{longtable}[]{@{}ll@{}}
\toprule
\begin{minipage}[b]{0.05\columnwidth}\raggedright\strut
Paper Reference\strut
\end{minipage} & \begin{minipage}[b]{0.05\columnwidth}\raggedright\strut
Reason not selected\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.05\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Abate2009}{2}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.05\columnwidth}\raggedright\strut
This paper seems to delve more into one software project itself whereas
we are more interested in the relationship between different software
projects\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.05\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Abate2011}{1}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.05\columnwidth}\raggedright\strut
Similarly to {[}\protect\hyperlink{ref-Abate2009}{2}{]}, we are more
interested in the relationship between different software projects\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.05\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Mens2013}{90}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.05\columnwidth}\raggedright\strut
We were in doubt over this one, it could be useful but we weren't
convinced that it was. Since we already had a lot of material we decided
to not use this\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\emph{Table: 2. Papers from the initial seed that were not selected for
the literature survey, along with a specification of the reason why this
is the case.}

\subsection{Digital Search Engine}\label{digital-search-engine}

The second strategy type which is used to select relevant papers for
this literature study, is by a digital search engine. In this literature
survey, Google Scholar\footnote{\url{https://github.com:}} is used. From
the initial seed, common keywords were retrieved and the following
queries have been used to search for relevant papers:

\begin{itemize}
\tightlist
\item
  ``software ecosystems'' AND ``empirical analysis'' \emph{(2018)}
\item
  ``engineering software ecosystems'' \emph{(2014)}
\item
  ``software ecosystem'' AND ``empirical'' \emph{(2014)}
\item
  ``software ecosystem analytics'' \emph{(2014)}
\item
  ``software ecosystem'' AND ``analysis'' \emph{(2017)}
\item
  ``software ecosystem'' AND ``empirical'' \emph{(2018)}
\end{itemize}

For each of these queries, the results were first filtered by the
publish year. These are described by the italic year after each query
above. The papers that are filtered are published earlier than the set
publish year. These specific years were chosen since the survey focuses
on the state of the art within the ecosystem analytics.

After this filtering, we first determined whether a paper was relevant
to the literature survey by examining the title. If it was unclear
whether the paper was indeed relevant by only looking at the title, the
abstract of the paper was examined closely. On these two criteria, each
of the selected papers were judged and ultimately selected. The selected
paper using these method can be found in Table 3.

\begin{longtable}[]{@{}lllll@{}}
\toprule
\begin{minipage}[b]{0.05\columnwidth}\raggedright\strut
First Author\strut
\end{minipage} & \begin{minipage}[b]{0.31\columnwidth}\raggedright\strut
Title\strut
\end{minipage} & \begin{minipage}[b]{0.02\columnwidth}\raggedright\strut
Year\strut
\end{minipage} & \begin{minipage}[b]{0.34\columnwidth}\raggedright\strut
Keywords\strut
\end{minipage} & \begin{minipage}[b]{0.13\columnwidth}\raggedright\strut
Query Used\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.05\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Decan2018}{44}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.31\columnwidth}\raggedright\strut
An empirical comparison of dependency network evolution in seven
software packaging ecosystems\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2018\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright\strut
Software repository mining, Software ecosystem, Package manager,
Dependency network, Software evolution\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright\strut
``software ecosystems'' AND ``empirical analysis''\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.05\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Dittrich2014}{46}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.31\columnwidth}\raggedright\strut
Software engineering beyond the project -- Sustaining software
ecosystems\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2014\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright\strut
\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright\strut
engineering software ecosystems\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.05\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Hora2016}{64}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.31\columnwidth}\raggedright\strut
How do developers react to API evolution? A large-scale empirical
study\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2016\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright\strut
API evolution, API deprecation, Software ecosystem, Empirical
study\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright\strut
``software ecosystem'' AND ``empirical''\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.05\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Izquierdo2018}{66}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.31\columnwidth}\raggedright\strut
Software Development Analytics for Xen: Why and How\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2018\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright\strut
Companies, Ecosystems, Software, Measurement, Object recognition,
Monitoring, Virtualization\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright\strut
software ecosystem analytics\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.05\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Jansen2014}{67}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.31\columnwidth}\raggedright\strut
Measuring the Health of Open Source Software Ecosystems: Beyond the
Scope of Project Health\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2014\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright\strut
\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright\strut
``open source software ecosystems''\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.05\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Kula2017-2}{77}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.31\columnwidth}\raggedright\strut
An exploratory study on library aging by monitoring client usage in a
software ecosystem\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2017\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright\strut
\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright\strut
``software ecosystem'' AND ``analysis''\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.05\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Malloy2018}{83}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.31\columnwidth}\raggedright\strut
An empirical analysis of the transition from Python 2 to Python 3\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2018\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright\strut
Python programming, Programming language evolution, Compliance\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright\strut
``software ecosystem'' AND ``empirical''\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.05\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Manikas2016}{85}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.31\columnwidth}\raggedright\strut
Revisiting software ecosystems Research: A longitudinal literature
study\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2016\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright\strut
Software ecosystems; Longitudinal literature study; Software ecosystem
maturity\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright\strut
``Software ecosystems'' OR ``Dependency management'' OR ``semantic
version''\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.05\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Rajlich2014}{102}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.31\columnwidth}\raggedright\strut
Software evolution and maintenance\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2014\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright\strut
\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright\strut
Software Evolution and Maintenance\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.05\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Teixeira2015}{115}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.31\columnwidth}\raggedright\strut
Lessons learned from applying social network analysis on an industrial
Free/Libre/Open Source Software Ecosystem\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2015\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright\strut
Social network analysis Open source Open-coopetition Software ecosystems
Business models Homophily Cloud computing OpenStack\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright\strut
``software ecosystem analytics''\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\emph{Table: 3. Papers selected from searches using Google Scholar. The
column ``Query Used'' describes which of the queries is used to retrieve
the paper.}

\subsection{Referenced papers}\label{referenced-papers}

Finally, a selection of papers has been made by looking at the
references found in papers selected using the two methods above. For
these papers, the selection process is similar to that of the selected
papers using the digital search engine; it is selected when both the
title and the abstract are deemed relevant to the research questions.
This has led to the papers in Table 4. being selected.

\begin{longtable}[]{@{}lllll@{}}
\toprule
\begin{minipage}[b]{0.12\columnwidth}\raggedright\strut
First Author\strut
\end{minipage} & \begin{minipage}[b]{0.31\columnwidth}\raggedright\strut
Title\strut
\end{minipage} & \begin{minipage}[b]{0.02\columnwidth}\raggedright\strut
Year\strut
\end{minipage} & \begin{minipage}[b]{0.24\columnwidth}\raggedright\strut
Keywords\strut
\end{minipage} & \begin{minipage}[b]{0.16\columnwidth}\raggedright\strut
Referenced In\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.12\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Bavota2014}{11}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.31\columnwidth}\raggedright\strut
How the Apache community upgrades dependencies: an evolutionary
study\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2014\strut
\end{minipage} & \begin{minipage}[t]{0.24\columnwidth}\raggedright\strut
Software Ecosystems  Project dependency upgrades  Mining software
repositories\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Kula2017}{78}{]}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.12\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Blincoe2015}{25}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.31\columnwidth}\raggedright\strut
Ecosystems in GitHub and a method for ecosystem identification using
reference coupling.\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2015\strut
\end{minipage} & \begin{minipage}[t]{0.24\columnwidth}\raggedright\strut
\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Constantinou2017}{38}{]}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.12\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Cox2015}{41}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.31\columnwidth}\raggedright\strut
Measuring Dependency Freshness in Software Systems\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2015\strut
\end{minipage} & \begin{minipage}[t]{0.24\columnwidth}\raggedright\strut
\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Kikas2017}{73}{]}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.12\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Decan2017}{43}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.31\columnwidth}\raggedright\strut
An empirical comparison of dependency issues in OSS packaging
ecosystems\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2017\strut
\end{minipage} & \begin{minipage}[t]{0.24\columnwidth}\raggedright\strut
\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Abdalkareem2017}{3}{]},
{[}\protect\hyperlink{ref-Constantinou2017}{38}{]},
{[}\protect\hyperlink{ref-Decan2018}{44}{]}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.12\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Dietrich2014}{45}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.31\columnwidth}\raggedright\strut
Broken Promises - An Empirical Study into Evolution Problems in Java
Programs Caused by Library Upgrades\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2014\strut
\end{minipage} & \begin{minipage}[t]{0.24\columnwidth}\raggedright\strut
\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Raemaekers2017}{101}{]}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.12\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Malloy2017}{84}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.31\columnwidth}\raggedright\strut
Quantifying the transition from Python 2 to 3: an empirical study of
Python applications.\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2017\strut
\end{minipage} & \begin{minipage}[t]{0.24\columnwidth}\raggedright\strut
\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Malloy2018}{83}{]}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.12\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-McDonnell2013}{88}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.31\columnwidth}\raggedright\strut
An empirical study of api stability and adoption in the android
ecosystem\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2013\strut
\end{minipage} & \begin{minipage}[t]{0.24\columnwidth}\raggedright\strut
\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Manikas2016}{85}{]}\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\emph{Table: 4. Papers selected which are referenced in previously
selected papers. The column ``Referenced In'' describes in which
selected paper the paper is referenced.}

\section{Answers}\label{answers-2}

In this section, an aggregation of information, found in the papers, is
presented. Each subsection of this section focuses on one of the three
research questions posed in Section 1.

\subsection{What is the current state of the art in software analytics
for ecosystem
analytics?}\label{what-is-the-current-state-of-the-art-in-software-analytics-for-ecosystem-analytics}

To answer this research question, we examine the explored topics in
ecosystem analytics. Moreover, we summarize which research methods,
tools and datasets are being used to explore this topics.

The main topic explored in the selected papers are related to the
dependencies within the software ecosystem. One of the main subjects
related to these dependencies is the subject of breaking changes between
different versions of a package.
{[}\protect\hyperlink{ref-Bogart2016}{26}{]} researched the attitude of
developers of Eclipse, CRAN and NPM packages towards making breaking
changes.

\begin{longtable}[]{@{}lllllll@{}}
\toprule
\begin{minipage}[b]{0.09\columnwidth}\raggedright\strut
Reference\strut
\end{minipage} & \begin{minipage}[b]{0.16\columnwidth}\raggedright\strut
Explored topic(s)\strut
\end{minipage} & \begin{minipage}[b]{0.17\columnwidth}\raggedright\strut
Research method(s)\strut
\end{minipage} & \begin{minipage}[b]{0.07\columnwidth}\raggedright\strut
Tool(s)\strut
\end{minipage} & \begin{minipage}[b]{0.10\columnwidth}\raggedright\strut
Dataset(s)\strut
\end{minipage} & \begin{minipage}[b]{0.12\columnwidth}\raggedright\strut
Ecosystem(s)\strut
\end{minipage} & \begin{minipage}[b]{0.10\columnwidth}\raggedright\strut
Conclusion\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.09\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Abdalkareem2017}{3}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright\strut
Empirical study on the use of trivial packages, as well as the reasoning
behind this\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright\strut
Quantitative frequency, Survey\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedright\strut
-\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright\strut
NPM, GitHub\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\raggedright\strut
NPM\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright\strut
Used because it is assumed to be well implemented and tested (only 45\%
actually has tests) and increases productivity. Quantitative research
has shown that 10\% of NodeJS uses trivial packages, where 16.8\% are
trivial packages in NPM\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.09\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Bogart2016}{26}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright\strut
Attitude of towards breaking changes and how do ecosystems influence
this\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright\strut
Interviews\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedright\strut
-\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright\strut
-\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\raggedright\strut
Eclipse, CRAM, NPM\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright\strut
There are numerous ways of dealing with breaking changes and ecosystems
play an essential role in the chosen way.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.09\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Decan2018}{44}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright\strut
Quantative empirical analysis of differences and similarities between
the evolution of 7 varying ecosystems\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright\strut
Survival analysis\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedright\strut
-\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright\strut
libraries.io\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\raggedright\strut
Cargo, CPAN, CRAN, npm, NuGet, Packagist, RubyGems\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright\strut
Package updates, which may cause dependent package failrues, are done on
average every few months. Many packages in the analyzed package
dependency networks were found to have a high number of transitive
reverse dependencies, implying that package failures can affect a large
number of other packages in the ecosystem.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.09\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Dittrich2014}{46}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright\strut
The article provides a holistic understanding of the observed and
reported practices as a starting point to device specific support for
the development in software ecosystems\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright\strut
Qualitative interview study\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedright\strut
-\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright\strut
-\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\raggedright\strut
-\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright\strut
The main contribution of this article is the presentation of common
features of product development and evolution in four companies.
Although size, kind of software and business models differ\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.09\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Izquierdo2018}{66}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright\strut
Code review analysis\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright\strut
Virtualization of process\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedright\strut
-\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright\strut
Xen Github data\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\raggedright\strut
Xen\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright\strut
Analysis of code review has lead to more reviews and a more thoughtful
and participary review process. Also providing accomodations for new
software developers on OSS by easy access is very important.\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\subsection{What are the practical implications from the state of the
art?}\label{what-are-the-practical-implications-from-the-state-of-the-art}

\begin{longtable}[]{@{}llllll@{}}
\toprule
\begin{minipage}[b]{0.10\columnwidth}\raggedright\strut
Reference\strut
\end{minipage} & \begin{minipage}[b]{0.18\columnwidth}\raggedright\strut
Explored topic(s)\strut
\end{minipage} & \begin{minipage}[b]{0.19\columnwidth}\raggedright\strut
Research method(s)\strut
\end{minipage} & \begin{minipage}[b]{0.11\columnwidth}\raggedright\strut
Dataset(s)\strut
\end{minipage} & \begin{minipage}[b]{0.13\columnwidth}\raggedright\strut
Ecosystem(s)\strut
\end{minipage} & \begin{minipage}[b]{0.11\columnwidth}\raggedright\strut
Conclusion\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.10\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Hora2016}{64}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.18\columnwidth}\raggedright\strut
Exploratory study aimed at observing API evolution and its impact\strut
\end{minipage} & \begin{minipage}[t]{0.19\columnwidth}\raggedright\strut
Empirical study\strut
\end{minipage} & \begin{minipage}[t]{0.11\columnwidth}\raggedright\strut
3600 distinct systems\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright\strut
Pharo\strut
\end{minipage} & \begin{minipage}[t]{0.11\columnwidth}\raggedright\strut
After API changes, clients need time to react and rarely react at all.
Replacements cannot be resolved in a uniform manner throughout the
ecosystem. API changes and deprication can present different
characteristics.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.10\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Kula2017}{78}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.18\columnwidth}\raggedright\strut
An Empirical Study on the Impact of Security Advisories on Library
Migration\strut
\end{minipage} & \begin{minipage}[t]{0.19\columnwidth}\raggedright\strut
Empirical study\strut
\end{minipage} & \begin{minipage}[t]{0.11\columnwidth}\raggedright\strut
4,600 GitHub software projects and 2,700 library dependencies\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright\strut
Github, Maven\strut
\end{minipage} & \begin{minipage}[t]{0.11\columnwidth}\raggedright\strut
Currently, developers do not actively update their libraries, leading to
security risks.\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\subsection{What are the open challenges in ecosystem analytics, for
which future research is
required?}\label{what-are-the-open-challenges-in-ecosystem-analytics-for-which-future-research-is-required}

\begin{longtable}[]{@{}ll@{}}
\toprule
\begin{minipage}[b]{0.13\columnwidth}\raggedright\strut
Reference\strut
\end{minipage} & \begin{minipage}[b]{0.29\columnwidth}\raggedright\strut
Open Challenges Found\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.13\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Abdalkareem2017}{3}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.29\columnwidth}\raggedright\strut
Examine relationship between team experience and project maturity and
usage of trivial packages\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.13\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Abdalkareem2017}{3}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.29\columnwidth}\raggedright\strut
Compare use of code snippets on Q\&A sites and trivial packages\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.13\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Abdalkareem2017}{3}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.29\columnwidth}\raggedright\strut
How to manage and help developers choose the best packages\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.13\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Decan2018}{44}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.29\columnwidth}\raggedright\strut
Findings for one ecosystem cannot necessarily be generalized to
another\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.13\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Decan2018}{44}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.29\columnwidth}\raggedright\strut
Transitive dependencies are very frequent, meaning that package failrues
can affect a large number of other packages in the ecosystem\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.13\columnwidth}\raggedright\strut
{[}\protect\hyperlink{ref-Jansen2014}{67}{]}\strut
\end{minipage} & \begin{minipage}[t]{0.29\columnwidth}\raggedright\strut
Determing the health of a system from an ecosystem perspective instead
of project level is needed to determine which systems to use. This paper
provides an initial approach but a lot more research could and should be
done to determine system health.\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\chapter{Release Engineering
Analytics}\label{release-engineering-analytics}

\section{Motivation}\label{motivation-4}

Release engineering is a discipline involved with making software
available for end users. Efforts spent within the development
environment of a software system should eventually be integrated and
deployed such that end users may benefit from them. In recent years,
release engineers have developed and adopted techniques to build
infrastructures and pipelines which automate the process of releasing
software to an increasingly large degree. These modern approaches have
resulted in various practices such as releasing new versions of a
software system in significantly shorter cycles.

Due to these developments being industry-driven, release engineering
forms a largely uncharted territory for software engineering research.
It requires the attention from researchers both because these new
practices have an often unanticipated impact on software studies and
because they require empirical validation
{[}\protect\hyperlink{ref-adams2016a}{4}{]}.

Therefore, this systematic literature review aims to provide an overview
of the software analytics research that has been conducted so far on
modern release engineering. Its main purpose is to identify the apparent
gap between research and practice, in order to guide further research
efforts.

\subsection{Research Questions}\label{research-questions-1}

Contrary to what is regularly the case, advances in release engineering
practices are driven by industry, instead of scientific research.
Building on this idea, our questions are constructed to identify in
which ways existing modern release engineering practices should still be
studied in software analytics research. Our review thus aims to answer
the following questions.

\begin{itemize}
\item
  \textbf{RQ 1:} \emph{How is modern release engineering done in
  practice?} This question aims to identify the so-called ``state of the
  practice'' in release engineering. We will summarize practices that
  have been adopted to drive release engineering forward. In addition we
  will identify the tools utilized to bring this about. Case studies
  will also be analyzed to this end.
\item
  \textbf{RQ 2:} \emph{What aspects of modern release engineering have
  been studied in software analytics research so far?} In order to
  answer this question we investigate the practices that previous
  empirical studies have focused on. In doing so, we identify the
  associated costs and benefits that have been found, and the analysis
  methods used.
\item
  \textbf{RQ 3:} \emph{What aspects of modern release engineering make
  for relevant study objects in future software analytics research?} In
  answering this question we aim to identify the gap between practice
  and research in release engineering. This way, our intent is not only
  to guide but also to motivate future research.
\end{itemize}

\section{Research Protocol}\label{research-protocol-4}

In this section, we will describe\ldots{}

\subsection{Search Strategy}\label{search-strategy}

Since release engineering is a relatively new research topic, we took an
exploratory approach in collecting any literature revolving around the
topic of release engineering from the perspective of software analytics.
This aided us in determining a more narrow scope for our survey,
subsequently allowing us to find additional literature fitting this
scope.

At the start of this project, we were provided with an initial seed of
five papers as a starting point for our literature survey. These initial
papers were {[}\protect\hyperlink{ref-adams2016a}{4}{]},
{[}\protect\hyperlink{ref-da2016a}{40}{]},
{[}\protect\hyperlink{ref-da2014a}{39}{]},
{[}\protect\hyperlink{ref-khomh2012a}{72}{]}, and
{[}\protect\hyperlink{ref-khomh2015a}{71}{]}.

We collected publications using two search engines: Scopus and Google
Scholar. Each of the two search engines comprises several databases such
as ACM Digital Library, Springer, IEEE Xplore and ScienceDirect. The
main query that we constructed is displayed in Figure 1. The
publications found using this query were:

\begin{itemize}
\tightlist
\item
  {[}\protect\hyperlink{ref-kaur2019a}{69}{]}
\item
  {[}\protect\hyperlink{ref-kerzazi2013a}{70}{]}
\item
  {[}\protect\hyperlink{ref-castelluccio2017a}{30}{]}
\item
  {[}\protect\hyperlink{ref-karvonen2017a}{68}{]}
\item
  {[}\protect\hyperlink{ref-claes2017a}{36}{]}
\item
  {[}\protect\hyperlink{ref-fujibayashi2017a}{54}{]}
\item
  {[}\protect\hyperlink{ref-souza2015a}{111}{]}
\item
  {[}\protect\hyperlink{ref-laukkanen2018a}{79}{]}
\end{itemize}

\begin{verbatim}
TITLE-ABS-KEY(
  (
    "continuous release"OR"rapid release"OR"frequent release"
    OR "quick release"OR"speedy release"OR"accelerated release"
    OR"agile release"OR"short release"OR"shorter release"
    OR"lightning release"OR"brisk release"OR"hasty release"
    OR"compressed release"OR"release length"OR"release size"
    OR"release cadence"OR"release frequency"
    OR "continuous delivery"OR"rapid delivery"OR"frequent delivery"
    OR"fast delivery"OR"quick delivery"OR"speedy delivery"
    OR"accelerated delivery"OR"agile delivery"OR"short delivery"
    OR"lightning delivery"OR"brisk delivery"OR"hasty delivery"
    OR"compressed delivery"OR"delivery length"OR"delivery size"
    OR"delivery cadence" OR "continuous deployment"OR"rapid deployment"
    OR"frequent deployment"OR"fast deployment"OR"quick deployment"
    OR"speedy deployment"OR"accelerated deployment"OR"agile deployment"
    OR"short deployment"OR"lightning deployment"OR"brisk deployment"
    OR"hasty deployment"OR"compressed deployment"OR"deployment length"
    OR"deployment size"OR"deployment cadence"
  ) AND (
    "release schedule"OR"release management"OR"release engineering"
    OR"release cycle"OR"release pipeline"OR"release process"
    OR"release model"OR"release strategy"OR"release strategies"
    OR "release infrastructure"
  )
  AND software
) AND (
  LIMIT-TO(SUBJAREA, "COMP") OR LIMIT-TO(SUBJAREA, "ENGI")
)
AND PUBYEAR AFT 2014
\end{verbatim}

\emph{Figure 1. Query used for retrieving release engineering
publications via Scopus.}

In addition to querying search engines as described above, references
related to retrieved papers were analyzed. These reference lists were
obtained from Google Scholar and from the \emph{References} section in
the papers themselves. We selected all papers on release engineering
that are citing or being cited by the initial set of papers. Using this
approach, we have found six additional papers. The results of the
reference analysis are listed in Table 1.

\emph{Table 1. Papers found indirectly by investigating citations of/by
other papers.}

\begin{longtable}[]{@{}lll@{}}
\toprule
Starting point & Type & Result\tabularnewline
\midrule
\endhead
{[}\protect\hyperlink{ref-souza2015a}{111}{]} & has cited &
{[}\protect\hyperlink{ref-plewnia2014a}{99}{]}
{[}\protect\hyperlink{ref-mantyla2015a}{87}{]}\tabularnewline
{[}\protect\hyperlink{ref-khomh2015a}{71}{]} & is cited by &
{[}\protect\hyperlink{ref-poo-caamano2016a}{100}{]}
{[}\protect\hyperlink{ref-teixeira2017a}{114}{]}\tabularnewline
{[}\protect\hyperlink{ref-mantyla2015a}{87}{]} & is cited by &
{[}\protect\hyperlink{ref-rodriguez2017a}{106}{]}
{[}\protect\hyperlink{ref-cesar2017a}{34}{]}\tabularnewline
\bottomrule
\end{longtable}

All the papers that were found, were stored in a custom built web-based
tool for conducting literature reviews. The source code of this tool is
published in a \href{https://github.com/jessetilro/research}{GitHub
repository}. The tool was hosted on a virtual private server, such that
all retrieved publications were stored centrally, accessible to all
reviewers.

\subsection{Study Selection}\label{study-selection}

We selected the studies that we wanted to include in the survey with aid
of the aforementioned tool for storing the papers. In this tool, it is
possible to label papers with tags and leave comments and ratings. Every
paper is reviewed based on the selection criteria. Based on this, the
tool allowed to filter out all papers that appeared not to be relevant
for this literature survey.

The selection criteria are as follows:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The study must show (at least) one release engineering technique.
\item
  The study must not just show a release engineering technique, but
  analyze its performance compared to other techniques.
\end{enumerate}

Based on these selection criteria, the following papers appeared to be
irrelevant for the scope of this survey:

\begin{itemize}
\tightlist
\item
  {[}link to paper{]} - Excluded based on rule 2.
\end{itemize}

\subsection{Study Quality Assessment}\label{study-quality-assessment}

Based on {[}\protect\hyperlink{ref-kitchenham2004procedures}{76}{]}, the
quality of a paper will be assessed by the evidence it provides, based
on the following scale. All levels of quality in this scale will be
accepted, except for level 5 (evidence obtained from expert opinion).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Evidence obtained from at least one properly-designed randomised
  controlled trial.
\item
  Evidence obtained from well-designed pseudo-randomised controlled
  trials (i.e.~non-random allocation to treatment).
\item
  Comparative studies in a real-world setting:

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \tightlist
  \item
    Evidence obtained from comparative studies with concurrent controls
    and allocation not randomised, cohort studies, case-control studies
    or interrupted time series with a control group.
  \item
    Evidence obtained from comparative studies with historical control,
    two or more single arm studies, or interrupted time series without a
    parallel control group.
  \end{enumerate}
\item
  Experiments in artificial settings:

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \tightlist
  \item
    Evidence obtained from a randomised experiment performed in an
    artificial setting.
  \item
    Evidence obtained from case series, either post-test or
    pre-test/post-test.
  \item
    Evidence obtained from a quasi-random experiment performed in an
    artificial setting.
  \end{enumerate}
\item
  Evidence obtained from expert opinion based on theory or consensus.
\end{enumerate}

Also, the studies will be examined to see if they contain any type of
bias. For this, the same types of biases will be used as described by
{[}\protect\hyperlink{ref-kitchenham2004procedures}{76}{]}:

\begin{itemize}
\tightlist
\item
  Selection/Allocation bias: Systematic difference between comparison
  groups with respect to treatment.
\item
  Performance bias: Systematic difference is the conduct of comparison
  groups apart from the treatment being evaluated.
\item
  Measurement/Detection bias: Systematic difference between the groups
  in how outcomes are ascertained.
\item
  Attrition/Exclusion bias: Systematic differences between comparison
  groups in terms of withdrawals or exclusions of participants from the
  study sample.
\end{itemize}

The studies will be labeled by their quality level and possible biases.
This information can be used during the Data Synthesis phase to weigh
the importance of individual studies
{[}\protect\hyperlink{ref-kitchenham2004procedures}{76}{]}.

\subsection{Data Extraction}\label{data-extraction}

To accurately capture the information contributed by each publication in
our survey, we will use a systematic approach to extracting data. To
guide this process, we will be using a data extraction form which
describes what aspects of a publication are crucial to record. Besides
general publication information (title, author etc.), the form contains
questions that are based on our defined research questions. Furthermore,
the form contains a section for quantitative research, where aspects
such as population and evaluation will be documented. The form that is
used for this is shown below:

\begin{verbatim}
General information:

- Name of person extracting data:
- Date form completed (dd/mm/yyyy):
- Publication title:
- Author information:
- Publication type:
- Conference/Journal:
- Type of study:

What practices in release engineering does this publication mention?

Are these practices to be classified under dated, state of the art or state of
the practice? Why?

What open challenges in release engineering does this publication mention?

What research gaps does this publication contain?

Are these research gaps filled by any other publications in this survey?

Quantitative research publications:

- Study start date:
- Study end date or duration:
- Population description:
- Method(s) of recruitment of participants:
- Sample size:
- Evaluation/measurement description:
- Outcomes:
- Limitations:
- Future research:

Notes:
\end{verbatim}

\subsection{Data Synthesis}\label{data-synthesis}

To summarize the contributions and limitations of each of the included
publications, we will apply a descriptive synthesis approach. In this
part of our survey, we will compare the data that was extracted of the
included publications. Publications with similar findings will be
grouped and evaluated, and differences between groups of publications
will be structured and elaborated on. In this we will compare them using
specifics such as their study types, time of publication and study
quality.

If the extracted data allows for a structured tabular visualization of
similarities and differences between publications this we serve as an
additional form of synthesis. However, this depends on the final
included publications of this survey.

\subsection{Included and Excluded
Studies}\label{included-and-excluded-studies}

\textbf{Included:}

\begin{itemize}
\tightlist
\item
  {[}\protect\hyperlink{ref-adams2016a}{4}{]}
\item
  \textbf{???}
\item
  {[}\protect\hyperlink{ref-cesar2017a}{34}{]}
\item
  {[}\protect\hyperlink{ref-claes2017a}{36}{]}
\item
  {[}\protect\hyperlink{ref-da2014a}{39}{]}
\item
  {[}\protect\hyperlink{ref-da2016a}{40}{]}
\item
  {[}\protect\hyperlink{ref-dyck2015a}{48}{]}
\item
  \textbf{???}
\item
  {[}\protect\hyperlink{ref-karvonen2017a}{68}{]}
\item
  {[}\protect\hyperlink{ref-kerzazi2013a}{70}{]}
\item
  {[}\protect\hyperlink{ref-khomh2015a}{71}{]}
\item
  {[}\protect\hyperlink{ref-laukkanen2018a}{79}{]}
\item
  {[}\protect\hyperlink{ref-mantyla2015a}{87}{]}
\item
  {[}\protect\hyperlink{ref-plewnia2014a}{99}{]}
\item
  {[}\protect\hyperlink{ref-poo-caamano2016a}{100}{]}
\item
  {[}\protect\hyperlink{ref-rodriguez2017a}{106}{]}
\item
  {[}\protect\hyperlink{ref-souza2015a}{111}{]}
\item
  {[}\protect\hyperlink{ref-teixeira2017a}{114}{]}
\end{itemize}

\textbf{Excluded:}

\begin{itemize}
\tightlist
\item
  {[}\protect\hyperlink{ref-khomh2012a}{72}{]} has been excluded,
  because it presents the same results as
  {[}\protect\hyperlink{ref-khomh2015a}{71}{]}, while the latter is more
  extensive because it is a journal article instead of a conference
  article.
\end{itemize}

\subsection{Project timetable}\label{project-timetable}

The literature review was conducted over the course of four weeks. We
worked iteratively and planned for four weekly milestones.

\begin{longtable}[]{@{}lll@{}}
\toprule
\begin{minipage}[b]{0.22\columnwidth}\raggedright\strut
Milestone\strut
\end{minipage} & \begin{minipage}[b]{0.18\columnwidth}\raggedright\strut
Deadline\strut
\end{minipage} & \begin{minipage}[b]{0.48\columnwidth}\raggedright\strut
Goals\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.22\columnwidth}\raggedright\strut
Milestone 1\strut
\end{minipage} & \begin{minipage}[t]{0.18\columnwidth}\raggedright\strut
16/9/18\strut
\end{minipage} & \begin{minipage}[t]{0.48\columnwidth}\raggedright\strut
- Develop the search strategy - Collect initial publications\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright\strut
Milestone 2\strut
\end{minipage} & \begin{minipage}[t]{0.18\columnwidth}\raggedright\strut
23/9/18\strut
\end{minipage} & \begin{minipage}[t]{0.48\columnwidth}\raggedright\strut
Write full research protocol\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright\strut
Milestone 3\strut
\end{minipage} & \begin{minipage}[t]{0.18\columnwidth}\raggedright\strut
30/9/18\strut
\end{minipage} & \begin{minipage}[t]{0.48\columnwidth}\raggedright\strut
- Collect additional literature according to the protocol - Perform data
extraction\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright\strut
Milestone 4\strut
\end{minipage} & \begin{minipage}[t]{0.18\columnwidth}\raggedright\strut
7/10/18\strut
\end{minipage} & \begin{minipage}[t]{0.48\columnwidth}\raggedright\strut
- Perform data synthesis - Write final version of the chapter\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\section{Answers}\label{answers-3}

\subsection{RQ1: \ldots{}}\label{rq1}

\subsection{RQ2: \ldots{}}\label{rq2}

\subsection{RQ3: \ldots{}}\label{rq3}

\section{Discussion}\label{discussion}

\section{Conclusion}\label{conclusion-1}

\section{Raw extracted data}\label{raw-extracted-data}

This section is not part of the main content of our chapter. It can be
viewed as an Appendix.

\subsection{Understanding the impact of rapid releases on software
quality -- The Case of
Firefox}\label{understanding-the-impact-of-rapid-releases-on-software-quality-the-case-of-firefox}

Reference: {[}\protect\hyperlink{ref-khomh2015a}{71}{]}

General information:

\begin{itemize}
\tightlist
\item
  Name of person extracting data: Maarten Sijm
\item
  Date form completed: 27-09-2018
\item
  Author information: Foutse Khomh, Bram Adams, Tejinder Dhaliwal, Ying
  Zou
\item
  Publication type: Paper in Conference Proceedings
\item
  Conference: Mining Software Repositories (MSR)
\item
  Type of study: Quantitative, empirical case study
\end{itemize}

What practices in release engineering does this publication mention?

\begin{itemize}
\tightlist
\item
  Changing from traditional to rapid release cycles in Mozilla Firefox
\end{itemize}

Are these practices to be classified under dated, state of the art or
state of the practice? Why?

\begin{itemize}
\tightlist
\item
  State of the practice, because they study Firefox and Firefox is still
  using rapid release cycles. However, it is dated because the data is
  six years old.
\end{itemize}

What open challenges in release engineering does this publication
mention?

\begin{itemize}
\tightlist
\item
  More case studies are needed
\end{itemize}

What research gaps does this publication contain?

\begin{itemize}
\tightlist
\item
  More case studies are needed
\end{itemize}

Are these research gaps filled by any other publications in this survey?

\begin{itemize}
\tightlist
\item
  Not yet known \textbf{TODO}
\end{itemize}

Quantitative research publications:

\begin{itemize}
\tightlist
\item
  Study start date: 01-01-2010 (Firefox 3.6)
\item
  Study end date or duration: 20-12-2011 (Firefox 9.0)
\item
  Population description: Mozilla Wiki, VCS, Crash Repository, Bug
  Repository
\item
  Method(s) of recruitment of participants: N/A (case study)
\item
  Sample size: 25 alpha versions, 25 beta versions, 29 minor versions
  and 7 major versions. Amount of bugs/commits/etc. is not specified.
\item
  Evaluation/measurement description: Wilcoxon rank sum test
\item
  Outcomes:

  \begin{itemize}
  \tightlist
  \item
    With shorter release cycles, users do not experience significantly
    more post-release bugs
  \item
    Bugs are fixed faster
  \item
    Users experience these bugs earlier during software execution (the
    program crashes earlier)
  \end{itemize}
\item
  Limitations: Results are specific to Firefox
\item
  Future research: More case studies are needed
\end{itemize}

\subsection{On the influence of release engineering on software
reputation}\label{on-the-influence-of-release-engineering-on-software-reputation}

Reference: {[}\protect\hyperlink{ref-plewnia2014a}{99}{]}

General information:

\begin{itemize}
\tightlist
\item
  Name of person extracting data: Maarten Sijm
\item
  Date form completed: 27-09-2018
\item
  Author information: Christian Plewnia, Andrej Dyck, Horst Lichter
\item
  Publication type: Paper in Conference Proceedings
\item
  Conference: 2nd International Workshop on Release Engineering
\item
  Type of study: Quantitative, empirical case study on multiple software
\end{itemize}

What practices in release engineering does this publication mention?

\begin{itemize}
\tightlist
\item
  Rapid releases
\end{itemize}

Are these practices to be classified under dated, state of the art or
state of the practice? Why?

\begin{itemize}
\tightlist
\item
  Dated practice, data is from before 2014
\end{itemize}

What open challenges in release engineering does this publication
mention?

\begin{itemize}
\tightlist
\item
  Identifying software reputation can better be done using a qualitative
  study.
\end{itemize}

What research gaps does this publication contain?

\begin{itemize}
\tightlist
\item
  Identifying software reputation can better be done using a qualitative
  study.
\end{itemize}

Are these research gaps filled by any other publications in this survey?

\begin{itemize}
\tightlist
\item
  Not yet known \textbf{TODO}
\end{itemize}

Quantitative research publications:

\begin{itemize}
\tightlist
\item
  Study start date: Q3 2008
\item
  Study end date or duration: Q4 2013
\item
  Population description: Chrome, Firefox, Internet Explorer
\item
  Method(s) of recruitment of participants: N/A (case study)
\item
  Sample size: 3 browsers
\item
  Evaluation/measurement description: No statistical analysis, just
  presenting market share results
\item
  Outcomes:

  \begin{itemize}
  \tightlist
  \item
    Chrome's market share increased after adopting rapid releases
  \item
    Firefox's market share decreased after adopting rapid releases
  \item
    IE's market share decreased
  \end{itemize}
\item
  Limitations:

  \begin{itemize}
  \tightlist
  \item
    Identifying software reputation can better be done using a
    qualitative study.
  \end{itemize}
\item
  Future research:

  \begin{itemize}
  \tightlist
  \item
    Identifying software reputation can better be done using a
    qualitative study.
  \end{itemize}
\end{itemize}

\subsection{On rapid releases and software testing: a case study and a
semi-systematic literature
review}\label{on-rapid-releases-and-software-testing-a-case-study-and-a-semi-systematic-literature-review}

Reference: {[}\protect\hyperlink{ref-mantyla2015a}{87}{]}

General information:

\begin{itemize}
\tightlist
\item
  Name of person extracting data: Maarten Sijm
\item
  Date form completed: 28-09-2018
\item
  Author information: Mntyl, Mika V. and Adams, Bram and Khomh, Foutse
  and Engstrm, Emelie and Petersen, Kai
\item
  Publication type: Journal/Magazine Article
\item
  Journal: Empirical Software Engineering
\item
  Type of study: Empirical case study and semi-systematic literature
  review
\end{itemize}

What practices in release engineering does this publication mention?

\begin{itemize}
\tightlist
\item
  Impact of rapid releases on testing effort
\end{itemize}

Are these practices to be classified under dated, state of the art or
state of the practice? Why?

\begin{itemize}
\tightlist
\item
  State of the practice for the case study
\item
  State of the art for the literature review
\end{itemize}

What open challenges in release engineering does this publication
mention?

\begin{itemize}
\tightlist
\item
  Future work should focus on empirical studies of these factors that
  complement the existing qualitative observations and perceptions of
  rapid releases.
\end{itemize}

What research gaps does this publication contain?

\begin{itemize}
\tightlist
\item
  See open challenges
\end{itemize}

Are these research gaps filled by any other publications in this survey?

\begin{itemize}
\tightlist
\item
  Not yet known \textbf{TODO}
\end{itemize}

Quantitative research publications:

\begin{itemize}
\tightlist
\item
  Study start date: June 2006 (Firefox 2.0)
\item
  Study end date or duration: June 2012 (Firefox 13.0)
\item
  Population description: System-level test execution data
\item
  Method(s) of recruitment of participants: N/A (case study)
\item
  Sample size: 1,547 unique test cases, 312,502 executions, performed by
  6,058 individuals on 2,009 software builds, 22 OS versions and 78
  locales.
\item
  Evaluation/measurement description: Wilcoxon rank-sum test, Cliff's
  delta, Cohen's Kappa for Firefox Research Question (FF-RQ) 5.
\item
  Outcomes (FF-RQs; RR = rapid release; TR = traditional release):

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    RRs perform more test executions per day, but these tests focus on a
    smaller subset of the test case corpus.
  \item
    RRs have less testers, but they have a higher workload.
  \item
    RRs test fewer, but larger builds.
  \item
    RRs test fewer platforms in total, but test each supported platform
    more thoroughly.
  \item
    RRs have higher similarity of test suites and testers within a
    release series than TRs had.
  \item
    RR testing happens closer to the release date and is more
    continuous, yet these findings were not confirmed by the QA
    engineer.
  \end{enumerate}
\item
  Limitations:

  \begin{itemize}
  \tightlist
  \item
    Study measures correlation, not causation
  \item
    Not generalizable, as it is a case study on FF
  \end{itemize}
\item
  Future research: More empirical studies
\end{itemize}

Semi-systematic literature survey:

\begin{itemize}
\tightlist
\item
  Study date: Unknown (before 2015)
\item
  Population description: Papers with main focus on:

  \begin{itemize}
  \tightlist
  \item
    Rapid Releases (RRs)
  \item
    Aspect of software engineering largely impacted by RRs
  \item
    An agile, lean or open source process having results of RRs
  \item
    Excluding: opinion papers without empirical data on RRs
  \end{itemize}
\item
  Method(s) of recruitment of participants: Scopus queries
\item
  Sample size: 24 papers
\item
  Outcomes:

  \begin{itemize}
  \tightlist
  \item
    Evidence is scarce. Often RRs are implemented as part of agile
    adoption. This makes it difficult to separate the impact of RRs from
    other process changes.
  \item
    Originates from several software development paradigms: Agile, FOSS,
    Lean, internet-speed software development
  \item
    Prevalence

    \begin{itemize}
    \tightlist
    \item
      Practiced in many software engineering domains, not just web
      applications
    \item
      Between 23\% and 83\% of practitioners do RRs
    \end{itemize}
  \item
    (Perceived) Problems:

    \begin{itemize}
    \tightlist
    \item
      Increased technical debt
    \item
      RRs are in conflict with high reliability and high test coverage
    \item
      Customers might be dipleased with RRs (many updates)
    \item
      Time-pressure / Deadline oriented work
    \end{itemize}
  \item
    (Perceived) Benefits:

    \begin{itemize}
    \tightlist
    \item
      Rapid feedback leading to increased quality focus of the devs and
      testers
    \item
      Easier monitoring of progress and quality
    \item
      Customer satisfaction
    \item
      Shorter time-to-market
    \item
      Continuous work / testing
    \end{itemize}
  \item
    Enablers:

    \begin{itemize}
    \tightlist
    \item
      Sequential development where multiple releases are under work
      simultaneously
    \item
      Tools for automated testing and efficient deployment
    \item
      Involvement of product management and productive customers
    \end{itemize}
  \end{itemize}
\item
  Limitations:

  \begin{itemize}
  \tightlist
  \item
    Not all papers that present results about RRs, have ``rapid
    release'' mentioned in the abstract.
  \end{itemize}
\item
  Future research:

  \begin{itemize}
  \tightlist
  \item
    Systematically search for agile and lean adoption papers
  \end{itemize}
\end{itemize}

Notes:

\begin{itemize}
\tightlist
\item
  Basically contains all the answers we need 
\end{itemize}

\subsection{Release management in free and open source software
ecosystems}\label{release-management-in-free-and-open-source-software-ecosystems}

Reference: {[}\protect\hyperlink{ref-poo-caamano2016a}{100}{]}

General information:

\begin{itemize}
\tightlist
\item
  Name of person extracting data: Maarten Sijm
\item
  Date form completed: 28-09-2018
\item
  Author information: Germn Poo-Caamao
\item
  Publication type: PhD Thesis
\item
  Type of study: Empirical case study on two large-scale FOSSs: GNOME
  and OpenStack
\end{itemize}

What practices in release engineering does this publication mention?

\begin{itemize}
\tightlist
\item
  Communication in release engineering
\end{itemize}

Are these practices to be classified under dated, state of the art or
state of the practice? Why?

\begin{itemize}
\tightlist
\item
  State of the practice, because case study
\end{itemize}

What open challenges in release engineering does this publication
mention?

\begin{itemize}
\tightlist
\item
  Is the ecosystem {[}around the studied software{]} shrinking or
  expanding?
\item
  How have communications in the ecosystem changed over time?
\end{itemize}

What research gaps does this publication contain?

\begin{itemize}
\tightlist
\item
  More case studies are needed
\end{itemize}

Are these research gaps filled by any other publications in this survey?

\begin{itemize}
\tightlist
\item
  Not yet known \textbf{TODO}
\end{itemize}

Quantitative research publications (GNOME):

\begin{itemize}
\tightlist
\item
  Study start date: January 2009 (GNOME 2.x)
\item
  Study end date or duration: August 2011 (GNOME 3.x)
\item
  Population description: Mailing lists
\item
  Method(s) of recruitment of participants: GNOME's website recommends
  this channel of communication. IRC is also recommended, but its
  history is not stored.
\item
  Sample size: 285 mailing lists, 6947 messages, grouped into 945
  discussions.
\item
  Evaluation/measurement description: Counting
\item
  Outcomes:

  \begin{itemize}
  \tightlist
  \item
    Developers also communicate via blogs, bug trackers, conferences,
    and hackfests.
  \item
    The Release Team has direct contact with almost all participants in
    the mailing list
  \item
    The tasks of the Release Team:

    \begin{itemize}
    \tightlist
    \item
      defining requirements of GNOME releases
    \item
      coordinating and communicating with projects and teams
    \item
      shipping a release within defined quality and time specifications
    \end{itemize}
  \item
    Major challenges of the Release Team:

    \begin{itemize}
    \tightlist
    \item
      coordinate projects and teams of volunteers without direct power
      over them
    \item
      keep the build process manageable
    \item
      monitor for unplanned changes
    \item
      monitor for changes during the stabilization phase
    \item
      test the GNOME release
    \end{itemize}
  \end{itemize}
\item
  Limitations:

  \begin{itemize}
  \tightlist
  \item
    Only mailing list was investigated, other channels were not
  \item
    Possible subjective bias in manually categorizing email subjects
  \item
    Not very generalizable, as it's just one case study
  \end{itemize}
\item
  Future research:

  \begin{itemize}
  \tightlist
  \item
    Fix the limitations
  \end{itemize}
\end{itemize}

Quantitative research publications (OpenStack):

\begin{itemize}
\tightlist
\item
  Study start date: May 2012
\item
  Study end date or duration: July 2014
\item
  Population description: Mailing lists
\item
  Method(s) of recruitment of participants: Found on OpenStack's website
\item
  Sample size: 47 mailing lists, 24,643 messages, grouped into 7,650
  discussions. Filtered data: 14,486 messages grouped into 2,682
  discussions.
\item
  Evaluation/measurement description: Counting
\item
  Outcomes:

  \begin{itemize}
  \tightlist
  \item
    Developers communicate via email, blogs, launchpad, wiki, gerrit,
    face-to-face, IRC, video-conferences, and etherpad.
  \item
    Project Team Leaders and the Release Team members are the key
    players in the communication and coordination across projects in the
    context of release management
  \item
    The tasks for the Release Team and Project Team Leaders:

    \begin{itemize}
    \tightlist
    \item
      defining the requirements of an OpenStack release
    \item
      coordinating and communicating with projects and teams to reach
      the objectives of each milestone
    \item
      coordinating feature freeze exceptions at the end of a release
    \item
      shipping a release within defined quality and time specifications
    \end{itemize}
  \item
    Major challenges of these teams:

    \begin{itemize}
    \tightlist
    \item
      coordinate projects and teams without direct power over them
    \item
      keep everyone informed and engaged
    \item
      decide what becomes part of of the integrated release
    \item
      monitor changes
    \item
      set priorities in cross-project coordination
    \item
      overcome limitations of the communication infrastructure
    \end{itemize}
  \end{itemize}
\item
  Limitations:

  \begin{itemize}
  \tightlist
  \item
    Only studies mailing list, to compare with GNOME case study
  \item
    Possible subjective bias in manually categorizing email subjects
  \item
    Not very generalizable, as it's just one case study
  \end{itemize}
\item
  Future research:

  \begin{itemize}
  \tightlist
  \item
    Fix the limitations
  \end{itemize}
\end{itemize}

Notes:

\begin{itemize}
\tightlist
\item
  Since there are two case studies, the results become a bit more
  generalizable
\item
  The author set up a theory that encapsulates the communication and
  coordination regarding release management in FOSS ecosystems, and can
  be summarized as:

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    The size and complexity of the integrated product is constrained by
    the release managers capacity
  \item
    The release management should reach the whole ecosystem to increase
    awareness and participation
  \item
    The release managers need social and technical skills
  \end{enumerate}
\end{itemize}

\subsection{Release Early, Release Often and Release on Time. An
Empirical Case Study of Release
Management}\label{release-early-release-often-and-release-on-time.-an-empirical-case-study-of-release-management}

Reference: {[}\protect\hyperlink{ref-teixeira2017a}{114}{]}

General information:

\begin{itemize}
\tightlist
\item
  Name of person extracting data: Maarten Sijm
\item
  Date form completed: 28-09-2018
\item
  Author information: Jose Teixeira
\item
  Publication type: Paper in Conference Proceedings
\item
  Conference: Open Source Systems: Towards Robust Practices
\item
  Type of study: Empirical case study
\end{itemize}

What practices in release engineering does this publication mention?

\begin{itemize}
\tightlist
\item
  Shifting towards rapid releases in OpenStack
\end{itemize}

Are these practices to be classified under dated, state of the art or
state of the practice? Why?

\begin{itemize}
\tightlist
\item
  State of the practice, because it is a recent case study on OpenStack
\end{itemize}

What open challenges in release engineering does this publication
mention?

\begin{itemize}
\tightlist
\item
  More case studies are needed.
\end{itemize}

What research gaps does this publication contain?

\begin{itemize}
\tightlist
\item
  More case studies are needed.
\end{itemize}

Are these research gaps filled by any other publications in this survey?

\begin{itemize}
\tightlist
\item
  Not yet known \textbf{TODO}
\end{itemize}

Quantitative research publications:

\begin{itemize}
\tightlist
\item
  Study start date: Not specified
\item
  Study end date or duration: Not specified
\item
  Population description: Websites and blogs
\item
  Method(s) of recruitment of participants: Random clicking through
  OpenStack websites
\item
  Sample size: Not specified
\item
  Evaluation/measurement description: Not specified
\item
  Outcomes:

  \begin{itemize}
  \tightlist
  \item
    OpenStack releases in a cycle of six months
  \item
    The release management process is a hybrid of feature-based and
    time-based
  \item
    Having a time-based release strategy is a challenging coopearative
    task involving multiple people and technology
  \end{itemize}
\item
  Limitations:

  \begin{itemize}
  \tightlist
  \item
    Study is not completed yet, these are preliminary results
  \end{itemize}
\item
  Future research:

  \begin{itemize}
  \tightlist
  \item
    Not indicated
  \end{itemize}
\end{itemize}

\subsection{Kanbanize the release engineering
process}\label{kanbanize-the-release-engineering-process}

Reference: {[}\protect\hyperlink{ref-kerzazi2013a}{70}{]}

General information:

\begin{itemize}
\tightlist
\item
  Name of person extracting data: Jesse Tilro
\item
  Date form completed: 29-09-2018
\item
  Author information: Kerzazi, N. and Robillard, P.N.
\item
  Publication type: Paper in Conference Proceedings
\item
  Journal: 2013 1st International Workshop on Release Engineering,
  RELENG 2013 - Proceedings
\item
  Type of study: Action research
\end{itemize}

What practices in release engineering does this publication mention?

\begin{itemize}
\tightlist
\item
  Following principles of the Kanban agile software development
  life-cycle model that implicitly describe the release process
\item
  (Switching to) more frequent (daily) release cycles
\item
  (Transitioning to) a structured release process
\end{itemize}

Are these practices to be classified under dated, state of the art or
state of the practice? Why?

\begin{itemize}
\tightlist
\item
  Either dated or state of the practice, not sure. Would have to do some
  additional research on the adoption of Kanban
\end{itemize}

What open challenges in release engineering does this publication
mention?

\begin{itemize}
\tightlist
\item
  Release effectiveness: minimize system failure and customer impact
\item
  Problems with releasing encountered in practice

  \begin{itemize}
  \tightlist
  \item
    \textbf{TODO} list problems if of interest
  \end{itemize}
\end{itemize}

What research gaps does this publication contain?

\begin{itemize}
\item
\end{itemize}

Are these research gaps filled by any other publications in this survey?

\begin{itemize}
\item
\end{itemize}

Quantitative research publications:

\begin{itemize}
\item
  Study start date:
\item
  Study end date or duration:
\item
  Population description:
\item
  Method(s) of recruitment of participants:
\item
  Sample size:
\item
  Evaluation/measurement description:
\item
  Outcomes:

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \item
  \end{enumerate}
\item ~
  \section{Limitations:}\label{limitations}
\item
  Future research:
\end{itemize}

Notes:

\begin{itemize}
\item
\end{itemize}

\subsection{Is it safe to uplift this patch? An empirical study on
mozilla
firefox}\label{is-it-safe-to-uplift-this-patch-an-empirical-study-on-mozilla-firefox}

Reference: {[}\protect\hyperlink{ref-castelluccio2017a}{30}{]}

General information:

\begin{itemize}
\tightlist
\item
  Name of person extracting data: Jesse Tilro
\item
  Date form completed: 29-09-2018
\item
  Author information: Castelluccio, M. and An, L. and Khomh, F.
\item
  Publication type: Paper in Conference Proceedings
\item
  Journal: Proceedings - 2017 IEEE International Conference on Software
  Maintenance and Evolution, ICSME 2017
\item
  Type of study: Case study, both quantitative (data analysis) and
  qualitative (interviews)
\end{itemize}

What practices in release engineering does this publication mention?

\begin{itemize}
\tightlist
\item
  Patch uplift (meaning the promotion of patches from development
  directly to a stabilization channel, potentially skipping several
  channels)
\end{itemize}

Are these practices to be classified under dated, state of the art or
state of the practice? Why?

\begin{itemize}
\tightlist
\item
  State of the practice: case study of what is being done in the field,
  quite recently (2017).
\end{itemize}

What open challenges in release engineering does this publication
mention?

\begin{itemize}
\tightlist
\item
  Exploring possibilities to leverage this research by building
  classifiers capable of automatically assessing the risk associated
  with patch uplift candidates and recommend patches that can be
  uplifted safely.
\item
  Validate and extend results of this study for generalizability.
\end{itemize}

What research gaps does this publication contain?

\begin{itemize}
\tightlist
\item
  Study aimed to fill two identified gaps identified in literature:

  \begin{itemize}
  \tightlist
  \item
    How do urgent patches in rapid release models affect software
    quality (in terms of fault proneness)?
  \item
    How can the reliability of the integration of urgent patches be
    improved?
  \end{itemize}
\end{itemize}

Are these research gaps filled by any other publications in this survey?

\begin{itemize}
\tightlist
\item
  The paper itself
\end{itemize}

Quantitative research publications:

\begin{itemize}
\tightlist
\item
  Study start date:
\item
  Study end date or duration:
\item
  Population description:
\item
  Method(s) of recruitment of participants:
\item
  Sample size:
\item
  Evaluation/measurement description:
\item
  Outcomes:

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \item
  \end{enumerate}
\item
  Limitations:
\item
  Future research:
\end{itemize}

Notes:

\begin{itemize}
\item
\end{itemize}

\subsection{Systematic literature review on the impacts of agile release
engineering
practices}\label{systematic-literature-review-on-the-impacts-of-agile-release-engineering-practices}

Reference: {[}\protect\hyperlink{ref-karvonen2017a}{68}{]}

General information:

\begin{itemize}
\tightlist
\item
  Name of person extracting data: Jesse Tilro
\item
  Date form completed: 29-09-2018
\item
  Author information: Karvonen, T. and Behutiye, W. and Oivo, M. and
  Kuvaja, P.
\item
  Publication type: Journal/Magazine Article
\item
  Journal: Information and Software Technology
\item
  Type of study: Systematic literature review
\end{itemize}

What practices in release engineering does this publication mention?

\begin{itemize}
\tightlist
\item
  Agile release engineering (ARE) practices

  \begin{itemize}
  \tightlist
  \item
    Continuous integration (CI)
  \item
    Continuous delivery (CD)
  \item
    Rapid Release (RR)
  \item
    Continuous deployment
  \item
    DevOps (similar to CD, congruent with release engineering practices)
  \end{itemize}
\end{itemize}

Are these practices to be classified under dated, state of the art or
state of the practice? Why?

\begin{itemize}
\tightlist
\item
  State of the art, for it concerns a state of the art report and was
  published recently (2017).
\end{itemize}

What open challenges in release engineering does this publication
mention?

\begin{itemize}
\tightlist
\item
  Claims that modern release engineering practices allow for software to
  be delivered faster and cheaper should be further empirically
  validated.
\item
  This analysis could be extended with industry case studies, to develop
  a checklist for analyzing company and ecosystem readiness for
  continuous delivery and continuous deployment.
\item
  The comprehensive reporting of the context and how the practice is
  implemented instead of merely referring to usage of the practice
  should be considered by future research.
\item
  Different stakeholders' points of view, such as customer perceptions
  regarding practices require further research.
\item
  Research on DevOps would be highly relevant for release engineering
  and the continuous software engineering research domain.
\item
  Future research on the impact of RE practices could benefit from more
  extensive use of quantitative methodologies from case studies, and the
  combination of quantitative with qualitative (e.g.~interviews)
  methods.
\end{itemize}

What research gaps does this publication contain?

\begin{itemize}
\tightlist
\item
  Refer to challenges
\end{itemize}

Are these research gaps filled by any other publications in this survey?

\begin{itemize}
\tightlist
\item
  \textbf{TODO}
\end{itemize}

Quantitative research publications:

\begin{itemize}
\tightlist
\item
  Study start date: N/A
\item
  Study end date or duration: N/A
\item
  Population description: N/A
\item
  Method(s) of recruitment of participants: N/A
\item
  Sample size: N/A
\item
  Evaluation/measurement description: N/A
\item
  Outcomes: N/A
\item
  Limitations: N/A
\item
  Future research: N/A
\end{itemize}

Notes:

\begin{itemize}
\item
\end{itemize}

\subsection{Abnormal Working Hours: Effect of Rapid Releases and
Implications to Work
Content}\label{abnormal-working-hours-effect-of-rapid-releases-and-implications-to-work-content}

Reference: {[}\protect\hyperlink{ref-claes2017a}{36}{]}

General information:

\begin{itemize}
\tightlist
\item
  Name of person extracting data: Jesse Tilro
\item
  Date form completed: 29-09-2018
\item
  Author information: Claes, M. and Mantyla, M. and Kuutila, M. and
  Adams, B.
\item
  Publication type: Paper in Conference Proceedings
\item
  Journal: IEEE International Working Conference on Mining Software
  Repositories
\item
  Type of study: Quantitative case study
\end{itemize}

What practices in release engineering does this publication mention?

\begin{itemize}
\tightlist
\item
  Faster release cycles
\end{itemize}

Are these practices to be classified under dated, state of the art or
state of the practice? Why?

\begin{itemize}
\item
\end{itemize}

What open challenges in release engineering does this publication
mention?

\begin{itemize}
\tightlist
\item
  Future research might further study the impact of time pressure and
  work patterns - indirectly release practices - on software developers.
\end{itemize}

What research gaps does this publication contain?

\begin{itemize}
\item
\end{itemize}

Are these research gaps filled by any other publications in this survey?

\begin{itemize}
\item
\end{itemize}

Quantitative research publications:

\begin{itemize}
\tightlist
\item
  Study start date: first data item 2012-12-21
\item
  Study end date or duration: last data item 2016-01-03
\item
  Population description: N/A
\item
  Method(s) of recruitment of participants: N/A
\item
  Sample size: 145691 bug tracker contributors (1.8\% timezone), 11.11
  million comments (53\% author with timezone)
\item
  Evaluation/measurement description: measure distributions on number of
  comments per day of the week and time of the day, before and after
  transition to rapid release cycles. Test distribution difference using
  Mann-Whitney U test and test effect size using Cohen's d and Cliff's
  delta. Also evaluate general development of number of comments,
  working day against weekend and day against night.
\item
  Outcomes:

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    Switching to rapid releases has reduced the amount of work performed
    outside of office hours. (Supported by results in psychology.)
  \item
    Thus, rapid release cycles seem to have a positive effect on
    occupational health.
  \item
    Comments posted during the weekend contained more technical terms.
  \item
    Comments posted during weekdays contained more positive and polite
    vocabulary.
  \end{enumerate}
\item
  Limitations:
\item
  Future research:
\end{itemize}

Notes:

\begin{itemize}
\item
\end{itemize}

\subsection{Does the release cycle of a library project influence when
it is adopted by a client
project?}\label{does-the-release-cycle-of-a-library-project-influence-when-it-is-adopted-by-a-client-project}

Reference: {[}\protect\hyperlink{ref-fujibayashi2017a}{54}{]}

General information:

\begin{itemize}
\tightlist
\item
  Name of person extracting data: Jesse Tilro
\item
  Date form completed: 29-09-2018
\item
  Author information: Fujibayashi, D. and Ihara, A. and Suwa, H. and
  Kula, R.G. and Matsumoto, K.
\item
  Publication type: Paper in Conference Proceedings
\item
  Journal: SANER 2017 - 24th IEEE International Conference on Software
  Analysis, Evolution, and Reengineering
\item
  Type of study: Quantitative study
\end{itemize}

What practices in release engineering does this publication mention?

\begin{itemize}
\tightlist
\item
  Rapid release cycles
\end{itemize}

Are these practices to be classified under dated, state of the art or
state of the practice? Why?

\begin{itemize}
\tightlist
\item
  State of the art and practice: practitioners currently practice it,
  researchers currently research it.
\end{itemize}

What open challenges in release engineering does this publication
mention?

\begin{itemize}
\tightlist
\item
  Gaining an understanding of the effect of a library's release cycle on
  its adoption.
\end{itemize}

What research gaps does this publication contain?

\begin{itemize}
\tightlist
\item
  First step towards solving the above challenge.
\end{itemize}

Are these research gaps filled by any other publications in this survey?

\begin{itemize}
\tightlist
\item
  This paper
\end{itemize}

Quantitative research publications:

\begin{itemize}
\tightlist
\item
  Study start date: 21-07-2016 (data extraction)
\item
  Study end date or duration:
\item
  Population description:
\item
  Method(s) of recruitment of participants:
\item
  Sample size: 23 libraries, 415 client projects
\item
  Evaluation/measurement description:
\item
  Scott-Knott test to group libraries with similar release cycle.
\item
  Outcomes:

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    There is a relationship between release cycle of a library project
    and the time for clients to adopt it: quicker release seems to be
    associated with quicker adoption.
  \end{enumerate}
\item
  Limitations:

  \begin{itemize}
  \tightlist
  \item
    Small sample size
  \item
    Not controlled for many factors
  \item
    No statistical significance tests?
  \end{itemize}
\item
  Future research:
\end{itemize}

Notes:

\begin{itemize}
\tightlist
\item
  Very short, probably not very strong evidence, refer to limitations
\item
  Nice that the focus is libraries here, very interesting population
  because most studies focus on end-user targeting software systems
\end{itemize}

\subsection{Rapid releases and patch backouts: A software analytics
approach}\label{rapid-releases-and-patch-backouts-a-software-analytics-approach}

Reference: {[}\protect\hyperlink{ref-souza2015a}{111}{]}

General information:

\begin{itemize}
\tightlist
\item
  Name of person extracting data: Jesse Tilro
\item
  Date form completed: 29-09-2018
\item
  Author information: Souza, R. and Chavez, C. and Bittencourt, R.A.
\item
  Publication type: Journal/Magazine Article
\item
  Journal: IEEE Software
\item
  Type of study: Quantitative
\end{itemize}

What practices in release engineering does this publication mention?

\begin{itemize}
\item
\end{itemize}

Are these practices to be classified under dated, state of the art or
state of the practice? Why?

\begin{itemize}
\item
\end{itemize}

What open challenges in release engineering does this publication
mention?

\begin{itemize}
\tightlist
\item
  How rapid release cycles affect code integration
\end{itemize}

What research gaps does this publication contain?

\begin{itemize}
\item
\end{itemize}

Are these research gaps filled by any other publications in this survey?

\begin{itemize}
\item
\end{itemize}

Quantitative research publications:

\begin{itemize}
\tightlist
\item
  Study start date:
\item
  Study end date or duration:
\item
  Population description:
\item
  Method(s) of recruitment of participants:
\item
  Sample size:
\item
  Evaluation/measurement description:
\item
  Outcomes:

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \item
  \end{enumerate}
\item
  Limitations:
\item
  Future research:
\end{itemize}

Notes:

\begin{itemize}
\tightlist
\item
  Also reviews existing literature very well
\end{itemize}

\subsection{Comparison of release engineering practices in a large
mature company and a
startup}\label{comparison-of-release-engineering-practices-in-a-large-mature-company-and-a-startup}

Reference: {[}\protect\hyperlink{ref-laukkanen2018a}{79}{]}

General information:

\begin{itemize}
\tightlist
\item
  Name of person extracting data: Jesse Tilro
\item
  Date form completed: 29-09-2018
\item
  Author information: Laukkanen, E. and Paasivaara, M. and Itkonen, J.
  and Lassenius, C.
\item
  Publication type: Journal/Magazine Article
\item
  Journal: Empirical Software Engineering
\item
  Type of study:
\end{itemize}

What practices in release engineering does this publication mention?

\begin{itemize}
\item
\end{itemize}

Are these practices to be classified under dated, state of the art or
state of the practice? Why?

\begin{itemize}
\item
\end{itemize}

What open challenges in release engineering does this publication
mention?

\begin{itemize}
\item
\end{itemize}

What research gaps does this publication contain?

\begin{itemize}
\item
\end{itemize}

Are these research gaps filled by any other publications in this survey?

\begin{itemize}
\item
\end{itemize}

Quantitative research publications:

\begin{itemize}
\item
  Study start date:
\item
  Study end date or duration:
\item
  Population description:
\item
  Method(s) of recruitment of participants:
\item
  Sample size:
\item
  Evaluation/measurement description:
\item
  Outcomes:

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \item
  \end{enumerate}
\item ~
  \section{Limitations:}\label{limitations-1}
\item
  Future research:
\end{itemize}

Notes:

\begin{itemize}
\item
\end{itemize}

\subsection{Modern Release Engineering in a
Nutshell}\label{modern-release-engineering-in-a-nutshell}

Reference: {[}\protect\hyperlink{ref-adams2016a}{4}{]}

General information:

\begin{itemize}
\tightlist
\item
  Name of person extracting data: Nels Numan
\item
  Date form completed (dd/mm/yyyy): 28/09/2018
\item
  Publication title: Modern Release Engineering in a Nutshell
\item
  Author information: Bram Adams and Shane McIntosh
\item
  Journal: 23rd International Conference on Software Analysis,
  Evolution, and Reengineering (2016)
\item
  Publication type: Conference paper
\item
  Type of study: Survey
\end{itemize}

What practices in release engineering does this publication mention?

\begin{itemize}
\tightlist
\item
  Branching and merging

  \begin{itemize}
  \tightlist
  \item
    Software teams rely on Version Control Systems
  \item
    Quality assurance activities like code reviews are used before doing
    a merge or even allowing a code change to be committed into a branch
  \item
    Keep branches short-lived and merge often. If this is impossible, a
    rebase can be done.
  \item
    ``trunk-based development'' can be applied to eliminate most
    branches below the master branch.
  \item
    Feature toggles are used to provide isolation for new features in
    case of the absence of branches.
  \end{itemize}
\item
  Building and testing

  \begin{itemize}
  \tightlist
  \item
    To help assess build and test conflicts, many projects also provide
    ``try'' servers to development teams, which automatically runs a
    build and test process referred to as CI.
  \item
    The CI process often does not run full test, but a representative
    subset.
  \item
    The more intensive tests, such as integration, system or performance
    typically get run nightly or in weekends.
  \end{itemize}
\item
  Build system:

  \begin{itemize}
  \tightlist
  \item
    GNU Make is the most popular file-based build system technology. Ant
    is the prototypical task-based build system technology.
    Lifecycle-based build technologies like Maven consider the build
    system of a project to have a sequence of standard build activities
    that together form a ``build lifecycle.''
  \item
    ``Reproducible builds'' involve for a given feature and hardware
    configuration of the code base, every build invoca- tion should
    yield bit-to-bit identical build results.
  \end{itemize}
\item
  Infrastructure-as-code

  \begin{itemize}
  \tightlist
  \item
    Containers or virtual machines are used to deploy new versions of
    the system for testing or even production.
  \item
    It has been recommended that infrastructure code is to be stored in
    a separate VCS repository than source code, in order to restrict
    access to infrastructure code.
  \end{itemize}
\item
  Deployment

  \begin{itemize}
  \tightlist
  \item
    The term ``dark launching'' corresponds to deploying new features
    without releasing them to the public, in which parts of the system
    automatically make calls to the hidden features in a way invisible
    to end users.
  \item
    ``Blue green deployment'' deploys the next software version on a
    copy of the production environment, and changes this to be the main
    enviroment on release.
  \item
    In ``canary deployment'' a prospective release of the software
    system is loaded onto a subset of the production environments for
    only a subset of users.
  \item
    ``A/B testing'' deploys alternative A of a feature to the
    environment of a subset of the user base, while alternative B is
    deployed to the environment of another subset.
  \end{itemize}
\item
  Release

  \begin{itemize}
  \tightlist
  \item
    Once a deployed version of a system is released, the release
    engineers monitor telemetry data and crash logs to track the
    performance and quality of releases. Several frameworks and
    applications have been introduced for this.
  \end{itemize}
\end{itemize}

Are these practices to be classified under dated, state of the art or
state of the practice? Why?

\begin{itemize}
\tightlist
\item
  The majority of these practices are classified by the paper as state
  of the practice, but state of the art practices are also mentioned.
\end{itemize}

What open challenges in release engineering does this publication
mention?

\begin{itemize}
\tightlist
\item
  Branching and merging

  \begin{itemize}
  \tightlist
  \item
    No methodology or insight exists on how to empirically validate the
    best branching structure for a given organization or project, and
    what results in the smallest amount of merge conflicts.
  \item
    Release engineers need to pay particular attention to conflicts and
    incompatibilities caused by evolving library and API dependencies.
  \end{itemize}
\item
  Building and testing

  \begin{itemize}
  \tightlist
  \item
    Speeding up CI might be the major concern of practitioners. This
    speed up can be achieved through predicting whether a code change
    will break the build, or by ``chunking'' code changes into a group
    and only compile and test each group once.
  \item
    The concept of ``green builds'' slowly is becoming an issue, in the
    sense that frequent triggering of the CI server consumes energy.
  \item
    Security of the release engineering pipeline in general, and the CI
    server in particular, also has become a major concern.
  \end{itemize}
\item
  Release

  \begin{itemize}
  \tightlist
  \item
    Qualitative studies are not only essential to understand the
    rationale behind quantitative findings, but also to identify design
    patterns and best practices for build systems.

    \begin{itemize}
    \tightlist
    \item
      How can developers make their builds more maintainable and of
      higher quality?
    \item
      What refactorings should be performed for which build system
      anti-patterns?
    \end{itemize}
  \item
    Identification and resolution of build bugs, i.e., source code or
    build specification changes that cause build breakage, possibly on a
    subset of the supported platforms.
  \item
    Basic tools have a hard time determining what part of the system is
    necessary to build.
  \item
    Studies on non-GNU Make build systems are missing.
  \item
    Apart from identifying bottlenecks, such approaches should also
    suggest concrete refactorings of the build system specifications or
    source code.
  \end{itemize}
\item
  Infrastructure-as-code

  \begin{itemize}
  \tightlist
  \item
    Research on differences between infrastructure languages is lacking.
  \item
    Best practices and design patterns for infrastructure-as-code need
    to be documented.
  \item
    Qualitative analysis of infrastructure code will be necessary to
    understand how developers address different infrastructure needs.
  \item
    Quantitative analysis of the version control and bug report systems
    can then help to determine which patterns were beneficial in terms
    of maintenance effort and/or quality.
  \end{itemize}
\item
  Deployment

  \begin{itemize}
  \tightlist
  \item
    More emperical studies can be done to answer question like this:

    \begin{itemize}
    \tightlist
    \item
      Is blue-green deployment the fastest means to deploy a new version
      of a web app?
    \item
      Are A/B testing and dark launching worth the investment and risk?
    \item
      Should one use containers or virtual machines for a medium-sized
      web app in order to meet application performance and robustness
      criteria?
    \item
      If an app is part of a suite of apps built around a common
      database, should each app be deployed in a different container?
    \end{itemize}
  \item
    Better tools for quality assurance are required, to prevent
    showstopper bugs from slipping through and requiring re-deployment
    of a mobile app version (with corresponding vetting), these include:

    \begin{itemize}
    \tightlist
    \item
      Defect prediction (either file- or commit-based)
    \item
      Smarter/safer update mechanisms
    \item
      Tools for improving code review
    \item
      Generating tests
    \item
      Filtering and interpreting crash reports
    \item
      Prioritization and triaging of defect reports
    \end{itemize}
  \end{itemize}
\item
  Release

  \begin{itemize}
  \tightlist
  \item
    More research is needed on determining which code change is the
    perfect one for triggering the release of one of these releases, or
    whether a canary is good enough to be released to another data
    centre.
  \item
    Question such as the following should be investigated:

    \begin{itemize}
    \tightlist
    \item
      Should one release on all platforms at the same time?
    \item
      In the case of defects, which platform should receive priority?
    \item
      Should all platforms use the same version numbering, or should
      that be feature-dependent?
    \item
      Research on the continuous delivery and rapid releases from other
      systems should be explored.
    \end{itemize}
  \end{itemize}
\end{itemize}

What research gaps does this publication contain?

\begin{itemize}
\tightlist
\item
  As is common with surveys, it does not contain the state of the field
  today. More quantitive and qualitive research has been done, which can
  not possibly be included.
\end{itemize}

Are these research gaps filled by any other publications in this survey?

\begin{itemize}
\tightlist
\item
  An example of further research that expand on this study is
  {[}\protect\hyperlink{ref-da2016a}{40}{]}
\end{itemize}

\subsection{The Impact of Switching to a Rapid Release Cycle on the
Integration Delay of Addressed
Issues}\label{the-impact-of-switching-to-a-rapid-release-cycle-on-the-integration-delay-of-addressed-issues}

Reference: {[}\protect\hyperlink{ref-da2016a}{40}{]}

General information:

\begin{itemize}
\tightlist
\item
  Name of person extracting data: Nels Numan
\item
  Date form completed (dd/mm/yyyy): 28/09/2018
\item
  Publication title: The Impact of Switching to a Rapid Release Cycle on
  the Integration Delay of Addressed Issues
\item
  Author information: Daniel Alencar da Costa, Shane McIntosh, Uira
  Kulesza, Ahmed E. Hassan
\item
  Journal: 13th Working Conference on Mining Software Repositories
  (2016)
\item
  Publication type: Conference paper
\item
  Type of study: Emperical study
\end{itemize}

What practices in release engineering does this publication mention?

\begin{itemize}
\tightlist
\item
  To give a context to the study, the paper describes the concept of
  traditional releases, rapid releases, their differences, and how issue
  reports are structured.
\end{itemize}

Are these practices to be classified under dated, state of the art or
state of the practice? Why?

\begin{itemize}
\tightlist
\item
  State of the practice. The paper describes common practices that were
  in use at the time of the publication.
\end{itemize}

What open challenges in release engineering does this publication
mention?

\begin{itemize}
\tightlist
\item
  The study mentions that comparing systems with different release
  structures is difficult since one has to distinguish to what extent
  the results are due to the release strategy and which are due to
  intricacies of the systems or organization itself.
\end{itemize}

What research gaps does this publication contain?

\begin{itemize}
\tightlist
\item
  The main gap in this study is the specificity of the data. Only
  Mozilla has been considered, and external factors such as other
  organizational challenges which could have an effect on release time
  could not be included. More research that looks further into comparing
  this case to that of other organizations is needed.
\end{itemize}

Are these research gaps filled by any other publications in this survey?

\begin{itemize}
\item
\end{itemize}

Quantitative research publications:

\begin{itemize}
\tightlist
\item
  Study start date: Used data starts from 1999
\item
  Study end date or duration: Used data ends in 2010
\item
  Population description: The paper describes multiple steps to describe
  their data collection approach. The paper collected the date and
  version number of each Firefox release. Tags within the VCS were used
  to link issue IDs to releases. The paper discards issues that are
  potential false positives: IDs that have less five digits, issues that
  refer to tests instead of bugfixes, any potential ID that is the name
  of a file. Since the commit logs are linked to the VCS tags, the paper
  is able to link the issue IDs found within these commit logs to the
  releases that correspond to those tags.
\item
  Method(s) of recruitment of participants: Firefox release history wiki
  and VCS logs
\item
  Sample size: 72114 issue reports from the Firefox system (34673 for
  traditional releases and 37441 for rapid releases)
\item
  Evaluation/measurement description: The paper aims to answer three
  research questions:

  \begin{itemize}
  \tightlist
  \item
    Are addressed issues integrated more quickly in rapid releases?

    \begin{itemize}
    \tightlist
    \item
      Approach: Through beanplots to compare the distributions, the
      paper first observes the lifetime of the issues of traditional and
      rapid releases. Next, it looks at the time span of the triaging,
      fixing, and integration phases within the lifetime of an issue.
    \end{itemize}
  \item
    Why can traditional releases integrate addressed issues more
    quickly?

    \begin{itemize}
    \tightlist
    \item
      Approach: the paper groups traditional and rapid releases into
      major and minor releases and study their integration delay through
      beanplots, Mann-Whiteney-Wilcoxon tests, Cliff's delta, and MAD.
    \end{itemize}
  \item
    Did the change in the release strategy have an impact on the
    characteristics of delayed issues?

    \begin{itemize}
    \tightlist
    \item
      Approach: the paper builds linear regression models for both
      release approaches. The paper firstly estimates the degrees of
      freedom that can be spent on the models. Secondly, they check for
      metrics that are highly correlated using Spearman rank correlation
      tests and perform a redundancy check to remove redundant metrics.
      The paper then assesses the fit of our models using the ROC area
      and the Brier score. The ROC area is used to evaluate the degree
      of discrimination achieved by the model. The Brier score is used
      to evaluate the accuracy of probabilistic predictions. The used
      metrics include reporter experience, resolver experience, issue
      severity, issue priority, project queue rank, number of impacted
      files and fix time. A full list of metrics can be found in Table 2
      of the paper.
    \end{itemize}
  \end{itemize}
\item
  Outcomes:

  \begin{itemize}
  \tightlist
  \item
    Are addressed issues integrated more quickly in rapid releases?

    \begin{itemize}
    \tightlist
    \item
      Results: There is no significant difference between traditional
      and rapid releases regarding issue lifetime. Results:
    \end{itemize}
  \item
    Why can traditional releases integrate addressed issues more
    quickly?

    \begin{itemize}
    \tightlist
    \item
      Results: Minor-traditional releases tend to have less integration
      delay than major/minor-rapid releases.
    \end{itemize}
  \item
    Did the change in the release strategy have an impact on the
    characteristics of delayed issues?

    \begin{itemize}
    \tightlist
    \item
      Results: The models achieve a Brier score of 0.05- 0.16 and ROC
      areas of 0.81-0.83. Traditional releases prioritize the
      integration of backlog issues, while rapid releases prioritize the
      inte- gration of issues of the current release cycle.
    \end{itemize}
  \end{itemize}
\item
  Limitations: Defects in the tools that were developed to perform the
  data collection and evaluation could have an effect on the outcomes.
  Furthermore, the way that issue IDs are linked to releases may not
  represent the total addressed issues per release. The results cannot
  be generalized as the evaluation was solely done on the Firefox
  system.
\item
  Future research: Further research can look into applying the same
  evaluation strategy to other organizations that switched from
  traditional to rapid release.
\end{itemize}

Notes:

\subsection{An Empirical Study of Delays in the Integration of Addressed
Issues}\label{an-empirical-study-of-delays-in-the-integration-of-addressed-issues}

Reference: {[}\protect\hyperlink{ref-da2014a}{39}{]}

General information:

\begin{itemize}
\tightlist
\item
  Name of person extracting data: Nels Numan
\item
  Date form completed (dd/mm/yyyy): 29/09/18
\item
  Publication title: An Empirical Study of Delays in the Integration of
  Addressed Issues
\item
  Author information: Daniel Alencar da Costa, Surafel Lemma Abebe,
  Shane McIntosh, Uira Kulesza, Ahmed E. Hassan
\item
  Journal: 2014 IEEE International Conference on Software Maintenance
  and Evolution
\item
  Publication type: Conference paper
\item
  Type of study: Emperical study
\end{itemize}

What practices in release engineering does this publication mention?

\begin{itemize}
\tightlist
\item
  This publication discusses the usage of issue tracking systems, and
  what the term issue means to form a context around the study.
\end{itemize}

Are these practices to be classified under dated, state of the art or
state of the practice? Why?

\begin{itemize}
\tightlist
\item
  State of the practice.
\end{itemize}

What open challenges in release engineering does this publication
mention?

\begin{itemize}
\tightlist
\item
  The results based on the investigated open source projects may not be
  generalizable and replication of the study is required on a larger set
  of projects to form a more general conclusion. Another challenge is
  finding metrics that are truly correlated with the integration delay
  of issues.
\end{itemize}

What research gaps does this publication contain?

\begin{itemize}
\tightlist
\item
  Please see last question.
\end{itemize}

Are these research gaps filled by any other publications in this survey?

\begin{itemize}
\tightlist
\item
  {[}\protect\hyperlink{ref-da2016a}{40}{]}
\end{itemize}

Quantitative research publications:

\begin{itemize}
\tightlist
\item
  Study start date:
\item
  Used data start dates:

  \begin{itemize}
  \tightlist
  \item
    ArgoUML: 18/08/2003
  \item
    Eclipse: 03/11/2003
  \item
    Firefox: 05/06/2012
  \end{itemize}
\item
  Used data end dates:

  \begin{itemize}
  \tightlist
  \item
    ArgoUML: 15/12/2011
  \item
    Eclipse: 12/02/2007
  \item
    Firefox: 04/02/2014
  \end{itemize}
\item
  Population description:
\item
  Method(s) of recruitment of participants: The data was collected from
  both ITSs and VCSs of the studied systems.
\item
  Sample size: 20,995 issues from ArgoUML, Eclipse and Firefox projects
\item
  Evaluation/measurement description:

  \begin{itemize}
  \tightlist
  \item
    How long are addressed issues typically delayed by the integration
    process?

    \begin{itemize}
    \tightlist
    \item
      Approach: models are created using metrics from four dimensions:
      reporter, issue, project, and history. Please refer to Table 2 in
      the paper for all of the metrics considered. The models are
      trained using the random forest technique. Precision, recall,
      F-measure, and ROC area are used to evaluate the models.
    \end{itemize}
  \end{itemize}
\item
  Outcomes:

  \begin{itemize}
  \tightlist
  \item
    How long are addressed issues typically delayed by the integration
    process?

    \begin{itemize}
    \tightlist
    \item
      Addressed issues are usually delayed in a rapid release cycle.
      Many delayed issues were addressed well before releases from which
      they were omitted. Many delayed issues were addressed well before
      releases from which they were omitted.
    \end{itemize}
  \item
    Can we accurately predict when an addressed issue will be
    integrated?

    \begin{itemize}
    \tightlist
    \item
      The prediction models achieve a weighted average precision between
      0.59 to 0.88 and a recall between 0.62 to 0.88, with ROC areas of
      above 0.74. The models achieve better F-measure values than
      Zero-R.
    \end{itemize}
  \item
    What are the most influential attributes for estimating integration
    delay?

    \begin{itemize}
    \tightlist
    \item
      The integrator workload has a bigger influence on integrator delay
      than the other attributes. Severity and priority have little
      influence on issue in- tegration delay.
    \end{itemize}
  \end{itemize}
\item
  Limitations: See open challenges.
\item
  Future research: See open challenges.
\end{itemize}

Notes:

\subsection{Towards Definitions for Release Engineering and
DevOps}\label{towards-definitions-for-release-engineering-and-devops}

Reference: {[}\protect\hyperlink{ref-dyck2015a}{48}{]}

General information:

\begin{itemize}
\tightlist
\item
  Name of person extracting data: Nels Numan
\item
  Date form completed (dd/mm/yyyy): 30/09/2018
\item
  Publication title: Towards Definitions for Release Engineering and
  DevOps
\item
  Author information: Andrej Dyck, Ralf Penners, Horst Lichter
\item
  Journal:
\item
  Publication type:
\item
  Type of study: Survey
\end{itemize}

What practices in release engineering does this publication mention?

\begin{itemize}
\tightlist
\item
  This paper talks about approaches to improve the collaboration between
  development and IT operations teams, in order to streamline software
  engineering processes. The paper defines for release engineering and
  devops.
\end{itemize}

Are these practices to be classified under dated, state of the art or
state of the practice? Why?

\begin{itemize}
\tightlist
\item
  Not applicable.
\end{itemize}

What open challenges in release engineering does this publication
mention?

\begin{itemize}
\tightlist
\item
  The paper mentions that creating a definition which is uniform and
  valid for many situations is difficult to find and that further
  research is needed.
\end{itemize}

What research gaps does this publication contain?

\begin{itemize}
\tightlist
\item
  This paper aims to form a uniform definition for release engeneering
  and devops, in collaboration with experts. It is unclear how many
  experts were consulted for this definition, and more consultations and
  research could be done to further improve the definition.
\end{itemize}

Are these research gaps filled by any other publications in this survey?

\begin{itemize}
\item
\end{itemize}

Quantitative research publications:

\begin{itemize}
\tightlist
\item
  Study start date:
\item
  Study end date or duration:
\item
  Population description:
\item
  Method(s) of recruitment of participants:
\item
  Sample size:
\item
  Evaluation/measurement description:
\item
  Outcomes:
\item
  Limitations:
\item
  Future research:
\end{itemize}

Notes:

\subsection{Continuous deployment of software intensive products and
services: A systematic mapping
study}\label{continuous-deployment-of-software-intensive-products-and-services-a-systematic-mapping-study}

Reference: {[}\protect\hyperlink{ref-rodriguez2017a}{106}{]}

General information:

\begin{itemize}
\tightlist
\item
  Name of person extracting data: Nels Numan
\item
  Date form completed (dd/mm/yyyy): 30/09/18
\item
  Publication title: Continuous deployment of software intensive
  products and services: A systematic mapping study
\item
  Author information: Pilar Rodrgueza, Alireza Haghighatkhaha, Lucy
  Ellen Lwakatarea, Susanna Teppolab, Tanja Suomalainenb, Juho Eskelib,
  Teemu Karvonena, Pasi Kuvajaa, June M. Vernerc, Markku Oivoa
\item
  Journal:
\item
  Publication type:
\item
  Type of study: Semantic study
\end{itemize}

What practices in release engineering does this publication mention?

\begin{itemize}
\tightlist
\item
  This paper discussed the developments of continuous development over
  the years until June 2014. This paper has performed a semantic study
  to identify, classify and analyze primary studies related to
  continuous development. The paper has found the following major
  points:

  \begin{itemize}
  \tightlist
  \item
    Almost all primary studies make reference in one way or another to
    accelerate the releae cycle by shortening the release cadence and
    turning it into a continuous flow.
  \item
    Some reviewed publications claim that accelerating the release cycle
    can make it harder to perform re-engineering activities.
  \item
    CD challenges and changes traditional planning towards continuous
    planning in order to achieve fast and frequent releases.
  \item
    Tighter integration between planning and execution is required in
    order to achieve a more holisitic view on planning in CD.
  \item
    It is important for the engineering and QA teams to ensure backward
    compatibility of enhancements, so that users perceive only
    improvements rather than experience any loss of functionality.
  \item
    Code change activities tend to focus more on bug fixing and
    maintenance than functional- ity expansion
  \item
    The architecture must be robust enough to allow the organization to
    invest its resources in offensive initiatives such as new
    functionalitity, product enhancements and innovation rather than
    defensive efforts such as bugfixes.
  \item
    A major challenge in CD is to retain the balance between speed and
    quality. Some approaches reviewed by this study propose a focus on
    measuring and monitoring source code and architectural quality.
  \item
    To avoid issues such as duplicated testing efforts and slow feedback
    loops it is important to make all testing activities transparent to
    individual developers.
  \end{itemize}
\end{itemize}

What open challenges in release engineering does this publication
mention?

\begin{itemize}
\tightlist
\item
  Continuous and rapid experimentation is an emerging research topic
  with many possibilities for future work. This is why it's important to
  keep up with the newly contributed studies and add them to future
  reviews to compare their findings.
\end{itemize}

What research gaps does this publication contain?

\begin{itemize}
\item
\end{itemize}

Notes:

\subsection{Frequent Releases in Open Source Software: A Systematic
Review}\label{frequent-releases-in-open-source-software-a-systematic-review}

Reference: {[}\protect\hyperlink{ref-cesar2017a}{34}{]}

General information:

\begin{itemize}
\tightlist
\item
  Name of person extracting data: Nels Numan
\item
  Date form completed (dd/mm/yyyy): 30/09/18
\item
  Publication title: Frequent Releases in Open Source Software: A
  Systematic Review
\item
  Author information: Antonio Cesar Brando Gomes da Silva, Glauco de
  Figueiredo Carneiro, Fernando Brito e Abreu and Miguel Pessoa Monteiro
\item
  Journal: Information
\item
  Publication type: Journal
\item
  Type of study: Survey
\end{itemize}

What practices in release engineering does this publication mention?

\begin{itemize}
\tightlist
\item
  This paper discussed the developments of continuous development over
  the years. This paper has performed a semantic study to identify,
  classify and analyze primary studies related to continuous
  development. The paper finds:

  \begin{itemize}
  \tightlist
  \item
    Two main motivations for the implementation of frequent software
    releases in the context of OSS projects, which are the project
    attractiveness/increase of participants and maintenance and increase
    of market share
  \item
    Four main strategies are adopted by practitioners to implement
    frequent software releases in the context of OSS projects:
    time-based release, automated release, test-driven development and
    continuous delivery/deployment.
  \item
    The main positive points associated to rapid releases are: quick
    return on customer needs, rapid delivery of new features, quick bug
    fixes, immediate release security patches, increased efficiency,
    entry of new collaborators, and greater focus on quality on the part
    of developers and testers.
  \item
    The main negative points assocaited to rapid releases are
    reliability of new versions, increase in the ``technical debt'',
    pressure felt by employees and community dependence.
  \end{itemize}
\end{itemize}

Are these practices to be classified under dated, state of the art or
state of the practice? Why?

\begin{itemize}
\tightlist
\item
  The practices discussed are a combination of state of the art and
  state of the practice approaches.
\end{itemize}

What open challenges in release engineering does this publication
mention?

\begin{itemize}
\tightlist
\item
  A meta-model for the mining of open source bases in view of gathering
  data that leads to assessment of the quality of projects adoping the
  frequent release approach.
\end{itemize}

What research gaps does this publication contain?

\begin{itemize}
\item
\end{itemize}

Are these research gaps filled by any other publications in this survey?

\begin{itemize}
\item
\end{itemize}

\chapter{Code Review}\label{code-review}

\section{Review protocol}\label{review-protocol}

This section describes the review protocol used for the systematic
review presented in this section. The protcol has been set up using
Kitchenham's method as described by Kitchenham et al.
{[}\protect\hyperlink{ref-kitchenham2007}{74}{]}.

\subsection{Research questions}\label{research-questions-2}

The goal of the review is to summarize the state of the art and identify
future challenges in the code review area. The research questions are as
follows:

\begin{itemize}
\tightlist
\item
  \textbf{RQ1}: \emph{What is the state of the art in the research area
  of code review?} This question focusses on topics that are researched
  often, the results of that research, and research methods, tools and
  datasets that are used.
\item
  \textbf{RQ2}: \emph{What is the current state of practice in the area
  of code review?} This concerns tools and techniques that are developed
  and used in practice, by open source projects but also by commercial
  companies.
\item
  \textbf{RQ3}: \emph{What are future challenges in the area of code
  review?} This concerns both research challenges and challenges for use
  in practice.
\end{itemize}

\subsection{Search process}\label{search-process}

The search process consists of the following:

\begin{itemize}
\tightlist
\item
  A Google Scholar search using the search query \emph{``modern code
  review'' OR ``modern code reviews''}. The results list will be sorted
  by decreasing relevance by Google Scholar and will be considered by us
  in order.
\item
  A general Google search for non-scientific reports (e.g., blog posts)
  and implemented code review tools. For this search queries \emph{code
  review} and \emph{code review tools} are used, respectively. The
  result list will be considered in order.
\item
  All papers in the initial seed provided by the course instructor will
  be considered.
\item
  All papers referenced by already collected papers will be considered.
\end{itemize}

From now on, all four categories listed above in general will be called
\emph{resource}.

\subsection{Inclusion criteria}\label{inclusion-criteria}

From the scientific literature, the following types of papers will be
considered:

Papers researching recent code review

\begin{itemize}
\tightlist
\item
  concepts,
\item
  methodologies,
\item
  tools and platforms,
\item
  and experiments concerning the preceding.
\end{itemize}

From non-scientific resources, all resources discussing recent tools and
techniques used in practice will be considered.

\subsection{Exclusion criteria}\label{exclusion-criteria}

Resources published before 2008 will be excluded from the study.

\subsection{Primary study selection
process}\label{primary-study-selection-process}

We will select a number of candidate resources based on the criteria
stated above. For each resource, each person participating in the review
can select it as a candidate.

From all candidates, resource will be selected that will actually be
reviewed. This can also be done by each person participating in the
review. All resources that are candidates but are not selected for
actual review must be explicitly rejected, with accompanying reasoning,
by at least two persons participating in the review.

\subsection{Data collection}\label{data-collection}

The following data will be collected from each considered resource:

\begin{itemize}
\tightlist
\item
  Source (for example, the blog website or specific journal)
\item
  Year published
\item
  Type of resource
\item
  Author(s) and organization(s)
\item
  Summary of the resource of a maximum of 100 words
\item
  Data for answering \textbf{RQ1}:

  \begin{itemize}
  \tightlist
  \item
    Sub-topic of research
  \item
    Research method
  \item
    Used tools
  \item
    Used datasets
  \item
    Research questions and their answers
  \end{itemize}
\item
  Data for answering \textbf{RQ2}:

  \begin{itemize}
  \tightlist
  \item
    Tools used
  \item
    Company/organization using the tool
  \item
    Evaluation of the tool
  \end{itemize}
\item
  Data for answering \textbf{RQ3}:

  \begin{itemize}
  \tightlist
  \item
    Future research challenges posed
  \end{itemize}
\end{itemize}

All data will be collected by one person participating in the review and
checked by another.

\section{Candidate resources}\label{candidate-resources}

In this section, all candidates that are collected using the described
search process are presented. The in survey column in the tables below
indicates whether the paper has been included in the survey in the end
or if it has been excluded for some reason. If it has been excluded, the
reason is stated along with the paper summary.

\subsection{Initial seed}\label{initial-seed-1}

These following table lists all initial seed papers provided by the
course intructor. They are listed in alphabetical order of the first
author's name, and then by publish year.

\begin{longtable}[]{@{}llll@{}}
\toprule
First author & Year & Reference & In survey? (Y/N)\tabularnewline
\midrule
\endhead
Bacchelli, A. & 2013 &
{[}\protect\hyperlink{ref-bacchelli2013expectations}{7}{]}
&\tabularnewline
Beller, M. & 2014 & {[}\protect\hyperlink{ref-beller2014modern}{15}{]}
&\tabularnewline
Bird, C. & 2015 & {[}\protect\hyperlink{ref-bird2015lessons}{23}{]}
&\tabularnewline
Fagan, M. & 2002 & {[}\protect\hyperlink{ref-fagan2002design}{52}{]}
&\tabularnewline
Gousios, G. & 2014 &
{[}\protect\hyperlink{ref-gousios2014exploratory}{56}{]}
&\tabularnewline
McIntosh, S. & 2014 &
{[}\protect\hyperlink{ref-mcintosh2014impact}{89}{]} &\tabularnewline
\bottomrule
\end{longtable}

\subsection{Google Scholar}\label{google-scholar}

The following table lists all candidates that have been collected
through the Google Scholar search described in the search process. They
are listed in alphabetical order of the first author's name, and then by
publish year. Note that as described in the search process section,
papers in the search are considered in order.

\begin{longtable}[]{@{}llll@{}}
\toprule
First author & Year & Reference & In survey? (Y/N)\tabularnewline
\midrule
\endhead
Baysal, O. & 2016 &
{[}\protect\hyperlink{ref-baysal2016investigating}{12}{]}
&\tabularnewline
Thongtanunam, P. & 2015 &
{[}\protect\hyperlink{ref-thongtanunam2015should}{117}{]}
&\tabularnewline
Thongtanunam, P. & 2016 &
{[}\protect\hyperlink{ref-thongtanunam2016revisiting}{116}{]}
&\tabularnewline
Xia, X. & 2015 & {[}\protect\hyperlink{ref-xia2015should}{123}{]}
&\tabularnewline
Zanjani, M. B. & 2016 &
{[}\protect\hyperlink{ref-zanjani2016automatically}{126}{]}
&\tabularnewline
\bottomrule
\end{longtable}

\subsection{By reference}\label{by-reference}

The following table lists all candidates that have been found by being
referenced by another paper we found. They are listed in alphabetical
order of the first author's name, and then by publish year.

\begin{longtable}[]{@{}lllll@{}}
\toprule
First author & Year & Reference & Referenced by & In survey?
(Y/N)\tabularnewline
\midrule
\endhead
Baum & 2016 & {[}\protect\hyperlink{ref-baum2016faceted}{10}{]} &
&\tabularnewline
Baum & 2017 & {[}\protect\hyperlink{ref-baum2017choice}{9}{]} &
&\tabularnewline
Baysal & 2013 & {[}\protect\hyperlink{ref-baysal2013influence}{13}{]} &
&\tabularnewline
Bosu & 2013 & {[}\protect\hyperlink{ref-bosu2013impact}{27}{]} &
&\tabularnewline
Ciolkowski & 2003 &
{[}\protect\hyperlink{ref-ciolkowski2003software}{35}{]} &
&\tabularnewline
Czerwonka & 2015 & {[}\protect\hyperlink{ref-czerwonka2015code}{42}{]} &
&\tabularnewline
\bottomrule
\end{longtable}

\section{Paper summaries}\label{paper-summaries}

This section contains summaries of all papers included in the survey.
They are listed in alphabetical order of first author name, and then by
year published.

\subsection{Expectations, outcomes, and challenges of modern code
review}\label{expectations-outcomes-and-challenges-of-modern-code-review}

Reference: {[}\protect\hyperlink{ref-bacchelli2013expectations}{7}{]}

This paper describes research about the goals and actual effects of code
reviews. Interviews and experiments have been done with people in the
programming field.

One of the main conclusions is that the main effect of doing code
reviews is that everyone involved understands the code better. This is
opposed to what the goal of code reviews is generally: discovering
errors.

\subsection{A Faceted Classification Scheme for Change-Based Industrial
Code Review
Processes}\label{a-faceted-classification-scheme-for-change-based-industrial-code-review-processes}

Reference: {[}\protect\hyperlink{ref-baum2016faceted}{10}{]}

The broad research questions treated in this article are: How is code
review performed in industry today? Which commonalities and variations
exist between code review processes of different teams and companies?
The article describes a classification scheme for change-based code
review processes in industry. This scheme is based on descriptions of
the code review processes of eleven companies, obtained from interviews
with software engineering professionals that were performed during a
Grounded Theory study.

\subsection{The Choice of Code Review Process: A Survey on the State of
the
Practice}\label{the-choice-of-code-review-process-a-survey-on-the-state-of-the-practice}

Reference: {[}\protect\hyperlink{ref-baum2017choice}{9}{]}

This paper, published in 2017, is trying to answer 3 RQs. Firstly, how
prevalent is change-based review in the industry? Secondly, does the
chance that code review remains in use increase if code review is
embedded into the process (and its supporting tools) so that it does not
require a conscious decision to do a review? Thirdly, are the intended
and acceptable levels of review effects a mediator in determining the
code review process?

\subsection{The influence of non-technical factors on code
review}\label{the-influence-of-non-technical-factors-on-code-review}

Reference: {[}\protect\hyperlink{ref-baysal2013influence}{13}{]}

\subsection{Investigating technical and non-technical factors
influencing modern code
review}\label{investigating-technical-and-non-technical-factors-influencing-modern-code-review}

Reference: {[}\protect\hyperlink{ref-baysal2016investigating}{12}{]}

\subsection{Modern code reviews in open-source projects: Which problems
do they
fix?}\label{modern-code-reviews-in-open-source-projects-which-problems-do-they-fix}

Reference: {[}\protect\hyperlink{ref-beller2014modern}{15}{]}

It has been researched what kinds of problems are solved by doing code
reviews. The conclusion is that 75\% are improvements in evolvability of
the code, and 25\% in functional aspects.

It has also been researched which part of the review comments is
actually followed up by an action, and which part of the edits after a
review are actually caused by review comments.

\subsection{Lessons learned from building and deploying a code review
analytics
platform}\label{lessons-learned-from-building-and-deploying-a-code-review-analytics-platform}

Reference: {[}\protect\hyperlink{ref-bird2015lessons}{23}{]}

A code review data analyzation platform developed and used by Microsoft
is discussed. It is mainly presented what users of the system think of
it and how its use influences development teams. One of the conclusions
is that in general, the platform has a positive influence on development
teams and their products.

\subsection{Impact of peer code review on peer impression formation: A
survey}\label{impact-of-peer-code-review-on-peer-impression-formation-a-survey}

Reference: {[}\protect\hyperlink{ref-bosu2013impact}{27}{]}

\subsection{Software Reviews: The State of the
Practice}\label{software-reviews-the-state-of-the-practice}

Reference: {[}\protect\hyperlink{ref-ciolkowski2003software}{35}{]}

To investigate how industry carries out software reviews and in what
forms, this paper con- ducted a two-part survey in 2002, the first part
based on a national initiative in Germany and the second involving
companies world- wide. Additionally, this paper also include some
fundenmental concepts of code review, such as functionalities of code
review.

\subsection{Code reviews do not find bugs: how the current code review
best practice slows us
down}\label{code-reviews-do-not-find-bugs-how-the-current-code-review-best-practice-slows-us-down}

Reference: {[}\protect\hyperlink{ref-czerwonka2015code}{42}{]}

As code review has many uses and benefits, the authors hope to find out
whether the current code review methods are sufficiently efficient. They
also research whether other methods may be more efficient. With
experience gained at Microsoft and with support of data, the authors
posit (1) that code reviews often do not find functionality issues that
should block a code submission; (2) that effective code reviews should
be performed by people with a specific set of skills; and (3) that the
social aspect of code reviews cannot be ignored.

\subsection{Design and code inspections to reduce errors in program
development}\label{design-and-code-inspections-to-reduce-errors-in-program-development}

Reference: {[}\protect\hyperlink{ref-fagan2002design}{52}{]}

This paper describes a method to thoroughly check code quality after
each step of the development process, in a heavyweight manner. It does
not really concern agile development.

The authors state that these methods do not affect the developing
process negatively, and that they work well for improving software
quality.

\subsection{An exploratory study of the pull-based software development
model}\label{an-exploratory-study-of-the-pull-based-software-development-model}

Reference: {[}\protect\hyperlink{ref-gousios2014exploratory}{56}{]}

This article focusses on how much pull requests are being used and how
they are used, focussing on GitHub. For example, it is concluded that
pull-request are not being used that much, that pull-requests are being
merged fast after they have been submitted, and that a pull request not
being merged is most of the time not caused by technical errors in the
pull-request.

\subsection{The impact of code review coverage and code review
participation on software quality: A case study of the qt, vtk, and itk
projects}\label{the-impact-of-code-review-coverage-and-code-review-participation-on-software-quality-a-case-study-of-the-qt-vtk-and-itk-projects}

Reference: {[}\protect\hyperlink{ref-mcintosh2014impact}{89}{]}

This paper focusses on the influence of doing light-weight code reviews
on software quality. In particular, the effect of review coverage (the
part of the code that has been reviewed) and review participation (a
measure for how much reviewers are involved in the review process) are
being assessed.

It turns out that both aspects improve software quality when they are
higher. Review participation is the most influential. According to the
authors there are other aspects, which they have not looked into, that
are of significant importance for the review process.

\subsection{Who should review my code? A file location-based
code-reviewer recommendation approach for modern code
review}\label{who-should-review-my-code-a-file-location-based-code-reviewer-recommendation-approach-for-modern-code-review}

Reference: {[}\protect\hyperlink{ref-thongtanunam2015should}{117}{]}

\subsection{Revisiting code ownership and its relationship with software
quality in the scope of modern code
review}\label{revisiting-code-ownership-and-its-relationship-with-software-quality-in-the-scope-of-modern-code-review}

Reference: {[}\protect\hyperlink{ref-thongtanunam2016revisiting}{116}{]}

\subsection{Who should review this change?: Putting text and file
location analyses together for more accurate
recommendations}\label{who-should-review-this-change-putting-text-and-file-location-analyses-together-for-more-accurate-recommendations}

Reference: {[}\protect\hyperlink{ref-xia2015should}{123}{]}

\subsection{Automatically recommending peer reviewers in modern code
review}\label{automatically-recommending-peer-reviewers-in-modern-code-review}

Reference: {[}\protect\hyperlink{ref-zanjani2016automatically}{126}{]}

\chapter{Runtime and Performance
Analytics}\label{runtime-and-performance-analytics}

In this chapter, we discuss the field of performance and runtime
analytics. This chapter does not cover the entire field because it is
too broad. Using Kitchenham's method
{[}\protect\hyperlink{ref-kitchenham2004procedures}{76}{]}, we have
narrowed down the scope of this survey.

For inspiration, we started reading five recent papers on runtime and
performance analytics published at top conferences. These five were
selected because the papers handle the software side of performance and
runtime analytics which is more in line with the other chapters of this
book. However, focussing on only software, the field is still very
broad. Currently, we are leaning towards a focus on performance and
runtime analytics literature regarding the Android platform. As we still
are at the start of this research, we might deviate from this initial
focus.

We have gathered a few other papers (excluding the five initial papers)
to find out if this field is suited for this survey. These papers can be
found in Figure INSERT FIGURE NUMBER HERE. To get relevant papers, we
used the following keywords: Android, performance, runtime, reliability,
synchronization, security, monitoring. Furthermore, we only retrieved
papers published at top venues, which we list here:

\begin{itemize}
\tightlist
\item
  ACM Transactions on Software Engineering Methodology (TOSEM),
\item
  Empirical Software Engineering (EMSE),
\item
  IEEE Transactions on Software Engineering (TSE),
\item
  Information and Software Technology (IST),
\item
  Journal of Systems and Software (JSS),
\item
  ACM Computing Surveys (CSUR),
\item
  Foundations of Software Engineering (SIGSOFT FSE),
\item
  International Conference on Automated Software Engineering (ASE),
\item
  Working Conference on Mining Software Repositories (MSR)
\item
  Symposium on Operating Systems Design and Implementation (OSDI)
\end{itemize}

\section{Week 1}\label{week-1}

Because we consider the five starting papers to be our inspiration, we
have chosen to briefly describe these papers by giving some basic
metrics about them (citations), summarizing them and by adding a few
notes about them. This is our initial work that we would like to expand
on in the coming weeks.

\subsection{Charting the API minefield using software telemetry
data}\label{charting-the-api-minefield-using-software-telemetry-data}

In this paper, researchers used software telemetry data from mobile
application crashes. With heuristics, they separated the API calls from
application calls so they can analyze what the most common causes for
crashes are. Top crash causes are: memory exhaustion, race conditions or
deadlocks, and missing resources. A significant percentage was not
suitable for analysis as these crashes were associated with generic
exceptions (10\%). They performed a literature search to find solutions
to the problems that cause the crashes. For each crash cause category,
an implementation recommendation is made. More specific exceptions,
non-blocking algorithms, and default resources can eliminate the most
frequent crashes. They also suggest that development tools like memory
analyzers, thread debuggers, and static analyzers can prevent many
application failures. They also propose features of execution platforms
and frameworks related to process and memory management that could
reduce application crashes.

\textbf{Remarks}

\begin{itemize}
\tightlist
\item
  Among the papers that refer to this paper or are referenced by this
  paper there are four papers that share the topic of crash data on
  mobile platforms that have been publiced to top software engineering
  venues {[}{]}.
\item
  The paper seems to be quite discerning as they evaluate their methods
  and reason about the threats to validity.
\end{itemize}

\subsection{Reproducing context-sensitive crashes of mobile apps using
crowdsourced
monitoring}\label{reproducing-context-sensitive-crashes-of-mobile-apps-using-crowdsourced-monitoring}

The mobile applications market continues to grow and many applications
are available. It is important for developers that their application
keeps working and that crashes are fixed as fast as possible to keep up
with competitors. However, the mobile market is complex as for end users
there are endless configurations of application versions, mobile
hardware and user input sequences. Therefore, it is difficult to
reproduce software crashes under the same context and conditions that
triggered the observed crash. This is why the researchers developed
MoTiF which uses machine learning to reproduce the steps the end users
take before the app crashes on the end user's phone and generates a test
suite. MoTiF also uses the crowd to validate whether the generated test
suite truly reproduces the observed crash.

\textbf{Remarks}

\begin{itemize}
\tightlist
\item
  The datasets used for the research are a bit questionable. One is
  based on simply performing a large amount of random event on the app,
  the other dataset is created by letting a group of 10 student try to
  crash the app in one hour.
\item
  Only 5 different apps have been tested.
\item
  Contains reference to ``Charting the API minefield using software
  telemetry data''.
\end{itemize}

\subsection{An exploratory study on faults in web api integration in a
large-scale payment
company}\label{an-exploratory-study-on-faults-in-web-api-integration-in-a-large-scale-payment-company}

This research explores what the implications of web API faults are, what
the most common web API faults are and best practices for API design.
The faults in API integration can be grouped in 11 causes: invalid user
input, missing user input, expired request data, invalid request data,
missing request data, insufficient permissions, double processing,
configuration, missing server data, internal and third party. Most
faults can be attributed to the invalid or missing request data, and
most API consumers seem to be impacted by faults caused by invalid
request data and third party integration. Furthermore, API consumers
most often use official API documentation to implement an API correctly,
followed by code examples. The challenges of preventing runtime problems
are the lack of implementation details, insufficient guidance on certain
aspects of the integration, insufficient understanding of the impact of
problems, and missing guidance on how to recover from errors.

\textbf{Remarks}

\begin{itemize}
\tightlist
\item
  Easy to read
\item
  Paper only considers a single API
\item
  Survey only has 40 responses
\end{itemize}

\subsection{Search-based test data generation for SQL
queries}\label{search-based-test-data-generation-for-sql-queries}

SQL queries should be tested as thoroughly as program code. However, it
is hard to generate test data for testing. Other researchers proposed
viewing this problem as a constraint solving problem, so test data could
be generated with a SAT-solver. However, strings are not supported by
current SAT-solver tools and it is a complex task to translate a query
to a satisfiability problem. In this research, the test generation
problem is treated as a search-based problem. They use random search,
biased random search and genetic algorithms (GA) to generate the data.
The methods are combined in a tool called EvSQL and the tool is tested
on more than 2000 queries. The GA method is the best and is able to
cover a little over 98\% of the queries.

\textbf{Remarks}

\begin{itemize}
\tightlist
\item
  Easy to read
\item
  Utilizes queries of 4 different systems
\item
  Generation of test data for SQL questies implies easier generation of
  unit- regression- and integration tests for SQL queries.
\end{itemize}

\subsection{Anomaly detection using program control flow graph mining
from execution
logs}\label{anomaly-detection-using-program-control-flow-graph-mining-from-execution-logs}

The paper attempts to diagnose distributed applications. For this
purpose they mine templates and their sequences from exedcution logs,
from this information they create a control flow graph. The main cause
of failures identified: making an API request to another application.
This results in many new calls to other services or even other
applications. This flow gets interrupted at some point. So when the top
level API is not working, they want to show where it goes wrong. In
earlier work, primarily metrics and logs were used to find the cause.
However these approaches struggled with many benign warnings or errors
in healthy state or faults do not manifest as errors. Manually checking
a transaction flow is also very hard. Instead, templates are used as
print statements from the source code. These represent the nodes, the
edges are the flows. This approach imposes two major challenges. One,
mining print statements is hard because parameters are different in
every log. Two, flows can happen at the simultaneously. The paper tries
to solve these challenges by applying a join on two print statements if
the statements are preceded and followed by approximately the same
steps.

\textbf{Remarks}

\begin{itemize}
\tightlist
\item
  Has a presentation on YouTube
\item
  Difficult to read
\end{itemize}

\section{Week 2}\label{week-2}

Because we are still working on the exact scope of the survey as well as
the lay-out of the chapter, we have chosen to temporarily divide the
papers by week. This will be changed later on. A more suitable focus for
this survey would be the Energy vs performance sub-domain of runtime and
performance analytics. To explore this domain we have summarized some
initial papers.

The survey on performance vs energy efficiency focuses on the following
research questions: \textbf{RQ1} What is the current state of art?
\textbf{RQ2} What is the current state of practice? \textbf{RQ3} What
are the challenges of the future work?

To answer these questions three papers are selected to form the basis of
this literature survey:

\begin{itemize}
\item
  Yepang Liu, Chang Xu, and Shing-Chi Cheung. 2014. Characterizing and
  detecting performance bugs for smartphone applications. In Proceedings
  of the 36th International Conference on Software Engineering (ICSE
  2014). ACM, New York, NY, USA, 1013-1024. DOI:
  \url{https://doi.org/10.1145/2568225.2568229}
\item
  Rui Pereira, Pedro Simo, Jcome Cunha, and Joo Saraiva. 2018.
  jStanley: placing a green thumb on Java collections. In Proceedings of
  the 33rd ACM/IEEE International Conference on Automated Software
  Engineering (ASE 2018). ACM, New York, NY, USA, 856-859. DOI:
  \url{https://doi.org/10.1145/3238147.3240473}
\item
  Stefanos Georgiou, Maria Kechagia, Panos Louridas, and Diomidis
  Spinellis. 2018. What are your programming language's energy-delay
  implications?. In Proceedings of the 15th International Conference on
  Mining Software Repositories (MSR '18). ACM, New York, NY, USA,
  303-313. DOI: \url{https://doi.org/10.1145/3196398.3196414}
\end{itemize}

By looking into the state of programming languages in regards to energy
performance, the state of the art will be determined, thus answering
RQ1. For the current state of practice (RQ2) literature on the topic of
energy efficiency in Android applications will be used. From both topics
the challenges and related work will be used for answering RQ3.

\textbf{Running list of domain keywords:} Programming Languages,
Energy-Delay-Product, Energy-Efficiency, Empirical study, performance
bug, testing, static analysis, Green Software, Energy-aware Software,
JCF

\subsection{What Are Your Programming Language's Energy-Delay
Implications?}\label{what-are-your-programming-languages-energy-delay-implications}

Motivated by the lack of studies that investigate the energy consumption
of software applications compared to the number of studies in the energy
efficiency of hardware, the researchers set out to investigate the
run-time performance of commonly used programming tasks in different
languages on different platforms. The paper contributes by giving a
customized and extended data set that can be used as a benchmark for
similar studies, a set of publicly available tools for measuring the
Energy Delay Product (EDP) of various programming tasks implemented in
different programming languages, an empirical study on programming
language EDP implications, by using different types of programming tasks
and software platforms, and a programming language-based ranking
catalogue, in the form of heat maps, where developers can find which
programming language to pick for particular tasks and platforms; when
energy or run-time performance are important. The research questions
which are answered are as follows: Which programming languages are the
most EDP efficient and inefficient for particular tasks? Which types of
programming languages are, on average, more EDP efficient and
inefficient for each of the selected platforms (i.e.~server, laptop and
embedded system)? How much does the EDP of each programming language
differ among the selected platforms? To answer these questions the
Rosetta Code Repository, a publicly available repository for programming
tasks, is used. It offers 868 tasks, 204 draft tasks and has
implementations in 675 programming languages. The results of the paper
are that for most tasks the compiled programming languages outperform
the interpreted ones.

\textbf{Keywords:} Programming Languages; Energy-Delay-Product;
Energy-Efficiency

\subsection{Characterizing and Detecting Performance Bugs for Smartphone
Applications}\label{characterizing-and-detecting-performance-bugs-for-smartphone-applications}

Bugs can cause significant performance degradation, which in turn may
lead to losing the competitive edge for the application. The paper is
motivated by people having little understanding for performance bugs and
the lack of effective techniques to fight these bugs. In the paper the
questions are researched what the common types of performance bugs are
in Android applications, and what impact they have on the user
experience (RQ1), how the performance bugs manifest themselves and if
their manifestation needs special input (RQ2), if performance bugs are
more difficult to debug and fix compared to non-performance bugs and
what information or tools can help with that (RQ3) and if there are
common causes of performance bugs, and if patterns can be distilled to
facilitate performance analysis and bug detection (RQ4). Answering these
questions leads to the paper making two major contributions: The first
empirical study of real-world performance bugs in smartphone
applications. The findings can help understand characteristics of
performance bugs in smartphone applications, and provide guidance to
related research. The implementation of a static code analyzer,
PerfChecker, which successfully identified performance optimization
opportunities in 18 popular Android applications. The selected Android
applications needed to have more than 10.000 downloads and own a public
bug tracking system. Furthermore there should be at least hundreds of
code revisions. These criteria provide an indicator of the popularity
and maturity of the selected applications. At first 29 Android
applications were selected, with PerfChecker successfully detecting 126
matching instances of the bug patterns in 18 of these applications. Of
these detected 126 matching instances of performance bug patterns, 68
were quickly confirmed by developers as previously unknown issues that
affect application performance.

\textbf{Keywords}: Empirical study, performance bug, testing, static
analysis.

\subsection{jStanley: Placing a Green Thumb on Java
Collections}\label{jstanley-placing-a-green-thumb-on-java-collections}

In this short paper the tool jStanley is presented. With the help of
this tool developers can obtain information and suggestions on the
energy efficiency of their Java code. jStanley is available as Eclipse
plugin. In a preliminary evaluation jStanley shows energy gains between
2\% and 17\%, and a reduction in execution time between 2\% and 13\%.

\textbf{Keywords:} Green Software, Energy-aware Software, JCF, Eclipse
Plugin

\subsection{A Study on the Energy Consumption of Android App Development
Approaches}\label{a-study-on-the-energy-consumption-of-android-app-development-approaches}

In this study, an analysis is given of the energy consumption of Android
app according to which development method was used to create them. They
look mainly at the difference between programming languages and their
respective frameworks. They measured across multiple devices, which
presented little difference between them. They also rewrote some app to
use a hybrid framework in the hopes of improving the performance vs
Energy consumption balance and they report a non-negligible improvement.

\textbf{Keywords:} Android, runtime, performance (search keywords, the
paper itself did not contain keywords)

\chapter{App Store Analytics}\label{app-store-analytics}

\section{Motivation}\label{motivation-5}

In the year 2008, the first app stores became available. These stores
have grown rapidly in size since then, with over 3 million apps in the
Google Play store alone at the time of writing {[}REFERENCE{]}. These
app stores together with the large user bases associated with them
provide software developers and researchers with valuable data. The
process of exploiting this data from app stores to gain valuable
insights is what we would call ``App Store Analytics''. Because apps
have not been around for a long time the research field of App Store
Analytics is still very young. However, because apps are used so much
nowadays it plays an important role in the field of Software
Engineering. Therefore, to get an overview of the current state of this
young research field this chapter(?) is devoted as a survey on the field
of App Store Analytics. We present three research questions to structure
this survey:

\begin{itemize}
\tightlist
\item
  \textbf{RQ1} Current state of the art in software analytics for App
  Store Analytics:

  \begin{itemize}
  \tightlist
  \item
    Topics that are being explored.
  \item
    Research methods, tools, and datasets being used.
  \item
    Main research findings, aggregated.
  \end{itemize}
\item
  \textbf{RQ2} Current state of practice in software analytics for App
  Store Analytics:

  \begin{itemize}
  \tightlist
  \item
    Tools and companies creating/employing them.
  \item
    Case studies and their findings.
  \end{itemize}
\item
  \textbf{RQ3} Open challenges and future research required.
\end{itemize}

\section{Research protocol}\label{research-protocol-5}

TODO: here are just ideas of what I'm doing but they should be properly
written

The research protocol is divided into two important parts: the articles
search process and the article selection process. In the following
paragraphs, both processes will be explained. {[}Refer to Kitchenham?{]}

\subsection{Search queries (Article search
process)}\label{search-queries-article-search-process}

Our initial seed of the papers came from the survey of the field of App
Store Analytics by Martin et al. {[}TODO: REFER to survey{]} and after
that we used the keywords \textbf{apps}, \textbf{app store}, \textbf{app
store analytics} and \textbf{app store mining} to search for other
relevant papers on Google Scholar, ACM, IEEE Xplore and pages of
individual journals (CSUR, TSE, EMSE, JSS, TOSEM, IST) and conferences
(ICSE, FSE, ASE, MSR, OSDI). From the results only articles with
relevant titles were selected and added to the list for consideration.

TODO: Include a table with journals/conferences including their full
names

\subsection{Article selection}\label{article-selection}

In order to retain only the most relevant papers to answer the research
questions, we devised a composed metric that takes into account the
number of citations and the year the paper was published. Taking these
elements the scoring scheme is the following: Citations (C): Year of
publication (Y): The metric is computed as follows: Inclusion\_metric =
C (0.5) * Y (0.5)

For each paper the previously mentioned metric was calculated and the
top 30 were selected, discarding the rest.

\subsubsection{Inclusion criteria}\label{inclusion-criteria-1}

\begin{itemize}
\tightlist
\item
  The paper was published in well established journal or conference.
\item
  Title or abstract of the paper mentions app stores, mining from app
  stores or app store analytics.
\item
  Tha paper was published in 2010 or later.
\end{itemize}

\subsubsection{Exclution criteria}\label{exclution-criteria}

\begin{itemize}
\tightlist
\item
  The paper has at least 10 citations on Google Scholar.
\item
  The paper focuses on mobile app development or is an analysis of
  arbitrary selection of apps and does not extend to the app stores as a
  whole.
\end{itemize}

\subsection{Fact extraction}\label{fact-extraction}

Taking into consideration the example presented by Kitchenham et al in
{[}reference{]}, the following data were extracted from each of the
papers: - Source (journal or conference) - Complete reference - Main
topic area - Authors information (full names, institution, and country)
- Summary (research questions and answers) - Research question / issue -
MORE?

Each one of the team members was in charge of reviewing and extracting
the data of a set of papers . Then, the extracted data was checked by
another member. The allocation of team members to the papers was random,
equally splitting the workloads.

\section{Answers}\label{answers-4}

\begin{itemize}
\item
  \textbf{RQ1} Current state of the art in software analytics for App
  Store Analytics
\item
  \textbf{RQ2} Current state of practice in software analytics for App
  Store Analytics
\item
  \textbf{RQ3} Open challenges and future research required
\end{itemize}

\section{Paper extracted data}\label{paper-extracted-data}

\subsection{API change and fault proneness: A threat to the success of
Android
apps}\label{api-change-and-fault-proneness-a-threat-to-the-success-of-android-apps}

\textbf{Source:} Conference ESEC/FSE'17 Joint Meeting of the European
Software Engineering Conference and the ACM SIGSOFT Symposium on the
Foundations of Software Engineering

\textbf{Main topic area:} using user feedback/reviews, API changes

\textbf{Authors information (full names, institution, and country):} -
Mario Linares-Vsquez - Universidad de los Andes, Colombia - Gabriele
Bavota - University of Sannio, Italy - Carlos Bernal-Crdenas -
Universidad Nacional de Colombia, Colombia - Massimiliano Di Penta -
University of Sannio, Italy - Rocco Oliveto - University of Molise,
Italy - Denys Poshyvanyk - College of William and Mary, USA

The paper presents an empirical study that aims to corroborate the
relationship between the fault and change-proneness of APIs and the
degree of success of Android apps measured by their user ratings. For
this, the authors selected a sample of 7,097 free Android apps from the
Google Play Market and gathered information of the changes and faults
that the APIs used by them presented. Using this data and statistical
tools such as box-plots and the Mann-Whitney test, two main hypotheses
were analyzed. The first hypothesis tested the relationship between
fault-proneness (number of bugs fixed in the API) and the success of an
app. The second tested the relationship between change-proneness
(overall method changes, changes in method signatures and changes to the
set of exceptions thrown by methods) and the success of an app. Finally,
although no causal relationships between the variables can be assumed,
the paper found significant differences of the level of success of the
apps taking into consideration the change and fault-proneness of the
APIs they use.

\textbf{Research question/issue:} relationship between fault- and
change-proneness of APIs and the degree of success in Android apps.

\subsection{What would users change in my app? summarizing app reviews
for recommending software
changes}\label{what-would-users-change-in-my-app-summarizing-app-reviews-for-recommending-software-changes}

\textbf{Source:} Proceeding FSE 2016 Proceedings of the 2016 24th ACM
SIGSOFT International Symposium on Foundations of Software Engineering

\textbf{Main topic area:} using user feedback/reviews

\textbf{Authors information (full names, institution, and country):} -
Andrea Di Sorbo - University of Sannio, Italy - Sebastiano Panichella -
University of Zurich, Switzerland - Carol V. Alexandru - University of
Zurich, Switzerland - Junji Shimagaki - Sony Mobile Communications,
Japan - Corrado A. Visaggio - University of Sannio, Italy - Gerardo
Canfora - University of Sannio, Italy - Harald C. Gall - University of
Zurich, Switzerland

\textbf{Summary (research questions and answers):} The paper proposes a
new approach for analyzing App Store user reviews, deriving insights
from them. The presented solution has two components. First, the User
Reviews Model (URM) that enable the classification of users intentions
(e.g., UI improvements, bug fixes, etc.). Second, the Summarizer of User
Review Feedback (SURF). A tool that, by leveraging the URM, is capable
of generating summaries of users feedback. After evaluating the proposed
approach, TODO

\textbf{Research question/issue:} there is no approach that is able to
do, at the same time, the following: (i) determine for a large number of
reviews the specic topic discussed in the review (e.g., UI
improvements, security/licensing issues, etc.), (ii) identify the
maintenance task to perform for addressing the request stated in the
review (e.g., bug xing, feature enhancement, etc.), and (iii) present
such information in the form of a condensed, interactive and structured
agenda of recommended software changes, which is actionable for
developers. {[}Reference paper{]}

\subsection{App Store, Marketplace, Play! An Analysis of Multi-Homing in
Mobile Software
Ecosystems}\label{app-store-marketplace-play-an-analysis-of-multi-homing-in-mobile-software-ecosystems}

\textbf{Source:} Proceedings of the Fourth International Workshops on
Software Ecosystems \textbf{Main topic area:} App store ecosystem

\textbf{Authors information (full names, institution, and country):}
Sami Hyrynsalmi, University of Turku, Finland

Tuomas Mkil, University of Turku, Finland

Antero Jrvi, University of Turku, Finland

Arho Suominen, VTT Technical Research Centre of Finland, Finland

Marko Seppnen, Tampere University of Technology, Finland

Timo Knuutila, University of Turku, Finland

\textbf{Summary (research questions and answers):} Multi-homing is not
used by many developers, where multi-homing is the strategy of releasing
your application to multiple platforms. An analysis of Google Play, App
Store and Windows Phone Store shows that not many developers use this
strategy. Next to this, the paper found that the type and popularity of
apps does not differ from those that use a single-homing strategy.

\textbf{Research question/issue:} Analysis of multi-homing in different
app stores. How much is it used by developers and is there a difference
in popularity?

\subsection{A systematic literature review: Opinion mining studies from
mobile app store user
reviews}\label{a-systematic-literature-review-opinion-mining-studies-from-mobile-app-store-user-reviews}

*Source:** Journal of Systems and Software

\textbf{Main topic area:} Opinion Mining and Requirement Engineering

\textbf{Authors information (full names, institution, and country):}
Necmiye Genc-Nayebi, cole de Technologie Suprieure (ETS) - Universit
du Qubec, Canada Dr.~Alain Abran, cole de Technologie Suprieure (ETS)
- Universit du Qubec, Canada

\textbf{Summary (research questions and answers):} TODO: summary

\textbf{Research question/issue:} What are the proposed solutions for
mining online opinions in app store user reviews, challenges and
unsolved problems in the domain, new contributions to software
requirements evolution and future research direction.

\subsection{The Impact of API Change and Fault-Proneness on the User
Ratings of Android
Apps}\label{the-impact-of-api-change-and-fault-proneness-on-the-user-ratings-of-android-apps}

TODO: template

The paper by Bavota et al. aims to find empirical evidence supporting
the success of apps and the relationship with change- and
fault-proneness of the underlying APIs, where the success of the app is
measured by its user rating. They performed two case studies to find
quantitative evidence using 5848 free Android apps as well as an
explanation for these results doing a survey with 45 professional
Android developers. The quantitative case study was done by comparing
the user ratings to the number of bug fixes and changes in the API that
an app uses. They found that apps with a high user rating are
significantly less change- and fault-prone than APIs used by apps with a
low user rating. In the second case study the paper found that most of
the 45 developers observed a direct relationship between the user
ratings of apps and the APIs those apps use.

\subsection{How can i improve my app? Classifying user reviews for
software maintenance and
evolution}\label{how-can-i-improve-my-app-classifying-user-reviews-for-software-maintenance-and-evolution}

TODO: template

The most popular apps in the app stores (such as Google Play or App
Store) receive thousands of user reviews per day and therefore it would
be very time demanding to go through the reviews manually to obtain
relevant information for the future development of the apps. This paper
uses a combination of Natural Language Processing Sentiment Analysis and
Text Analysis to extract relevant sentences from the reviews and to
classify them into the following categories: Information Seeking,
Information Giving, Feature Request, Problem Discovery, and Others. The
results show 75\% precision and 74\% recall when classifier (J48 using
data from NLP+SA+TA) is trained on 20\% of the data (1421 manually
labeled sentences from reviews of seven different apps) and the rest is
used for testing. The paper also states that the results do not differ
in a statistically significant manner when a different classifier is
used and shows that precision and recall can be further improved by
increasing the size of the data set.

\chapter{Final Words}\label{final-words}

We have finished a nice book on Software Analytics.

\hypertarget{refs}{}
\hypertarget{ref-Abate2011}{}
{[}1{]} Abate, P. and Cosmo, R.D. 2011. Predicting upgrade failures
using dependency analysis. \emph{2011 IEEE 27th international conference
on data engineering workshops} (Apr. 2011).

\hypertarget{ref-Abate2009}{}
{[}2{]} Abate, P. et al. 2009. Strong dependencies between software
components. \emph{2009 3rd international symposium on empirical software
engineering and measurement} (Oct. 2009).

\hypertarget{ref-Abdalkareem2017}{}
{[}3{]} Abdalkareem, R. et al. 2017. Why do developers use trivial
packages? An empirical case study on npm. \emph{Proceedings of the 2017
11th joint meeting on foundations of software engineering - ESEC/FSE
2017} (2017).

\hypertarget{ref-adams2016a}{}
{[}4{]} Adams, B. and McIntosh, S. 2016. Modern release engineering in a
nutshell--why researchers should care. \emph{Software analysis,
evolution, and reengineering (saner), 2016 ieee 23rd international
conference on} (2016), 78--90.

\hypertarget{ref-Arisholm2010}{}
{[}5{]} Arisholm, E. et al. 2010. A systematic and comprehensive
investigation of methods to build and evaluate fault prediction models.
\emph{Journal of Systems and Software}. 83, 1 (2010), 2--17.

\hypertarget{ref-atifi2017}{}
{[}6{]} Atifi, M. et al. 2017. \emph{A comparative study of software
testing techniques}.

\hypertarget{ref-bacchelli2013expectations}{}
{[}7{]} Bacchelli, A. and Bird, C. 2013. Expectations, outcomes, and
challenges of modern code review. \emph{Proceedings of the 2013
international conference on software engineering} (2013), 712--721.

\hypertarget{ref-baltes2018no}{}
{[}8{]} Baltes, S. et al. 2018. (No) influence of continuous integration
on the commit activity in github projects. \emph{arXiv preprint
arXiv:1802.08441}. (2018).

\hypertarget{ref-baum2017choice}{}
{[}9{]} Baum, T. et al. 2017. The choice of code review process: A
survey on the state of the practice. \emph{International conference on
product-focused software process improvement} (2017), 111--127.

\hypertarget{ref-baum2016faceted}{}
{[}10{]} Baum, T. et al. 2016. A faceted classification scheme for
change-based industrial code review processes. \emph{Software quality,
reliability and security (qrs), 2016 ieee international conference on}
(2016), 74--85.

\hypertarget{ref-Bavota2014}{}
{[}11{]} Bavota, G. et al. 2014. How the apache community upgrades
dependencies: An evolutionary study. \emph{Empirical Software
Engineering}. 20, 5 (Sep. 2014), 1275--1317.

\hypertarget{ref-baysal2016investigating}{}
{[}12{]} Baysal, O. et al. 2016. Investigating technical and
non-technical factors influencing modern code review. \emph{Empirical
Software Engineering}. 21, 3 (2016), 932--959.

\hypertarget{ref-baysal2013influence}{}
{[}13{]} Baysal, O. et al. 2013. The influence of non-technical factors
on code review. \emph{Reverse engineering (wcre), 2013 20th working
conference on} (2013), 122--131.

\hypertarget{ref-beck2003test}{}
{[}14{]} Beck, K. 2003. \emph{Test-driven development: By example}.
Addison-Wesley Professional.

\hypertarget{ref-beller2014modern}{}
{[}15{]} Beller, M. et al. 2014. Modern code reviews in open-source
projects: Which problems do they fix? \emph{Proceedings of the 11th
working conference on mining software repositories} (2014), 202--211.

\hypertarget{ref-beller2017developer}{}
{[}16{]} Beller, M. et al. 2017. Developer testing in the ide: Patterns,
beliefs, and behavior. \emph{IEEE Transactions on Software Engineering}.
1 (2017), 1--1.

\hypertarget{ref-Beller:2015:DT:2819009.2819101}{}
{[}17{]} Beller, M. et al. 2015. How (much) do developers test?
\emph{Proceedings of the 37th international conference on software
engineering - volume 2} (Piscataway, NJ, USA, 2015), 559--562.

\hypertarget{ref-beller2017oops}{}
{[}18{]} Beller, M. et al. 2017. Oops, my tests broke the build: An
explorative analysis of travis ci with github. \emph{Mining software
repositories (msr), 2017 ieee/acm 14th international conference on}
(2017), 356--367.

\hypertarget{ref-beller2017travistorrent}{}
{[}19{]} Beller, M. et al. 2017. Travistorrent: Synthesizing travis ci
and github for full-stack research on continuous integration.
\emph{Proceedings of the 14th international conference on mining
software repositories} (2017), 447--450.

\hypertarget{ref-beller2015}{}
{[}20{]} Beller, M. et al. 2015. When, how, and why developers (do not)
test in their ides. \emph{2015 10th joint meeting of the european
software engineering conference and the acm sigsoft symposium on the
foundations of software engineering, esec/fse 2015 - proceedings}
(2015), 179--190.

\hypertarget{ref-bevan2005}{}
{[}21{]} Bevan, J. et al. 2005. Facilitating software evolution research
with kenyon. \emph{ESEC/fse'05 - proceedings of the joint 10th european
software engineering conference (esec) and 13th acm sigsoft symposium on
the foundations of software engineering (fse-13)} (2005), 177--186.

\hypertarget{ref-bird2017predicting}{}
{[}22{]} Bird, C. and Zimmermann, T. 2017. Predicting software build
errors. Google Patents.

\hypertarget{ref-bird2015lessons}{}
{[}23{]} Bird, C. et al. 2015. Lessons learned from building and
deploying a code review analytics platform. \emph{Proceedings of the
12th working conference on mining software repositories} (2015),
191--201.

\hypertarget{ref-bisong2017built}{}
{[}24{]} Bisong, E. et al. 2017. Built to last or built too fast?:
Evaluating prediction models for build times. \emph{Proceedings of the
14th international conference on mining software repositories} (2017),
487--490.

\hypertarget{ref-Blincoe2015}{}
{[}25{]} Blincoe, K. et al. 2015. Ecosystems in GitHub and a method for
ecosystem identification using reference coupling. \emph{2015 IEEE/ACM
12th working conference on mining software repositories} (May 2015).

\hypertarget{ref-Bogart2016}{}
{[}26{]} Bogart, C. et al. 2016. How to break an API: Cost negotiation
and community values in three software ecosystems. \emph{Proceedings of
the 2016 24th ACM SIGSOFT international symposium on foundations of
software engineering - FSE 2016} (2016).

\hypertarget{ref-bosu2013impact}{}
{[}27{]} Bosu, A. and Carver, J.C. 2013. Impact of peer code review on
peer impression formation: A survey. \emph{Empirical software
engineering and measurement, 2013 acm/ieee international symposium on}
(2013), 133--142.

\hypertarget{ref-bouwers2012a}{}
{[}28{]} Bouwers, E. et al. 2012. Getting what you measure.
\emph{Commun. ACM}. 55, 7 (Jul. 2012), 54--59.

\hypertarget{ref-bowring2014obsidian}{}
{[}29{]} Bowring, J. and Hegler, H. 2014. Obsidian: Pattern-based unit
test implementations. \emph{Journal of Software Engineering and
Applications}. 7, 02 (2014), 94.

\hypertarget{ref-castelluccio2017a}{}
{[}30{]} Castelluccio, M. et al. 2017. Is it safe to uplift this patch?
An empirical study on mozilla firefox. \emph{Proceedings - 2017 IEEE
International Conference on Software Maintenance and Evolution, ICSME
2017} (2017), 411--421.

\hypertarget{ref-Catal2011}{}
{[}31{]} Catal, C. 2011. Software fault prediction: A literature review
and current trends. \emph{Expert Systems with Applications}. 38, 4
(2011), 4626--4636.

\hypertarget{ref-Catal2009review}{}
{[}32{]} Catal, C. and Diri, B. 2009. A systematic review of software
fault prediction studies.

\hypertarget{ref-Catal2009investigating}{}
{[}33{]} Catal, C. and Diri, B. 2009. Investigating the effect of
dataset size, metrics sets, and feature selection techniques on software
fault prediction problem. \emph{Information Sciences}. 179, 8 (2009),
1040--1058.

\hypertarget{ref-cesar2017a}{}
{[}34{]} Cesar Brando Gomes da Silva, A. et al. 2017. Frequent releases
in open source software: A systematic review. \emph{Information}. 8, 3
(2017), 109.

\hypertarget{ref-ciolkowski2003software}{}
{[}35{]} Ciolkowski, M. et al. 2003. Software reviews: The state of the
practice. \emph{IEEE software}. 6 (2003), 46--51.

\hypertarget{ref-claes2017a}{}
{[}36{]} Claes, M. et al. 2017. Abnormal working hours: Effect of rapid
releases and implications to work content. \emph{IEEE International
Working Conference on Mining Software Repositories} (2017), 243--247.

\hypertarget{ref-Claes2015}{}
{[}37{]} Claes, M. et al. 2015. A historical analysis of debian package
incompatibilities. \emph{2015 IEEE/ACM 12th working conference on mining
software repositories} (May 2015).

\hypertarget{ref-Constantinou2017}{}
{[}38{]} Constantinou, E. and Mens, T. 2017. An empirical comparison of
developer retention in the RubyGems and npm software ecosystems.
\emph{Innovations in Systems and Software Engineering}. 13, 2-3 (Aug.
2017), 101--115.

\hypertarget{ref-da2014a}{}
{[}39{]} Costa, D.A. da et al. 2014. An empirical study of delays in the
integration of addressed issues. \emph{2014 ieee international
conference on software maintenance and evolution} (2014), 281--290.

\hypertarget{ref-da2016a}{}
{[}40{]} Costa, D.A. da et al. 2016. The impact of switching to a rapid
release cycle on the integration delay of addressed issues - an
empirical study of the mozilla firefox project. \emph{2016 ieee/acm 13th
working conference on mining software repositories (msr)} (2016),
374--385.

\hypertarget{ref-Cox2015}{}
{[}41{]} Cox, J. et al. 2015. Measuring dependency freshness in software
systems. \emph{2015 IEEE/ACM 37th IEEE international conference on
software engineering} (May 2015).

\hypertarget{ref-czerwonka2015code}{}
{[}42{]} Czerwonka, J. et al. 2015. Code reviews do not find bugs: How
the current code review best practice slows us down. \emph{Proceedings
of the 37th international conference on software engineering-volume 2}
(2015), 27--28.

\hypertarget{ref-Decan2017}{}
{[}43{]} Decan, A. et al. 2017. An empirical comparison of dependency
issues in OSS packaging ecosystems. \emph{2017 IEEE 24th international
conference on software analysis, evolution and reengineering (SANER)}
(Feb. 2017).

\hypertarget{ref-Decan2018}{}
{[}44{]} Decan, A. et al. 2018. An empirical comparison of dependency
network evolution in seven software packaging ecosystems.
\emph{Empirical Software Engineering}. (Feb. 2018).

\hypertarget{ref-Dietrich2014}{}
{[}45{]} Dietrich, J. et al. 2014. Broken promises: An empirical study
into evolution problems in java programs caused by library upgrades.
\emph{2014 software evolution week - IEEE conference on software
maintenance, reengineering, and reverse engineering (CSMR-WCRE)} (Feb.
2014).

\hypertarget{ref-Dittrich2014}{}
{[}46{]} Dittrich, Y. 2014. Software engineering beyond the project
sustaining software ecosystems. \emph{Information and Software
Technology}. 56, 11 (Nov. 2014), 1436--1456.

\hypertarget{ref-dulz2013model}{}
{[}47{]} Dulz, W. 2013. Model-based strategies for reducing the
complexity of statistically generated test suites. \emph{International
conference on software quality} (2013), 89--103.

\hypertarget{ref-dyck2015a}{}
{[}48{]} Dyck, A. et al. 2015. Towards definitions for release
engineering and devops. \emph{Release engineering (releng), 2015
ieee/acm 3rd international workshop on} (2015), 3--3.

\hypertarget{ref-DAmbros2010}{}
{[}49{]} D'Ambros, M. et al. 2010. An extensive comparison of bug
prediction approaches. \emph{Proceedings - International Conference on
Software Engineering}. (2010), 31--41.

\hypertarget{ref-DAmbros2012}{}
{[}50{]} D'Ambros, M. et al. 2012. Evaluating defect prediction
approaches: A benchmark and an extensive comparison. \emph{Empirical
Software Engineering}. 17, 4-5 (2012), 531--577.

\hypertarget{ref-eick2001}{}
{[}51{]} Eick, S.G. et al. 2001. Does code decay? Assessing the evidence
from change management data. \emph{IEEE Transactions on Software
Engineering}. 27, 1 (Jan. 2001), 1--12.

\hypertarget{ref-fagan2002design}{}
{[}52{]} Fagan, M. 2002. Design and code inspections to reduce errors in
program development. \emph{Software pioneers}. Springer. 575--607.

\hypertarget{ref-fowler2006continuous}{}
{[}53{]} Fowler, M. and Foemmel, M. 2006. Continuous integration.
\emph{Thought-Works) http://www. thoughtworks. com/Continuous
Integration. pdf}. 122, (2006), 14.

\hypertarget{ref-fujibayashi2017a}{}
{[}54{]} Fujibayashi, D. et al. 2017. Does the release cycle of a
library project influence when it is adopted by a client project?
\emph{SANER 2017 - 24th IEEE International Conference on Software
Analysis, Evolution, and Reengineering} (2017), 569--570.

\hypertarget{ref-GAROUSI20131354}{}
{[}55{]} Garousi, V. and Zhi, J. 2013. A survey of software testing
practices in canada. \emph{Journal of Systems and Software}. 86, 5
(2013), 1354--1376.

\hypertarget{ref-gousios2014exploratory}{}
{[}56{]} Gousios, G. et al. 2014. An exploratory study of the pull-based
software development model. \emph{Proceedings of the 36th international
conference on software engineering} (2014), 345--355.

\hypertarget{ref-greiler2013}{}
{[}57{]} Greiler, M. et al. 2013. Strategies for avoiding text fixture
smells during software evolution. \emph{IEEE international working
conference on mining software repositories} (2013), 387--396.

\hypertarget{ref-Gyimothy2005}{}
{[}58{]} Gyimothy, T. et al. 2005. Empirical validation of
object-oriented metrics on open source software for fault prediction.
\emph{IEEE Transactions on Software Engineering}. 31, 10 (Oct. 2005),
897--910.

\hypertarget{ref-Hall2012}{}
{[}59{]} Hall, T. et al. 2012. A Systematic Literature Review on Fault
Prediction Performance in Software Engineering. \emph{IEEE Transactions
on Software Engineering}. 38, 6 (Nov. 2012), 1276--1304.

\hypertarget{ref-hassan2018hirebuild}{}
{[}60{]} Hassan, F. and Wang, X. 2018. HireBuild: An automatic approach
to history-driven repair of build scripts. \emph{Proceedings of the 40th
international conference on software engineering} (2018), 1078--1089.

\hypertarget{ref-Hejderup2018}{}
{[}61{]} Hejderup, J. et al. 2018. Software ecosystem call graph for
dependency management. \emph{Proceedings of the 40th international
conference on software engineering new ideas and emerging results -
ICSE-NIER 18} (2018).

\hypertarget{ref-hemmati2018}{}
{[}62{]} Hemmati, H. and Sharifi, F. 2018. Investigating nlp-based
approaches for predicting manual test case failure. \emph{Proceedings -
2018 ieee 11th international conference on software testing,
verification and validation, icst 2018} (2018), 309--319.

\hypertarget{ref-hilton2016usage}{}
{[}63{]} Hilton, M. et al. 2016. Usage, costs, and benefits of
continuous integration in open-source projects. \emph{Proceedings of the
31st ieee/acm international conference on automated software
engineering} (2016), 426--437.

\hypertarget{ref-Hora2016}{}
{[}64{]} Hora, A. et al. 2016. How do developers react to API evolution?
A large-scale empirical study. \emph{Software Quality Journal}. 26, 1
(Oct. 2016), 161--191.

\hypertarget{ref-hurdugaci2012}{}
{[}65{]} Hurdugaci, V. and Zaidman, A. 2012. Aiding software developers
to maintain developer tests. \emph{2012 16th european conference on
software maintenance and reengineering} (March 2012), 11--20.

\hypertarget{ref-Izquierdo2018}{}
{[}66{]} Izquierdo, D. et al. 2018. Software development analytics for
xen: Why and how. \emph{IEEE Software}. (2018), 1--1.

\hypertarget{ref-Jansen2014}{}
{[}67{]} Jansen, S. 2014. Measuring the health of open source software
ecosystems: Beyond the scope of project health. \emph{Information and
Software Technology}. 56, 11 (Nov. 2014), 1508--1519.

\hypertarget{ref-karvonen2017a}{}
{[}68{]} Karvonen, T. et al. 2017. Systematic literature review on the
impacts of agile release engineering practices. \emph{Information and
Software Technology}. 86, (2017), 87--100.

\hypertarget{ref-kaur2019a}{}
{[}69{]} Kaur, A. and Vig, V. 2019. On understanding the release
patterns of open source java projects. \emph{Advances in Intelligent
Systems and Computing}. 711, (2019), 9--18.

\hypertarget{ref-kerzazi2013a}{}
{[}70{]} Kerzazi, N. and Robillard, P. 2013. Kanbanize the release
engineering process. \emph{2013 1st International Workshop on Release
Engineering, RELENG 2013 - Proceedings} (2013), 9--12.

\hypertarget{ref-khomh2015a}{}
{[}71{]} Khomh, F. et al. 2015. Understanding the impact of rapid
releases on software quality. \emph{Empirical Software Engineering}. 20,
2 (2015), 336--373.

\hypertarget{ref-khomh2012a}{}
{[}72{]} Khomh, F. et al. 2012. Do faster releases improve software
quality?: An empirical case study of mozilla firefox. \emph{Proceedings
of the 9th ieee working conference on mining software repositories}
(Piscataway, NJ, USA, 2012), 179--188.

\hypertarget{ref-Kikas2017}{}
{[}73{]} Kikas, R. et al. 2017. Structure and evolution of package
dependency networks. \emph{2017 IEEE/ACM 14th international conference
on mining software repositories (MSR)} (May 2017).

\hypertarget{ref-kitchenham2007}{}
{[}74{]} Kitchenham 2007. \emph{Guidelines for performing systematic
literature reviews in software engineering}. Keele University;
University of Durham.

\hypertarget{ref-Kitchenham2004}{}
{[}75{]} Kitchenham, B. 2004. Procedures for performing systematic
reviews. \emph{Keele}. 33, 1 (2004), 1--26.

\hypertarget{ref-kitchenham2004procedures}{}
{[}76{]} Kitchenham, B. 2004. Procedures for performing systematic
reviews. \emph{Keele, UK, Keele University}. 33, 2004 (2004), 1--26.

\hypertarget{ref-Kula2017-2}{}
{[}77{]} Kula, R.G. et al. 2017. An exploratory study on library aging
by monitoring client usage in a software ecosystem. \emph{2017 IEEE 24th
international conference on software analysis, evolution and
reengineering (SANER)} (Feb. 2017).

\hypertarget{ref-Kula2017}{}
{[}78{]} Kula, R.G. et al. 2017. Do developers update their library
dependencies? \emph{Empirical Software Engineering}. 23, 1 (May 2017),
384--417.

\hypertarget{ref-laukkanen2018a}{}
{[}79{]} Laukkanen, E. et al. 2018. Comparison of release engineering
practices in a large mature company and a startup. \emph{Empirical
Software Engineering}. (2018), 1--43.

\hypertarget{ref-leung2015testing}{}
{[}80{]} Leung, H.K. and Lui, K.M. 2015. Testing analytics on software
variability. \emph{Software analytics (swan), 2015 ieee 1st
international workshop on} (2015), 17--20.

\hypertarget{ref-Lewis2013}{}
{[}81{]} Lewis, C. et al. 2013. Does bug prediction support human
developers? Findings from a Google case study. \emph{2013 35th
international conference on software engineering (icse)} (May 2013),
372--381.

\hypertarget{ref-Lungu2009}{}
{[}82{]} Lungu, M. 2009. \emph{Reverse engineering software ecosystems}.
University of Lugano.

\hypertarget{ref-Malloy2018}{}
{[}83{]} Malloy, B.A. and Power, J.F. 2018. An empirical analysis of the
transition from python 2 to python 3. \emph{Empirical Software
Engineering}. (Jul. 2018).

\hypertarget{ref-Malloy2017}{}
{[}84{]} Malloy, B.A. and Power, J.F. 2017. Quantifying the transition
from python 2 to 3: An empirical study of python applications.
\emph{2017 ACM/IEEE international symposium on empirical software
engineering and measurement (ESEM)} (Nov. 2017).

\hypertarget{ref-Manikas2016}{}
{[}85{]} Manikas, K. 2016. Revisiting software ecosystems research: A
longitudinal literature study. \emph{Journal of Systems and Software}.
117, (Jul. 2016), 84--103.

\hypertarget{ref-marsavina2014}{}
{[}86{]} Marsavina, C. et al. 2014. Studying fine-grained co-evolution
patterns of production and test code. \emph{2014 ieee 14th international
working conference on source code analysis and manipulation} (Sept
2014), 195--204.

\hypertarget{ref-mantyla2015a}{}
{[}87{]} Mntyl, M.V. et al. 2015. On rapid releases and software
testing: A case study and a semi-systematic literature review.
\emph{Empirical Software Engineering}. 20, 5 (2015), 1384--1425.

\hypertarget{ref-McDonnell2013}{}
{[}88{]} McDonnell, T. et al. 2013. An empirical study of API stability
and adoption in the android ecosystem. \emph{2013 IEEE international
conference on software maintenance} (Sep. 2013).

\hypertarget{ref-mcintosh2014impact}{}
{[}89{]} McIntosh, S. et al. 2014. The impact of code review coverage
and code review participation on software quality: A case study of the
qt, vtk, and itk projects. \emph{Proceedings of the 11th working
conference on mining software repositories} (2014), 192--201.

\hypertarget{ref-Mens2013}{}
{[}90{]} Mens, T. et al. 2013. Studying evolving software ecosystems
based on ecological models. \emph{Evolving software systems}. Springer
Berlin Heidelberg. 297--326.

\hypertarget{ref-Messerschmitt2003}{}
{[}91{]} Messerschmitt, D.G. and Szyperski, C. 2003. \emph{Software
ecosystem: Understanding an indispensable technology and industry (mit
press)}. The MIT Press.

\hypertarget{ref-supportingtestsuite}{}
{[}92{]} Mirzaaghaei, M. et al. 2012. Supporting test suite evolution
through test case adaptation. \emph{2012 ieee fifth international
conference on software testing, verification and validation} (April
2012), 231--240.

\hypertarget{ref-moiz2017uncertainty}{}
{[}93{]} Moiz, S.A. 2017. Uncertainty in software testing. \emph{Trends
in software testing}. Springer. 67--87.

\hypertarget{ref-ni2018acona}{}
{[}94{]} Ni, A. and Li, M. 2018. ACONA: Active online model adaptation
for predicting continuous integration build failures. \emph{Proceedings
of the 40th international conference on software engineering: Companion
proceeedings} (2018), 366--367.

\hypertarget{ref-noor2015test}{}
{[}95{]} Noor, T.B. and Hemmati, H. 2015. Test case analytics: Mining
test case traces to improve risk-driven testing. \emph{Software
analytics (swan), 2015 ieee 1st international workshop on} (2015),
13--16.

\hypertarget{ref-pinto2018work}{}
{[}96{]} Pinto, G. and Rebouas, F.C.R.B.M. 2018. Work practices and
challenges in continuous integration: A survey with travis ci users.
(2018).

\hypertarget{ref-pinto2013}{}
{[}97{]} Pinto, L.S. et al. 2013. TestEvol: A tool for analyzing
test-suite evolution. \emph{Proceedings - international conference on
software engineering} (2013), 1303--1306.

\hypertarget{ref-pinto2012understanding}{}
{[}98{]} Pinto, L.S. et al. 2012. Understanding myths and realities of
test-suite evolution. \emph{Proceedings of the acm sigsoft 20th
international symposium on the foundations of software engineering}
(2012), 33.

\hypertarget{ref-plewnia2014a}{}
{[}99{]} Plewnia, C. et al. 2014. On the influence of release
engineering on software reputation. \emph{Mountain view, ca, usa: In 2nd
international workshop on release engineering} (2014).

\hypertarget{ref-poo-caamano2016a}{}
{[}100{]} Poo-Caamao, G. 2016. \emph{Release management in free and
open source software ecosystems}.

\hypertarget{ref-Raemaekers2017}{}
{[}101{]} Raemaekers, S. et al. 2017. Semantic versioning and impact of
breaking changes in the maven repository. \emph{Journal of Systems and
Software}. 129, (Jul. 2017), 140--158.

\hypertarget{ref-Rajlich2014}{}
{[}102{]} Rajlich, V. 2014. Software evolution and maintenance.
\emph{Proceedings of the on future of software engineering - FOSE 2014}
(2014).

\hypertarget{ref-rausch2017empirical}{}
{[}103{]} Rausch, T. et al. 2017. An empirical analysis of build
failures in the continuous integration workflows of java-based
open-source software. \emph{Proceedings of the 14th international
conference on mining software repositories} (2017), 345--355.

\hypertarget{ref-Robbes2012}{}
{[}104{]} Robbes, R. et al. 2012. How do developers react to API
deprecation? \emph{Proceedings of the ACM SIGSOFT 20th international
symposium on the foundations of software engineering - FSE 12} (2012).

\hypertarget{ref-robinson2011}{}
{[}105{]} Robinson, B. et al. 2011. Scaling up automated test
generation: Automatically generating maintainable regression unit tests
for programs. \emph{2011 26th ieee/acm international conference on
automated software engineering (ase 2011)} (Nov. 2011), 23--32.

\hypertarget{ref-rodriguez2017a}{}
{[}106{]} Rodrguez, P. et al. 2017. Continuous deployment of software
intensive products and services: A systematic mapping study.
\emph{Journal of Systems and Software}. 123, (2017), 263--291.

\hypertarget{ref-ROMANO201764}{}
{[}107{]} Romano, S. et al. 2017. Findings from a multi-method study on
test-driven development. \emph{Information and Software Technology}. 89,
(2017), 64--77.

\hypertarget{ref-santolucito2018statically}{}
{[}108{]} Santolucito, M. et al. 2018. Statically verifying continuous
integration configurations. \emph{arXiv preprint arXiv:1805.04473}.
(2018).

\hypertarget{ref-schneidewind2007}{}
{[}109{]} Schneidewind, N.F. 2007. Risk-driven software testing and
reliability. \emph{International Journal of Reliability, Quality and
Safety Engineering}. 14, 2 (2007), 99--132.

\hypertarget{ref-shamshiri2018automatically}{}
{[}110{]} Shamshiri, S. et al. 2018. How do automatically generated unit
tests influence software maintenance? \emph{Software testing,
verification and validation (icst), 2018 ieee 11th international
conference on} (2018), 250--261.

\hypertarget{ref-souza2015a}{}
{[}111{]} Souza, R. et al. 2015. Rapid releases and patch backouts: A
software analytics approach. \emph{IEEE Software}. 32, 2 (2015), 89--96.

\hypertarget{ref-Stallman2002}{}
{[}112{]} Stallman, R. 2002. \emph{Free software, free society: Selected
essays of richard m. stallman}. Lulu. com.

\hypertarget{ref-stolberg2009enabling}{}
{[}113{]} Stolberg, S. 2009. Enabling agile testing through continuous
integration. \emph{Agile conference, 2009. agile'09.} (2009), 369--374.

\hypertarget{ref-teixeira2017a}{}
{[}114{]} Teixeira, J. 2017. Release early, release often and release on
time. an empirical case study of release management. \emph{Open source
systems: Towards robust practices} (Cham, 2017), 167--181.

\hypertarget{ref-Teixeira2015}{}
{[}115{]} Teixeira, J. et al. 2015. Lessons learned from applying social
network analysis on an industrial free/libre/open source software
ecosystem. \emph{Journal of Internet Services and Applications}. 6, 1
(Jul. 2015).

\hypertarget{ref-thongtanunam2016revisiting}{}
{[}116{]} Thongtanunam, P. et al. 2016. Revisiting code ownership and
its relationship with software quality in the scope of modern code
review. \emph{Proceedings of the 38th international conference on
software engineering} (2016), 1039--1050.

\hypertarget{ref-thongtanunam2015should}{}
{[}117{]} Thongtanunam, P. et al. 2015. Who should review my code? A
file location-based code-reviewer recommendation approach for modern
code review. \emph{Software analysis, evolution and reengineering
(saner), 2015 ieee 22nd international conference on} (2015), 141--150.

\hypertarget{ref-Trockman2018}{}
{[}118{]} Trockman, A. 2018. Adding sparkle to social coding.
\emph{Proceedings of the 40th international conference on software
engineering companion proceeedings - ICSE 18} (2018).

\hypertarget{ref-vassallo2018break}{}
{[}119{]} Vassallo, C. et al. 2018. Un-break my build: Assisting
developers with build repair hints. (2018).

\hypertarget{ref-vassallo2017tale}{}
{[}120{]} Vassallo, C. et al. 2017. A tale of ci build failures: An open
source and a financial organization perspective. \emph{Software
maintenance and evolution (icsme), 2017 ieee international conference
on} (2017), 183--193.

\hypertarget{ref-vernotte2015}{}
{[}121{]} Vernotte, A. et al. 2015. \emph{Risk-driven vulnerability
testing: Results from eHealth experiments using patterns and model-based
approach}.

\hypertarget{ref-widder2018m}{}
{[}122{]} Widder, D.G. et al. 2018. I'im leaving you, travis: A
continuous integration breakup story. (2018).

\hypertarget{ref-xia2015should}{}
{[}123{]} Xia, X. et al. 2015. Who should review this change?: Putting
text and file location analyses together for more accurate
recommendations. \emph{Software maintenance and evolution (icsme), 2015
ieee international conference on} (2015), 261--270.

\hypertarget{ref-zaidman2011studying}{}
{[}124{]} Zaidman, A. et al. 2011. Studying the co-evolution of
production and test code in open source and industrial developer test
processes through repository mining. \emph{Empirical Software
Engineering}. 16, 3 (2011), 325--364.

\hypertarget{ref-zampetti2017open}{}
{[}125{]} Zampetti, F. et al. 2017. How open source projects use static
code analysis tools in continuous integration pipelines. \emph{Mining
software repositories (msr), 2017 ieee/acm 14th international conference
on} (2017), 334--344.

\hypertarget{ref-zanjani2016automatically}{}
{[}126{]} Zanjani, M.B. et al. 2016. Automatically recommending peer
reviewers in modern code review. \emph{IEEE Transactions on Software
Engineering}. 42, 6 (2016), 530--543.

\hypertarget{ref-zhao2017impact}{}
{[}127{]} Zhao, Y. et al. 2017. The impact of continuous integration on
other software development practices: A large-scale empirical study.
\emph{Proceedings of the 32nd ieee/acm international conference on
automated software engineering} (2017), 60--71.


\end{document}
